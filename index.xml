<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>PinkHello</title><link>https://pinkhello.me/</link><description>Recent content on PinkHello</description><generator>Hugo -- gohugo.io</generator><language>zh</language><copyright>PinkHello, All Rights Reserved</copyright><lastBuildDate>Tue, 16 Feb 2021 22:48:35 +0800</lastBuildDate><atom:link href="https://pinkhello.me/index.xml" rel="self" type="application/rss+xml"/><item><title>20 回望K8S 容器编排与Kubernetes作业管理</title><link>https://pinkhello.me/posts/20-%E5%9B%9E%E6%9C%9Bk8s-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E4%B8%8Ekubernetes%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/</link><pubDate>Tue, 16 Feb 2021 22:48:35 +0800</pubDate><guid>https://pinkhello.me/posts/20-%E5%9B%9E%E6%9C%9Bk8s-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E4%B8%8Ekubernetes%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/</guid><description>PinkHello https://pinkhello.me/posts/20-%E5%9B%9E%E6%9C%9Bk8s-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E4%B8%8Ekubernetes%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/ -&lt;h1 id="pod">Pod&lt;/h1>
&lt;p>&lt;code>pod&lt;/code> 是 &lt;code>Kubernetes&lt;/code> 项目的最小的 API 对象，原子调度单位.&lt;/p>
&lt;p>假设 &amp;ldquo;容器的本质是进程&amp;rdquo;，容器镜像就是 exe 安装包, kubernetes 是操作系统&lt;/p>
&lt;p>&lt;code>Pod&lt;/code> 最重要的一个事实是一个逻辑概念。它对于 &lt;code>Kubernetes&lt;/code> 最核心的意义是 &lt;code>容器设计模式&lt;/code>。&lt;code>Kubernetes&lt;/code> 真正处理的还是宿主机上操作系统上的 &lt;code>Linux&lt;/code> 容器的 &lt;code>Namespace&lt;/code> 和 &lt;code>Cgroups&lt;/code>，而不是一个所谓的 &lt;code>Pod&lt;/code> 边界和隔离环境。&lt;/p>
&lt;p>&lt;code>Pod&lt;/code> 其实是一组共享了某些资源的容器。&lt;code>Pod&lt;/code> 里面所有的容器，共享的同一个 &lt;code>Network Namespace&lt;/code>，并且可以声明共享同一个 &lt;code>Volume&lt;/code>.&lt;/p>
&lt;p>&lt;code>Kubernetes&lt;/code> 项目内部，&lt;code>Pod&lt;/code> 实现需要使用一个中间容器，这个容器叫做 &lt;code>Infra&lt;/code> 容器，在 &lt;code>Pod&lt;/code> 中，&lt;code>Infra&lt;/code> 容器永远都是第一个被创建的容器，而其他用户定义的容器，则通过 &lt;code>Join Network Namespace&lt;/code> 的方式，与 &lt;code>Infra&lt;/code> 容器关联在一起。&lt;/p>
&lt;h2 id="sidecar">&lt;code>sidecar&lt;/code>&lt;/h2>
&lt;h3 id="典型的例子war-包和-web-服务器">典型的例子：WAR 包和 Web 服务器&lt;/h3>
&lt;p>&lt;code>POD&lt;/code>后，将 &lt;code>WAR&lt;/code> 包和 &lt;code>Tomcat&lt;/code> 分别做成镜像，可以把他们容器结合在一起&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Pod&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>javaweb-2&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#228b22"># 启动后做了一件事 把应用的WAR包拷贝到 /app目录中，后退出&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">initContainers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>sample-war:v2&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>war&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">command&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>[&lt;span style="color:#cd5555">&amp;#34;cp&amp;#34;&lt;/span>,&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;/sample.war&amp;#34;&lt;/span>,&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;/app&amp;#34;&lt;/span>]&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">volumeMounts&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>/app&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>app-volume&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>tomcat:7.0&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>tomcat&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">command&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>[&lt;span style="color:#cd5555">&amp;#34;sh&amp;#34;&lt;/span>,&lt;span style="color:#cd5555">&amp;#34;-c&amp;#34;&lt;/span>,&lt;span style="color:#cd5555">&amp;#34;/root/apache-tomcat-7.0.42-v2/bin/start.sh&amp;#34;&lt;/span>]&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">volumeMounts&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>/root/apache-tomcat-7.0.42-v2/webapps&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>app-volume&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">8080&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">hostPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">8001&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">volumes&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>app-volume&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">emptyDir&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>{}&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#008b45;text-decoration:underline">...&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这个&lt;code>POD&lt;/code>中，定义了两个容器，第一个容器镜像&lt;code> sample-war:v2&lt;/code>，第二个容器镜像是 &lt;code>Tomcat&lt;/code> 镜像，War包容器的类型不是一个普通容器，是一个 &lt;code>Init Container&lt;/code> 类型的容器。&lt;/p>
&lt;p>在Pod中，所有 &lt;code>Init Container&lt;/code> 定义的容器，都比 &lt;code>spec.containers&lt;/code> 定义的用户容器先启动。并且， &lt;code>Init Container&lt;/code> 容器会按顺序准一启动，而直到他们都启动并且退出了，用户容器才会启动。&lt;/p>
&lt;p>这种组合的方式，正是容器设计模式里面最常用的一种模式：&lt;code>sidecar&lt;/code>&lt;/p>
&lt;h3 id="容器的日志收集">容器的日志收集&lt;/h3>
&lt;p>应用把日志文件输出到容器的 &lt;code>/var/log&lt;/code> 目录中，&lt;code>Pod&lt;/code>的 &lt;code>Volume&lt;/code> 挂载到应用容器的 &lt;code>/var/log&lt;/code> 目录上，然后在这个 &lt;code>Pod&lt;/code> 里的运行一个 &lt;code>sidecar&lt;/code> 容器，也声明挂载同一个 &lt;code>Volume&lt;/code> 到自己的 &lt;code>/var/log&lt;/code> 目录上，
这样这个 &lt;code>sidecar&lt;/code> 容器只需要做一件事，把自己的 &lt;code>/var/log&lt;/code> 目录中读取日志文件，转发就可以了，就是一个基本的日志收集&lt;/p>
&lt;h1 id="pod-对象的基本概念">&lt;code>Pod&lt;/code> 对象的基本概念&lt;/h1>
&lt;p>&lt;code>Pod&lt;/code> 是容器环境的 &lt;code>Kubernetes&lt;/code> 的基本单元，调度、网络、存储、以及安全相关的熟悉，都是属于 &lt;code>Pod&lt;/code> 级别的。&lt;/p>
&lt;p>&lt;code>Pod&lt;/code> 下重要的字段和含义&lt;/p>
&lt;ul>
&lt;li>&lt;code>NodeSelector&lt;/code> : 用户将 &lt;code>Pod&lt;/code> 和 &lt;code>Node&lt;/code> 绑定的字段&lt;/li>
&lt;li>&lt;code>NodeName&lt;/code> : 一旦 &lt;code>Pod&lt;/code> 的这个阻断被赋值，&lt;code>K8S&lt;/code> 会认为这个 &lt;code>Pod&lt;/code> 已经经过调度。&lt;/li>
&lt;li>&lt;code>HostAliases&lt;/code>：定义了 &lt;code>Pod&lt;/code> 的 &lt;code>hosts&lt;/code> 文件（比如 &lt;code>/etc/hosts&lt;/code>）里的内容&lt;/li>
&lt;/ul>
&lt;p>凡是跟容器的 &lt;code>Linux Namespace&lt;/code> 相关的属性，也一定是 &lt;code>Pod&lt;/code> 级别的。
&lt;code>shareProcessNamespace=true&lt;/code>&lt;/p>
&lt;p>&lt;code>Pod&lt;/code> 对象在 &lt;code>Kubernetes&lt;/code> 中的生命周期。&lt;code>Pod&lt;/code> 生命周期的变化，主要体现在 &lt;code>Pod API 对象&lt;/code>的 &lt;code>Status&lt;/code> 部分，这是它除了 &lt;code>Metadata&lt;/code> 和 &lt;code>Spec&lt;/code> 之外的第三个重要字段。其中，&lt;code>pod.status.phase&lt;/code>，就是 &lt;code>Pod&lt;/code> 的当前状态，
它有如下几种可能的情况：&lt;/p>
&lt;ul>
&lt;li>&lt;code>Pending&lt;/code>。这个状态意味着，&lt;code>Pod&lt;/code> 的 &lt;code>YAML&lt;/code> 文件已经提交给了 &lt;code>Kubernetes&lt;/code>，&lt;code>API&lt;/code> 对象已经被创建并保存在 &lt;code>Etcd&lt;/code> 当中。但是，这个 &lt;code>Pod&lt;/code> 里有些容器因为某种原因而不能被顺利创建。比如，调度不成功。&lt;/li>
&lt;li>&lt;code>Running&lt;/code>。这个状态下，&lt;code>Pod&lt;/code> 已经调度成功，跟一个具体的节点绑定。它包含的容器都已经创建成功，并且至少有一个正在运行中。&lt;/li>
&lt;li>&lt;code>Succeeded&lt;/code>。这个状态意味着，&lt;code>Pod&lt;/code> 里的所有容器都正常运行完毕，并且已经退出了。这种情况在运行一次性任务时最为常见。&lt;/li>
&lt;li>&lt;code>Failed&lt;/code>。这个状态下，&lt;code>Pod&lt;/code> 里至少有一个容器以不正常的状态（非 0 的返回码）退出。这个状态的出现，意味着你得想办法 &lt;code>Debug&lt;/code> 这个容器的应用，比如查看 &lt;code>Pod&lt;/code> 的 &lt;code>Events&lt;/code> 和日志。&lt;/li>
&lt;li>&lt;code>Unknown&lt;/code>。这是一个异常状态，意味着 &lt;code>Pod&lt;/code> 的状态不能持续地被 &lt;code>kubelet&lt;/code> 汇报给 &lt;code>kube-apiserver&lt;/code>，这很有可能是主从节点（&lt;code>Master&lt;/code> 和 &lt;code>Kubelet&lt;/code>）间的通信出现了问题。&lt;/li>
&lt;/ul>
&lt;h1 id="kubernetes-其他对象-volume">&lt;code>Kubernetes&lt;/code> 其他对象 &lt;code>Volume&lt;/code>&lt;/h1>
&lt;p>&lt;code>Kubernetes&lt;/code> 支持的 &lt;code>Project Volume&lt;/code> 一共有四种:&lt;/p>
&lt;ul>
&lt;li>&lt;code>Secret&lt;/code> : 把 Pod 想要访问的加密数据，存放到 &lt;code>Etcd&lt;/code> 中，然后通过在 Pod 的容器里挂载 Volume 的方式。&lt;/li>
&lt;li>&lt;code>ConfigMap&lt;/code> : 保存的是不需要加密的、应用所需的配置信息。而 &lt;code>ConfigMap&lt;/code> 的用法几乎与 &lt;code>Secret&lt;/code> 完全相同：你可以使用 &lt;code>kubectl create configmap&lt;/code> 从文件或者目录创建 &lt;code>ConfigMap&lt;/code>，也可以直接编写 &lt;code>ConfigMap&lt;/code> 对象的 &lt;code>YAML&lt;/code> 文件。&lt;/li>
&lt;li>&lt;code>Downward API&lt;/code> : 让 Pod 里的容器能够直接获取到这个&lt;code> Pod API&lt;/code> 对象本身的信息。
&lt;blockquote>
&lt;p>一定是 Pod 里的容器进程启动之前就能够确定下来的信息。而如果你想要获取 Pod 容器运行后才会出现的信息，比如，容器进程的 &lt;code>PID&lt;/code>，那就肯定不能使用 &lt;code>Downward API&lt;/code> 了，而应该考虑在 &lt;code>Pod&lt;/code> 里定义一个 &lt;code>sidecar&lt;/code> 容器。&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>&lt;code>ServiceAccountToken&lt;/code> : 这种把 &lt;code>Kubernetes&lt;/code> 客户端以容器的方式运行在集群里，然后使用 &lt;code>default Service Account&lt;/code> 自动授权的方式，被称作“InClusterConfig”.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Secret&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>mysecret&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">type&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Opaque&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">data&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">user&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>YWRtaW4=&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">pass&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>MWYyZDFlMmU2N2Rm&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#008b45;text-decoration:underline">...&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; kubectl create secret
&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="容器的健康检查和恢复机制">容器的健康检查和恢复机制&lt;/h1>
&lt;p>&lt;code>Pod&lt;/code> 容器定义了一个健康检查的&amp;quot;探针&amp;quot;（Probe）, 这样kubelet就会根据这个 probe 返回的值决定这个容器的状态，而不是直接以容器镜像十分运行来作为依据。生产环境保证应用健康存活的重要手段。&lt;/p>
&lt;p>&lt;code>Pod&lt;/code> 恢复机制 restartPolicy, 它是 Pod 的 Spec 部分的一个标准字段（&lt;code>pod.spec.restartPolicy&lt;/code>），默认值是 &lt;code>Always&lt;/code>，即：任何时候这个容器发生了异常，它一定会被重新创建。&lt;/p>
&lt;blockquote>
&lt;p>&lt;code>pod&lt;/code> 恢复，永远只发生在当前节点，而不会跑到别的节点上去。（不会发生故障转移）需要转移的需要切换到 &lt;code>Deployment&lt;/code> 这样的控制器来管理&lt;code>POD &lt;/code>&lt;/p>
&lt;/blockquote>
&lt;p>你还可以通过设置 &lt;code>restartPolicy&lt;/code>，改变 &lt;code>Pod&lt;/code> 的恢复策略。除了 &lt;code>Always&lt;/code>，它还有 &lt;code>OnFailure&lt;/code> 和 &lt;code>Never&lt;/code> 两种情况：&lt;/p>
&lt;ul>
&lt;li>&lt;code>Always&lt;/code>：在任何情况下，只要容器不在运行状态，就自动重启容器；&lt;/li>
&lt;li>&lt;code>OnFailure&lt;/code>: 只在容器 异常时才自动重启容器；&lt;/li>
&lt;li>&lt;code>Never&lt;/code>: 从来不重启容器。&lt;/li>
&lt;/ul>
&lt;h1 id="编排其实很简单-控制器模型">编排其实很简单-&amp;ldquo;控制器&amp;quot;模型&lt;/h1>
&lt;p>前面已经知道 &lt;code>POD&lt;/code> 是一个复杂的&lt;code>API对象&lt;/code>，实际也是对容器的进一步抽象和封装；也就是说&lt;code>Pod对象&lt;/code>是容器的升级版,它对容器的组合，添加了很多的属性和字段。&lt;/p>
&lt;p>&lt;code>Kubernetes&lt;/code>操作&lt;code>POD&lt;/code>是依赖控制器(Controller)完成的。就是 kube-controller-manager 组件&lt;/p>
&lt;p>通过查看 &lt;code>https://github.com/kubernetes/kubernetes/tree/master/pkg/controller&lt;/code> 源代码下能看见这些目录&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">deployment/ job/ podautoscaler/ cloud/ disruption/ namespace/
replicaset/ serviceaccount/ volume/cronjob/ garbagecollector/ nodelifecycle/
replication/ statefulset/ daemon/...
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这些每个目录都是一种类型的 &lt;code>controller&lt;/code>,各自负责某种编排功能。&lt;/p>
&lt;p>控制循环（control loop）&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">
&lt;span style="color:#8b008b;font-weight:bold">for&lt;/span> {
实际状态 := 获取集群中对象X的实际状态&lt;span style="color:#a61717;background-color:#e3d2d2">（&lt;/span>Actual State&lt;span style="color:#a61717;background-color:#e3d2d2">）&lt;/span>
期望状态 := 获取集群中对象X的期望状态&lt;span style="color:#a61717;background-color:#e3d2d2">（&lt;/span>Desired State&lt;span style="color:#a61717;background-color:#e3d2d2">）&lt;/span>
&lt;span style="color:#8b008b;font-weight:bold">if&lt;/span> 实际状态 == 期望状态{
什么都不做
} &lt;span style="color:#8b008b;font-weight:bold">else&lt;/span> {
执行编排动作&lt;span style="color:#a61717;background-color:#e3d2d2">，&lt;/span>将实际状态调整为期望状态
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>具体实现时候，&lt;code>实际状态&lt;/code>来自于&lt;code>Kubernetes&lt;/code> 集群本身，&lt;code>期望状态&lt;/code>来自于用户提交的 &lt;code>YAML&lt;/code> 文件。&lt;/p>
&lt;blockquote>
&lt;p>比如&lt;/p>
&lt;ul>
&lt;li>&lt;code>Deployment控制器&lt;/code>从&lt;code>Etcd&lt;/code>中获取到目标标签的 &lt;code>POD&lt;/code>，然后统计他们的数量，这是实际状态；&lt;/li>
&lt;li>&lt;code>Deployment对象&lt;/code>的 &lt;code>Replicas&lt;/code> 字段的值是期望状态；&lt;/li>
&lt;li>&lt;code>Deployment控制器&lt;/code>将两个状态做比较，然后根据比较结果，确定创建&lt;code>POD&lt;/code>还是删除已经存在的&lt;code>POD&lt;/code>&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>这个操作叫做协调（&lt;code>Reconcile&lt;/code>）即 控制循环&lt;/p>
&lt;blockquote>
&lt;p>为什么是循环，因为事件往往是一次性的，如果操作失败比较难处理，但是控制器循环一直尝试，更符合 Kubernetes 声明式API，最终达成一致。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://pinkhello.me/%E5%9B%9E%E6%9C%9BK8S/deployment.png" alt="deployment结构">&lt;/p>
&lt;p>上半部分的控制器定义（包含期望状态），下面的部分被控制对象的模板组成的。&lt;/p>
&lt;h1 id="作业副本和水平扩展">作业副本和水平扩展&lt;/h1>
&lt;h2 id="pod-的水平扩展--收缩horizontal-scaling-outin">Pod 的“水平扩展 / 收缩”（horizontal scaling out/in）&lt;/h2>
&lt;p>如果我们更新了 &lt;code>Deployment&lt;/code> 的 &lt;code>Pod&lt;/code> 模板（假如更新了容器镜像），那么 &lt;code>Deployment&lt;/code> 需要遵循一种 &amp;ldquo;滚动更新&amp;rdquo;（&lt;code>rolling update&lt;/code>）的方式来升级现有的容器。这也是 &lt;code>kubernetes&lt;/code> 重要的概念（API对象）：&lt;code>ReplicaSet&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>apps/v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>ReplicaSet&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx-set&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">3&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">matchLabels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">template&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx:1.7.9&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>一个 &lt;code>ReplicaSet&lt;/code>对象，由 副本数目的定义和一个Pod模板组成的。它其实是 &lt;code>Deployment&lt;/code> 的子集。而且，&lt;code>Deployment控制器&lt;/code>操作的正是 &lt;code>ReplicaSet&lt;/code> 对象，而不是&lt;code>Pod对象&lt;/code>。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">kubectl scale
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="https://pinkhello.me/%E5%9B%9E%E6%9C%9BK8S/replicaset.jpg" alt="ReplicaSet结构">&lt;/p>
&lt;h2 id="滚动更新">滚动更新&lt;/h2>
&lt;p>将一个集群中正在运行的多个 &lt;code>Pod&lt;/code> 版本，交替地逐一升级的过程，就是“滚动更新”。&lt;/p>
&lt;blockquote>
&lt;ul>
&lt;li>依赖 &lt;code>health check&lt;/code> 机制&lt;/li>
&lt;li>保证服务的连续性&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;img src="https://pinkhello.me/%E5%9B%9E%E6%9C%9BK8S/deployment-replicaset-pod.jpg" alt="DeploymentReplicaSet">&lt;/p>
&lt;p>&lt;code>Deployment&lt;/code> 实际上是一个两层控制器。首先，它通过 &lt;code>ReplicaSet&lt;/code> 的个数来描述应用的版本；然后，它再通过 &lt;code>ReplicaSet&lt;/code> 的属性（比如 &lt;code>replicas&lt;/code> 的值），来保证 &lt;code>Pod&lt;/code> 的副本数量。&lt;/p>
&lt;h1 id="深入理解statefulset">深入理解StatefulSet&lt;/h1>
&lt;ul>
&lt;li>拓扑状态：应用间不完全对等，需要谁先启动，谁后启动，必须按照某些顺序来启动。（在&lt;code>Pod&lt;/code>删除和再创建中保持稳定）&lt;/li>
&lt;li>存储状态：多个实例绑定了不同的存储数据，一个数据库应用的多个存储实例&lt;/li>
&lt;/ul>
&lt;h2 id="拓扑状态">拓扑状态&lt;/h2>
&lt;p>StatefulSet 核心功能：通过某种方式纪录这些状态，等POD被重新创建时候，能够为新的POD恢复状态。&lt;/p>
&lt;p>Headless Service&lt;/p>
&lt;p>Service 是 Kubernetes 项目中用来将一组 Pod 暴露给外界访问的一种机制。比如，一个 &lt;code>Deployment&lt;/code> 有 &lt;code>3&lt;/code> 个 &lt;code>Pod&lt;/code>，那么我就可以定义一个 &lt;code>Service&lt;/code>。然后，用户只要能访问到这个 &lt;code>Service&lt;/code>，它就能访问到某个具体的 &lt;code>Pod&lt;/code>。&lt;/p>
&lt;ul>
&lt;li>第一种方式，是以 &lt;code>Service&lt;/code> 的 &lt;code>VIP&lt;/code>（&lt;code>Virtual IP&lt;/code>，即：虚拟 IP）方式。&lt;/li>
&lt;li>第二种方式，就是以 &lt;code>Service&lt;/code> 的 &lt;code>DNS&lt;/code> 方式, 比如 只要我访问“&lt;code>my-svc.my-namespace.svc.cluster.local&lt;/code>”这条 DNS 记录，就可以访问到名叫 &lt;code>my-svc&lt;/code> 的 &lt;code>Service&lt;/code> 所代理的某一个 &lt;code>Pod&lt;/code>。&lt;/li>
&lt;/ul>
&lt;p>&lt;code>Service DNS&lt;/code> 下两种处理方法&lt;/p>
&lt;blockquote>
&lt;p>&lt;code>Normal Service&lt;/code>。这种情况下，你访问“my-svc.my-namespace.svc.cluster.local”解析到的，正是 my-svc 这个 Service 的 VIP，后面的流程就跟 VIP 方式一致了。
&lt;code>Headless Service&lt;/code>。这种情况下，你访问“my-svc.my-namespace.svc.cluster.local”解析到的，直接就是 my-svc 代理的某一个 Pod 的 IP 地址。可以看到，这里的区别在于，Headless Service 不需要分配一个 VIP，而是可以直接以 DNS 记录的方式解析出被代理 Pod 的 IP 地址。&lt;/p>
&lt;/blockquote>
&lt;p>Headless Service Yaml&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Service&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">80&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>web&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">clusterIP&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>None&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>StatefulSet Yaml&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>apps/v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>StatefulSet&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>web&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># 多了这个 ServiceName 就是告诉 StatefulSet 控制器，在执行控制循环（Control Loop）的时候，请使用 nginx 这个 Headless Service 来保证 Pod 的“可解析身份”。&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">serviceName&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;nginx&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">2&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">matchLabels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">template&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx:1.9.1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">80&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>web&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>，对于“有状态应用”实例的访问，你必须使用 &lt;code>DNS 记录&lt;/code>或者 &lt;code>hostname&lt;/code> 的方式，而绝不应该直接访问这些 &lt;code>Pod&lt;/code> 的 IP 地址。&lt;/p>
&lt;h2 id="存储状态">存储状态&lt;/h2>
&lt;p>&lt;code>StatefulSet&lt;/code> 存储状态的管理机制，主要使用的是一个叫做 &lt;code>Persistent Volume Claim&lt;/code> 功能。&lt;/p>
&lt;p>要在一个 Pod 里面声明 Volume，只要在 Pod 里加上 &lt;code>spec.volumes&lt;/code> 字段，然后就可以在这个字段里面定义一个具体的类型的 &lt;code>Volume&lt;/code>。比如 &lt;code>hostPath&lt;/code>。&lt;/p>
&lt;p>&lt;code>Kubernetes&lt;/code> 项目引入了一组叫作 &lt;code>Persistent Volume Claim&lt;/code>（PVC）和 &lt;code>Persistent Volume&lt;/code>（PV）的 API 对象，大大降低了用户声明和使用持久化 &lt;code>Volume&lt;/code> 的门槛。&lt;/p>
&lt;p>使用PVC的两步：&lt;/p>
&lt;ul>
&lt;li>定义一个 &lt;code>PVC&lt;/code>，声明想要的 &lt;code>Volume&lt;/code> 属性&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>PersistentVolumeClaim&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>pv-claim&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">accessModes&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- ReadWriteOnce&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># 挂载方式：可读写，并且只能被挂载在一个节点上，非多个节点共享&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">resources&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">requests&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">storage&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>1Gi &lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22">#存储大小&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>在应用 &lt;code>POD&lt;/code> 中，使用这个 &lt;code>PVC&lt;/code>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Pod&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>pv-pod&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>pv-container&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>nginx&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">80&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;http-server&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">volumeMounts&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;/usr/share/nginx/html&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>pv-storage&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">volumes&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>pv-storage&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">persistentVolumeClaim&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">claimName&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>pv-claim&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># 指定上面的PVC的名字&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>从上面来看，这个 &lt;code>Volume&lt;/code> 又从何而来呢？（运维人员维护的 &lt;code>PV&lt;/code>）&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#228b22"># 这个 PV 对象的 spec.rbd 字段，正是我们前面介绍过的 Ceph RBD Volume 的详细定义。而且，它还声明了这个 PV 的容量是 10 GiB。这样，Kubernetes 就会为我们刚刚创建的 PVC 对象绑定这个 PV&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>PersistentVolume&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>pv-volume&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">type&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>local&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">capacity&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">storage&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>10Gi&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">accessModes&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- ReadWriteOnce&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">rbd&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">monitors&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># 使用 kubectl get pods -n rook-ceph 查看 rook-ceph-mon- 开头的 POD IP 即可得下面的列表&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#cd5555">&amp;#39;10.16.154.78:6789&amp;#39;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#cd5555">&amp;#39;10.16.154.82:6789&amp;#39;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#cd5555">&amp;#39;10.16.154.83:6789&amp;#39;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">pool&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kube&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>foo&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">fsType&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>ext4&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">readOnly&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">true&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">user&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>admin&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">keyring&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>/etc/ceph/keyring&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>所以 &lt;code>Kubernetes&lt;/code> 中的 &lt;code>PVC&lt;/code> 和 &lt;code>PV&lt;/code> 的设计，类似于 &amp;ldquo;接口&amp;rdquo; 和 &amp;ldquo;实现&amp;rdquo; 的思想，这种解耦，避免了暴露系统更多的细节，也是职责的分离，更容易定位问题&lt;/p>
&lt;h2 id="statefulset-的工作原理">StatefulSet 的工作原理&lt;/h2>
&lt;ul>
&lt;li>&lt;code>StatefulSet&lt;/code> 控制器直接管理的是 &lt;code>POD&lt;/code>&lt;/li>
&lt;li>&lt;code>Kubernetes&lt;/code> 通过 &lt;code>Headless Service&lt;/code> 为这些有编号的 &lt;code>POD&lt;/code>。在 &lt;code>DNS&lt;/code> 服务器众生成同样带有编号的 &lt;code>DNS纪录&lt;/code>。只要 &lt;code>StatefulSet&lt;/code> 能够保证这些 &lt;code>POD&lt;/code> 的名字编号不变，类似 &amp;ldquo;&lt;code>web-0.default.svc.cluster.local&lt;/code>&amp;rdquo; 这样的 &lt;code>DNS纪录&lt;/code> 就不会变，而这条纪录解析出来的&lt;code>POD&lt;/code>的&lt;code>IP&lt;/code>地址，会随着&lt;code>后端的POD删除和再创建&lt;/code>而更新。&lt;/li>
&lt;li>&lt;code>StatefulSet&lt;/code> 还为每个 &lt;code>POD&lt;/code> 分配并创建一个同样编号的 &lt;code>PVC&lt;/code>，这样 &lt;code>Kubernetes&lt;/code> 可以通过 &lt;code>Persistent Volume&lt;/code> 机制为这个 &lt;code>PVC&lt;/code> 绑定对应的 &lt;code>PV&lt;/code>，保证一个&lt;code>POD&lt;/code>都有一个独立的 &lt;code>Volume&lt;/code>（即使&lt;code>POD&lt;/code>被删除，但是对应的 &lt;code>PVC&lt;/code> 和 &lt;code>PV&lt;/code> 保留下来，重新创建&lt;code>POD&lt;/code>的时候，还会找回来，数据还存在）&lt;/li>
&lt;/ul>
&lt;h1 id="容器化守护进程的意义-daemonset">容器化守护进程的意义 DaemonSet&lt;/h1>
&lt;p>&lt;code>DaemonSet&lt;/code> 主要的作用: 在&lt;code>Kubernetes&lt;/code>集群里运行一个 &lt;code>Daemon Pod&lt;/code>,这个&lt;code>Pod&lt;/code>三个特征&lt;/p>
&lt;ul>
&lt;li>每个&lt;code>Kubernetes&lt;/code>节点都会运行一个这样的&lt;code>POD&lt;/code>&lt;/li>
&lt;li>每个节点上只有一个这样的 &lt;code>Pod&lt;/code> 实例&lt;/li>
&lt;li>当有新的节点加入 &lt;code>Kuberntes&lt;/code> 集群后，该 &lt;code>Pod&lt;/code> 会自动的在新的节点上被创建出来，而当旧节点被删除后, 它上面的 Pod 也会相应地被回收掉。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>eg：&lt;/p>
&lt;ul>
&lt;li>网络插件的 Agent 组件，必须运行在每个节点上，用来处理容器的网络&lt;/li>
&lt;li>存储插件 Agent 组件，必须运行在每个节点上，用来挂载远程存储目录，操作容器的 Volume 目录&lt;/li>
&lt;li>监控组件 以及 日志组件，也是一样，负责节点的监控信息和日志收集&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>跟其他编排不一样，DaemonSet 开始运行的时机，很多时候比整个 Kubernetes 集群出现的还要早。比如容器网络组件，在所有的 Worker节点状态都是 NotReady。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#228b22"># fluentd-elasticsearch 镜像POD， 通过 Fluentd 将 Docker 容器日志转发到 ES 内。&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>apps/v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>DaemonSet&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>fluentd-elasticsearch&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">namespace&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kube-system&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">k8s-app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>fluentd-logging&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">matchLabels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>fluentd-elasticsearch&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">template&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>fluentd-elasticsearch&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">tolerations&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">key&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>node-role.kubernetes.io/master&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">effect&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>NoSchedule&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>fluentd-elasticsearch&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>k8s.gcr.io/fluentd-elasticsearch:1.20&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">resources&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">limits&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">memory&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>200Mi&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">requests&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">cpu&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>100m&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">memory&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>200Mi&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># 挂载了两个hostPath类型 的 Volume &lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">volumeMounts&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>varlog&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>/var/log&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># Docker 容器里应用的日志，默认会保存在宿主机的 /var/lib/docker/containers/{{. 容器 ID}}/{{. 容器 ID}}-json.log 文件里，所以这个目录正是 fluentd 的搜集目标 &lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>varlibdockercontainers&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>/var/lib/docker/containers&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">readOnly&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">true&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">terminationGracePeriodSeconds&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">30&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">volumes&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>varlog&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">hostPath&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">path&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>/var/log&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>varlibdockercontainers&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">hostPath&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">path&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>/var/lib/docker/containers&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>DaemonSet Controller&lt;/code>，首先从 &lt;code>Etcd&lt;/code> 里获取所有的 &lt;code>Node&lt;/code> 列表，然后遍历所有的 &lt;code>Node&lt;/code>。这时就会去检查这个&lt;code>Node&lt;/code>上是不是已经存在携带了 &lt;code>name=fluentd-elasticsearch&lt;/code> 的 &lt;code>POD&lt;/code> 在运行了&lt;/p>
&lt;ul>
&lt;li>没有这个POD，则创建一个新的 POD&lt;/li>
&lt;li>有这种POD，数量 &amp;gt; 1, 删除多余的&lt;/li>
&lt;li>正好一个，节点正常&lt;/li>
&lt;/ul>
&lt;p>&lt;code>DaemonSet&lt;/code> 会自动加上 &lt;code>tolerations&lt;/code>字段&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Pod&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>with-toleration&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># “容忍”所有被标记为 unschedulable“污点”的 Node；“容忍”的效果是允许调度。&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">tolerations&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">key&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>node.kubernetes.io/unschedulable&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">operator&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Exists&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">effect&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>NoSchedule&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在正常情况下，被标记了 unschedulable“污点”的 Node，是不会有任何 Pod 被调度上去的（effect: NoSchedule）。可是，DaemonSet 自动地给被管理的 Pod 加上了这个特殊的 Toleration，就使得这些 Pod 可以忽略这个限制，继而保证每个节点上都会被调度一个 Pod。当然，如果这个节点有故障的话，这个 Pod 可能会启动失败，而 DaemonSet 则会始终尝试下去，直到 Pod 启动成功。&lt;/p>
&lt;h1 id="离线业务-job-与-cronjob">离线业务 Job 与 CronJob&lt;/h1>
&lt;p>像在线业务诸如应用一类的，抽离了描述离线业务的API对象：Job&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>batch/v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Job&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>pi&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">template&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>pi&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>resouer/ubuntu-bc &lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">command&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>[&lt;span style="color:#cd5555">&amp;#34;sh&amp;#34;&lt;/span>,&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;-c&amp;#34;&lt;/span>,&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;echo &amp;#39;scale=10000; 4*a(1)&amp;#39; | bc -l &amp;#34;&lt;/span>]&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">restartPolicy&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Never&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">backoffLimit&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">4&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">
$ kubectl describe jobs/pi
Name: pi
Namespace: default
Selector: controller-uid=c2db599a-2c9d-11e6-b324-0209dc45a495
Labels: controller-uid=c2db599a-2c9d-11e6-b324-0209dc45a495
job-name=pi
Annotations: &amp;lt;none&amp;gt;
Parallelism: &lt;span style="color:#b452cd">1&lt;/span>
Completions: &lt;span style="color:#b452cd">1&lt;/span>
..
Pods Statuses: &lt;span style="color:#b452cd">0&lt;/span> Running / &lt;span style="color:#b452cd">1&lt;/span> Succeeded / &lt;span style="color:#b452cd">0&lt;/span> Failed
Pod Template:
Labels: controller-uid=c2db599a-2c9d-11e6-b324-0209dc45a495
job-name=pi
Containers:
...
Volumes: &amp;lt;none&amp;gt;
Events:
FirstSeen LastSeen Count From SubobjectPath Type Reason Message
--------- -------- ----- ---- ------------- -------- ------ -------
1m 1m &lt;span style="color:#b452cd">1&lt;/span> {job-controller } Normal SuccessfulCreate Created pod: pi-rq5rl
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这个 Job 对象在创建后，它的 Pod 模板，被自动加上了一个 controller-uid=&amp;lt; 一个随机字符串 &amp;gt; 这样的 Label。而这个 Job 对象本身，则被自动加上了这个 Label 对应的 Selector，从而 保证了 Job 与它所管理的 Pod 之间的匹配关系。而 Job Controller 之所以要使用这种携带了 UID 的 Label，就是为了避免不同 Job 对象所管理的 Pod 发生重合。&lt;/p>
&lt;p>如果作业失败了怎么办？&lt;/p>
&lt;p>定义了 restartPolicy=Never，那么离线作业失败后 Job Controller 就会不断地尝试创建一个新 Pod
我们就在 Job 对象的 spec.backoffLimit 字段里定义了重试次数为 4（即，backoffLimit=4），而这个字段的默认值是 6。
定义的 restartPolicy=OnFailure，那么离线作业失败后，Job Controller 就不会去尝试创建新的 Pod。但是，它会不断地尝试重启 Pod 里的容器&lt;/p>
&lt;p>Job 对象中，并行作业的控制方法&lt;/p>
&lt;ul>
&lt;li>1、spec.parallelism，它定义的是一个 Job 在任意时间最多可以启动多少个 Pod 同时运行；&lt;/li>
&lt;li>2、spec.completions，它定义的是 Job 至少要完成的 Pod 数目，即 Job 的最小完成数。&lt;/li>
&lt;/ul>
&lt;h2 id="常用的使用-job对象的方法">常用的使用 Job对象的方法&lt;/h2>
&lt;ul>
&lt;li>外部管理器 + Job模板 （sed）&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>batch/v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Job&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># 带遍历替换&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>process-item-$ITEM&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">jobgroup&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>jobexample&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">template&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>jobexample&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">jobgroup&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>jobexample&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>c&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>busybox&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">command&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>[&lt;span style="color:#cd5555">&amp;#34;sh&amp;#34;&lt;/span>,&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;-c&amp;#34;&lt;/span>,&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;echo Processing item $ITEM &amp;amp;&amp;amp; sleep 5&amp;#34;&lt;/span>]&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">restartPolicy&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Never&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>
&lt;p>拥有固定任务数目的并行Job&lt;/p>
&lt;/li>
&lt;li>
&lt;p>指定并行度（parallelism），但不设置固定的 completions 的值。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="cronjob-对象">CronJob 对象&lt;/h2>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>batch/v1beta1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>CronJob&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>hello&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># cron &lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">schedule&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;*/1 * * * *&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">jobTemplate&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">template&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>hello&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>busybox&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">args&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- /bin/sh&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- -c&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- date; echo Hello from the Kubernetes cluster&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">restartPolicy&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>OnFailure&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>CronJob 是专门管理 Job 对象的控制其。只不过它的创建和删除Job依据是根据
schedule 字段来定义的。&lt;/p>
&lt;p>在 定时任务的时候，可能有任务未执行完毕，就下面的Pod启动&lt;/p>
&lt;ul>
&lt;li>concurrencyPolicy=Allow，这也是默认情况，这意味着这些 Job 可以同时存在；&lt;/li>
&lt;li>concurrencyPolicy=Forbid，这意味着不会创建新的 Pod，该创建周期被跳过；&lt;/li>
&lt;li>concurrencyPolicy=Replace，这意味着新产生的 Job 会替换旧的、没有执行完的 Job。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#228b22"># startingDeadlineSeconds=200，意味着在过去 200 s 里，如果 miss 的数目达到了 100 次，那么这个 Job 就不会被创建执行了&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>spec.startingDeadlineSeconds 时间窗口&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>- https://pinkhello.me/posts/20-%E5%9B%9E%E6%9C%9Bk8s-%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E4%B8%8Ekubernetes%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/ - PinkHello, All Rights Reserved</description></item><item><title>19 回望K8S Kubernetes拼图</title><link>https://pinkhello.me/posts/19-%E5%9B%9E%E6%9C%9Bk8s-kubernetes%E6%8B%BC%E5%9B%BE/</link><pubDate>Tue, 16 Feb 2021 20:57:38 +0800</pubDate><guid>https://pinkhello.me/posts/19-%E5%9B%9E%E6%9C%9Bk8s-kubernetes%E6%8B%BC%E5%9B%BE/</guid><description>PinkHello https://pinkhello.me/posts/19-%E5%9B%9E%E6%9C%9Bk8s-kubernetes%E6%8B%BC%E5%9B%BE/ -&lt;h1 id="kubernetes-安装">&lt;code>kubernetes&lt;/code> 安装&lt;/h1>
&lt;h2 id="all-节点安装-docker-和-kubeadm">all 节点安装 &lt;code>Docker&lt;/code> 和 &lt;code>Kubeadm&lt;/code>&lt;/h2>
&lt;p>所有节点 &lt;code>root&lt;/code> 用户下操作&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
&amp;gt; cat &lt;span style="color:#cd5555">&amp;lt;&amp;lt;EOF &amp;gt; /etc/apt/sources.list.d/kubernetes.list
&lt;/span>&lt;span style="color:#cd5555">deb http://apt.kubernetes.io/ kubernetes-xenial main
&lt;/span>&lt;span style="color:#cd5555">EOF&lt;/span>
&amp;gt; apt-get update
&lt;span style="color:#228b22"># 这一步安装的时候 kubeadm 和 kubelet、kubectl、kubernetes-cni 都会自动安装完毕&lt;/span>
&amp;gt; apt-get install -y docker.io kubeadm
&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>提示：如果 &lt;code>apt.kubernetes.io&lt;/code> 因为网络问题访问不到，可以换成中科大的 &lt;code>Ubuntu&lt;/code> 镜像源 deb &lt;a href="http://mirrors.ustc.edu.cn/kubernetes/apt">http://mirrors.ustc.edu.cn/kubernetes/apt&lt;/a> kubernetes-xenial main。&lt;/p>
&lt;/blockquote>
&lt;h2 id="部署-kubernetes-master">部署 &lt;code>Kubernetes&lt;/code> &lt;code>Master&lt;/code>&lt;/h2>
&lt;p>声明一个 &lt;code>kubeadm.yaml&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kubeadm.k8s.io/v1alpha1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>MasterConfiguration&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">controllerManagerExtraArgs&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#228b22"># 配置了自定义自动水平扩展&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">horizontal-pod-autoscaler-use-rest-clients&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;true&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">horizontal-pod-autoscaler-sync-period&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;10s&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">node-monitor-grace-period&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;10s&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiServerExtraArgs&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">runtime-config&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;api/all=true&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#228b22"># kubeadm 部署的 kubernetes 的版本&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kubernetesVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;stable-1.11&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>···&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>执行下面的指令，完成 &lt;code>kubernetes&lt;/code> &lt;code>master&lt;/code> 部署，这回生成一行指令&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; kubeadm init --config kubeadm.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">kubeadm join 10.168.0.2:6443 --token 00bwbx.uvnaa2ewjflwu1ry --discovery-token-ca-cert-hash sha256:00eb62a2a6020f94132e3fe1ab721349bbcd3e9b94da9654cfe15f2985ebd711
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这个 &lt;code>kubeadm join&lt;/code> 命令, 用来给这个 &lt;code>Master&lt;/code> 节点添加更多的 &lt;code>Worker&lt;/code> 节点.&lt;/p>
&lt;p>另外 &lt;code>kubeadm&lt;/code> 会提示我们第一次使用 &lt;code>kubernetes&lt;/code> 集群所需要的配置命令:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; mkdir -p &lt;span style="color:#00688b">$HOME&lt;/span>/.kube
&amp;gt; sudo cp -i /etc/kubernetes/admin.conf &lt;span style="color:#00688b">$HOME&lt;/span>/.kube/config
&amp;gt; sudo chown &lt;span style="color:#8b008b;font-weight:bold">$(&lt;/span>id -u&lt;span style="color:#8b008b;font-weight:bold">)&lt;/span>:&lt;span style="color:#8b008b;font-weight:bold">$(&lt;/span>id -g&lt;span style="color:#8b008b;font-weight:bold">)&lt;/span> &lt;span style="color:#00688b">$HOME&lt;/span>/.kube/config
&lt;/code>&lt;/pre>&lt;/div>&lt;p>因为 &lt;code>Kubernetes&lt;/code> 集群默认需要加密方式访问，所以，需要将刚刚部署生成的 &lt;code>kubernetes&lt;/code> 集群安全配置文件，保存到当前用户的 &lt;code>.kube&lt;/code> 目录下, &lt;code>kubectl&lt;/code> 默认会使用这个目录下的授权信息进行访问&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22">#查看kubernetes集群的节点状态&lt;/span>
&amp;gt; kubectl get nodes
NAME STATUS ROLES AGE VERSION
master NotReady master 1d v1.11.1
&lt;span style="color:#228b22"># NotReady 因为还没有部署任何网络插件&lt;/span>
&amp;gt; kubectl describe node master
...
Conditions:
...
Ready False ... KubeletNotReady runtime network not ready: &lt;span style="color:#00688b">NetworkReady&lt;/span>=&lt;span style="color:#658b00">false&lt;/span> reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; kubectl get pods -n kube-system
NAME READY STATUS RESTARTS AGE
coredns-78fcdf6894-j9s52 0/1 Pending &lt;span style="color:#b452cd">0&lt;/span> 1h
coredns-78fcdf6894-jm4wf 0/1 Pending &lt;span style="color:#b452cd">0&lt;/span> 1h
etcd-master 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 2s
kube-apiserver-master 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 1s
kube-controller-manager-master 0/1 Pending &lt;span style="color:#b452cd">0&lt;/span> 1s
kube-proxy-xbd47 1/1 NodeLost &lt;span style="color:#b452cd">0&lt;/span> 1h
kube-scheduler-master 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 1s
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="部署-容器网络插件">部署 容器网络插件&lt;/h2>
&lt;p>在 &lt;code>kubernetes&lt;/code> 内部里面 &lt;code>一切皆容器&lt;/code> 设计方式，部署网络插件非常简单,以 &lt;code>Weave&lt;/code> 为例子&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; kubectl apply -f https://git.io/weave-kube-1.6
&lt;/code>&lt;/pre>&lt;/div>&lt;p>部署完毕后, 通过 &lt;code>kubectl get&lt;/code> 检查 &lt;code>POD&lt;/code> 状态&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; kubectl get pods -n kube-system
NAME READY STATUS RESTARTS AGE
coredns-78fcdf6894-j9s52 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 1d
coredns-78fcdf6894-jm4wf 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 1d
etcd-master 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 9s
kube-apiserver-master 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 9s
kube-controller-manager-master 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 9s
kube-proxy-xbd47 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 1d
kube-scheduler-master 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 9s
weave-net-cmk27 2/2 Running &lt;span style="color:#b452cd">0&lt;/span> 19s
&lt;/code>&lt;/pre>&lt;/div>&lt;p>而刚刚部署的 &lt;code>Weave&lt;/code> 网络插件则在 &lt;code>kube-system&lt;/code> 下面新建了一个名叫 &lt;code>weave-net-cmk27&lt;/code> 的 &lt;code>Pod&lt;/code>，一般来说，这些 &lt;code>Pod&lt;/code> 就是容器网络插件在每个节点上的控制组件。&lt;/p>
&lt;p>&lt;code>Kubernetes&lt;/code> 的支持的容器网络插件，使用的 &lt;code>CNI&lt;/code> 的通用接口，当前开源的容器网络插件有&lt;/p>
&lt;ul>
&lt;li>&lt;code>Flannel&lt;/code> 这个采用应该比较多的&lt;/li>
&lt;li>&lt;code>Calico&lt;/code>&lt;/li>
&lt;li>&lt;code>Canal&lt;/code>&lt;/li>
&lt;li>&lt;code>Romana&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="部署-kubernetes-worker">部署 &lt;code>Kubernetes&lt;/code> &lt;code>Worker&lt;/code>&lt;/h2>
&lt;p>&lt;code>Worker&lt;/code> 节点的部署 和 &lt;code>Master&lt;/code> 节点的运行的程序几乎相同, 都运行这 &lt;code>kubelet&lt;/code> 组件，唯一的区别是 &lt;code>kubelet&lt;/code> 启动后，&lt;code>Master&lt;/code> 节点需要自动运行 &lt;code>kube-apiserver&lt;/code>，&lt;code>kube-scheduler&lt;/code>，&lt;code>kube-controller-manager&lt;/code> 三个 &lt;code>Pod&lt;/code>&lt;/p>
&lt;p>执行部署&lt;code>Master&lt;/code>时候生成的 &lt;code>kubeadm join&lt;/code> 指令&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; kubeadm join 10.168.0.2:6443 --token 00bwbx.uvnaa2ewjflwu1ry --discovery-token-ca-cert-hash sha256:00eb62a2a6020f94132e3fe1ab721349bbcd3e9b94da9654cfe15f2985ebd711
&lt;/code>&lt;/pre>&lt;/div>&lt;p>通过 &lt;code>Taint/Toleration&lt;/code> 调整 &lt;code>Master&lt;/code> 执行 &lt;code>Pod&lt;/code> 的策略&lt;/p>
&lt;blockquote>
&lt;p>默认情况下 &lt;code>Master&lt;/code> 节点是不允许运行用户 &lt;code>Pod&lt;/code> 的。而 &lt;code>Kubernetes&lt;/code> 做到这一点，依靠的是 &lt;code>Kubernetes&lt;/code> 的 Taint/Toleration 机制。&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>它的原理非常简单：一旦某个节点被加上了一个 Taint，即被“打上了污点”，那么所有 Pod 就都不能在这个节点上运行，因为 Kubernetes 的 Pod 都有“洁癖”。除非，有个别的 Pod 声明自己能“容忍”这个“污点”，即声明了 Toleration，它才可以在这个节点上运行。其中，为节点打上“污点”（Taint）的命令是：kubectl taint nodes node1 foo=bar:NoSchedule&lt;/p>
&lt;/blockquote>
&lt;p>默认情况下 &lt;code>Master&lt;/code> 节点是不允许运行用户 &lt;code>Pod&lt;/code> 的, 可以通过 &lt;code>kubectl describe&lt;/code> 检查一下 &lt;code>Master&lt;/code> 节点的 &lt;code>Taint&lt;/code> 字段&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; kubectl describe node master
Name: master
Roles: master
Taints: node-role.kubernetes.io/master:NoSchedule
&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到，&lt;code>Master&lt;/code> 节点默认被加上了 &lt;code>node-role.kubernetes.io/master:NoSchedule&lt;/code> 这样一个“污点”，其中“键”是 &lt;code>node-role.kubernetes.io/master&lt;/code>，而没有提供“值”。&lt;/p>
&lt;p>当然，如果你就是想要一个单节点的 &lt;code>Kubernetes&lt;/code>，删除这个 &lt;code>Taint&lt;/code> 才是正确的选择：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22"># “node-role.kubernetes.io/master”这个键后面加上了一个短横线“-”，这个格式就意味着移除所有以“node-role.kubernetes.io/master”为键的 Taint。&lt;/span>
&amp;gt; kubectl taint nodes --all node-role.kubernetes.io/master-
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="部署-dashboard-可视化插件">部署 &lt;code>Dashboard&lt;/code> 可视化插件&lt;/h2>
&lt;p>&lt;code>Web&lt;/code> 页面展示也是一个很重要的方面，能可视化的查看集群的各种信息&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc6/aio/deploy/recommended.yaml
&amp;gt; kubectl get pods -n kube-system
kubernetes-dashboard-6948bdb78-f67xk 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 1m
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>Dashboard&lt;/code> 项目部署完成后，默认只能通过 &lt;code>Proxy&lt;/code> 的方式在本地访问&lt;/p>
&lt;h2 id="部署-容器存储插件">部署 容器存储插件&lt;/h2>
&lt;p>&lt;code>Kubernetes&lt;/code> 松耦合的设计，所以绝大多数存储项目都可以为 &lt;code>Kubernetes&lt;/code> 提供持久化存储能力.&lt;/p>
&lt;ul>
&lt;li>&lt;code>Ceph&lt;/code>&lt;/li>
&lt;li>&lt;code>GlusterFS&lt;/code>&lt;/li>
&lt;li>&lt;code>NFS&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>&lt;code>Rook&lt;/code> 插件是基于 &lt;code>Ceph&lt;/code> 的 &lt;code>Kubernetes&lt;/code> 存储插件，&lt;code>Rook&lt;/code> 在自己的实现中加入了水平扩展、迁移、灾备、监控等大量的企业级功能，这是一个完整的，可以应用在生产上的容器存储插件&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/common.yaml
&amp;gt; kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/operator.yaml
&amp;gt; kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/cluster.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>在部署完成后，你就可以看到 &lt;code>Rook&lt;/code> 项目会将自己的 &lt;code>Pod&lt;/code> 放置在由它自己管理的两个 &lt;code>Namespace&lt;/code> 当中：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; kubectl get pods -n rook-ceph-system
NAME READY STATUS RESTARTS AGE
rook-ceph-agent-7cv62 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 15s
rook-ceph-operator-78d498c68c-7fj72 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 44s
rook-discover-2ctcv 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 15s
&amp;gt; kubectl get pods -n rook-ceph
NAME READY STATUS RESTARTS AGE
rook-ceph-mon0-kxnzh 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 13s
rook-ceph-mon1-7dn2t 1/1 Running &lt;span style="color:#b452cd">0&lt;/span> 2s
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这样，一个基于 &lt;code>Rook&lt;/code> 持久化存储集群就以容器的方式运行起来了，而接下来在 &lt;code>Kubernetes&lt;/code> 项目上创建的所有 &lt;code>Pod&lt;/code> 就能够通过 &lt;code>Persistent Volume&lt;/code>（PV）和 &lt;code>Persistent Volume Claim&lt;/code>（PVC）的方式，在容器里挂载由 &lt;code>Ceph&lt;/code> 提供的数据卷了。&lt;/p>
- https://pinkhello.me/posts/19-%E5%9B%9E%E6%9C%9Bk8s-kubernetes%E6%8B%BC%E5%9B%BE/ - PinkHello, All Rights Reserved</description></item><item><title>18 回望K8S 白话容器</title><link>https://pinkhello.me/posts/18-%E5%9B%9E%E6%9C%9Bk8s-%E7%99%BD%E8%AF%9D%E5%AE%B9%E5%99%A8/</link><pubDate>Mon, 15 Feb 2021 10:16:34 +0800</pubDate><guid>https://pinkhello.me/posts/18-%E5%9B%9E%E6%9C%9Bk8s-%E7%99%BD%E8%AF%9D%E5%AE%B9%E5%99%A8/</guid><description>PinkHello https://pinkhello.me/posts/18-%E5%9B%9E%E6%9C%9Bk8s-%E7%99%BD%E8%AF%9D%E5%AE%B9%E5%99%A8/ -&lt;h1 id="进程开启">进程开启&lt;/h1>
&lt;h2 id="容器-到底是什么">容器, 到底是什么?&lt;/h2>
&lt;blockquote>
&lt;p>前面提出: 容器是一种沙盒技术. 就是一个集装箱, 把应用装起来的技术. 这样, 应用与应用之间有了边界不至于互相干扰; 有了这些集装箱, 也方便搬来搬去.&lt;/p>
&lt;/blockquote>
&lt;p>码农都知道可执行的二进制文件是代码的可执行镜像(&lt;code>executable image&lt;/code>). 一旦程序执行起来, 内存数据、寄存器的值、堆栈的指令、打开的文件等这些集合汇集成一个程序的计算机执行环境总和: 进程.&lt;/p>
&lt;p>&lt;code>进程&lt;/code>: 静态表现是程序, 动态表现计算机的数据和状态的总和。&lt;/p>
&lt;p>容器的核心功能, 就是通过约束和修改进程的动态表现, 从而为其创造一个&amp;quot;边界&amp;quot;.&lt;/p>
&lt;ul>
&lt;li>&lt;code>Cgroups 技术&lt;/code> 制造约束的主要手段&lt;/li>
&lt;li>&lt;code>Namespace 技术&lt;/code> 修改进程视图的主要方法&lt;/li>
&lt;/ul>
&lt;p>&lt;code>docker run&lt;/code> , &lt;code>-it&lt;/code> 告诉 &lt;code>Docker&lt;/code> 启动容器后, 需要分配一个文本输入/输出环境, 也就是 &lt;code>TTY&lt;/code>, 跟容器的标准输入相关联, 这样我们就可以和这个&lt;code>Docker&lt;/code>容器进行交互了。而 &lt;code>/bin/sh&lt;/code> 就是我们在 &lt;code>Docker&lt;/code> 容器里运行的程序.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; docker run -it busybox /bin/sh
/ &lt;span style="color:#228b22">#&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>帮我启动一个容器, 在容器里执行 &lt;code>/bin/sh&lt;/code>, 并且给我分配一个命令行终端跟这个容器进行交互, 在这个执行环境下可以完全执行&lt;code>LINUX&lt;/code>命令,且与宿主机完全隔离在不同的世界中.&lt;/p>
&lt;p>&lt;code>Docker&lt;/code>对被隔离应用的进程空间做了手脚, 使得这些进程只能看到重新计算的进程编号, 可是实际上, 他们在宿主机的操作系统里, 还是原来的第&lt;code>N&lt;/code>号进程. 这种技术就是&lt;code>Linux&lt;/code>内部的&lt;code>Namespace&lt;/code>机制。&lt;/p>
&lt;p>&lt;code>Namespace&lt;/code> 的使用方式也非常有意思：它其实只是 &lt;code>Linux&lt;/code> 创建新进程的一个可选参数。我们知道，在 &lt;code>Linux&lt;/code> 系统中创建线程的系统调用是 &lt;code>clone()&lt;/code>，比如：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">int &lt;span style="color:#00688b">pid&lt;/span> = clone(main_function, stack_size, SIGCHLD, NULL);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这个系统调用就会创建一个新的进程，并且返回的它的进程号 pid。&lt;/p>
&lt;p>当调用 clone() 系统调用创建一个新进程时，就可以在参数中指定 CLONE_NEWPID 参数，比如：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">int &lt;span style="color:#00688b">pid&lt;/span> = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这时，新创建的这个进程就会看到一个全新的进程空间，在这个进程空间里，他的&lt;code>PID&lt;/code>是&lt;code>1&lt;/code>，之所以说看到，是因为是一个障眼法，在宿主机真实的进程空间里，这个&lt;code>PID&lt;/code>还是真实的数值.当多次执行&lt;code>clone()&lt;/code>调用, 会创建多个 &lt;code>PID Namespace&lt;/code>, 每个 Namespace 里的应用进程，都会认为自己是当前容器里的第&lt;code>1&lt;/code>号进程，看不仅&lt;code>宿主机&lt;/code>的也看不到其他的&lt;code>Namespace&lt;/code>.&lt;/p>
&lt;blockquote>
&lt;p>备注:
Linux提供了不同的Namespace，去应对不同的进程上下文&lt;/p>
&lt;ul>
&lt;li>PID Namespace&lt;/li>
&lt;li>Mount Namespace&lt;/li>
&lt;li>IPC Namespace&lt;/li>
&lt;li>UTS Namespace&lt;/li>
&lt;li>Network Namespace&lt;/li>
&lt;li>User Namespace&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Docker容器，就是在创建容器进程时候，指定了这个进程所需要启用的一组 Namespace 参数, 这样, 容器就只能 看到 当前 Namespace 所限定的 资源、文件、设备、状态 或者 配置。所以说, 容器，其实是一种特殊的进程。&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E5%9B%9E%E6%9C%9BK8S/%E5%AE%B9%E5%99%A8%E4%B8%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.jpg" alt="容器与虚拟机工作原理">&lt;/p>
&lt;p>可以看出图中 &lt;code>Hypervisor&lt;/code> 是虚拟机主要部分。它通过硬件虚拟化功能，模拟出了运行一个操作系统需要的各种硬件，比如 CPU、内存、I/O设备等。 这样，用户的进程可以在这个虚拟的机器中，只能看到虚拟环境的文件和目录以及设备，起到隔离的作用。
而右边的图，&lt;code>Docker Engine&lt;/code>替换了&lt;code>Hypervisor&lt;/code>,但是有个核心一点&lt;code>Docker Engine&lt;/code>并不少&lt;code>轻量级&lt;/code>虚拟化技术。&lt;/p>
&lt;p>在&lt;code>Linux&lt;/code>的&lt;code>Namespace&lt;/code>工作方式后, 在使用&lt;code>Docker&lt;/code>的时候,&lt;code>Docker&lt;/code>并没有一个真正的&lt;code>Docker容器&lt;/code>运行在宿主机里面，而是&lt;code>Docker&lt;/code>启动还是原来的应用进程，只不过在创建这些进程时候，加上了各种&lt;code>Namespace&lt;/code>参数，使得这些进程觉得自己是在各自的&lt;code>PID Namespace&lt;/code>是第一号进程，并且只能看到各自&lt;code>Mount Namespace&lt;/code>里挂在的目录和文件、只能访问各自&lt;code>Network Namespace&lt;/code>里的网络设备.&lt;/p>
&lt;h1 id="隔离和限制">隔离和限制&lt;/h1>
&lt;p>前面提到实现 &lt;code>隔离&lt;/code> 的手段: &lt;code>Namespace&lt;/code>. &lt;code>Namespace&lt;/code> 技术实际修改了应用进程看待整个计算机的&amp;quot;视图&amp;quot;，即它的&amp;quot;视线&amp;quot;被操作系统做了限制，只能&amp;quot;看到&amp;quot;某些知道的内容.&lt;/p>
&lt;h2 id="为什么需要隔离">为什么需要&lt;code>隔离&lt;/code>&lt;/h2>
&lt;ul>
&lt;li>首先，既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。&lt;/li>
&lt;li>在Linux内核中，还有许多资源和对象是不能被 Namespace 化的，最典型的例子是：时间
&lt;blockquote>
&lt;p>容器中使用 settimeofday(2) 系统调用修改了时间，整个宿主机的时间都会被随之修改。这样肯定与预期不符&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;/ul>
&lt;h2 id="上述是为什么要隔离下面说为什么要限制这个问题">上述是为什么要&lt;code>隔离&lt;/code>，下面说为什么要&lt;code>限制&lt;/code>这个问题。&lt;/h2>
&lt;blockquote>
&lt;p>在宿主机上,启动多个容器都是在宿主机上的特殊进程,但是在不同的进程之间, 资源（CPU、内存）还是可能被其他进程（或者容器）占用的。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;code>Linux Cgroups&lt;/code>全称&lt;code>Linux Control Group&lt;/code> 就是 Linux 内核中用来为进程设置资源限制的一个重要功能, 限制一个进程组能够使用的资源上限, 包括 CPU、内存、磁盘、网络带宽 等等。此外 &lt;code>Cgroups&lt;/code> 还能够对进程进行优先级设置、审计，以及将进程挂起和恢复操作。&lt;/p>
&lt;p>在&lt;code>Linux&lt;/code>中,&lt;code>Cgroups&lt;/code>给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 &lt;code>/sys/fs/cgroup&lt;/code> 路径下&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22"># Ubuntu 下 mount 指令展示出来&lt;/span>
&amp;gt; mount -t cgroup
cpuset on /sys/fs/cgroup/cpuset &lt;span style="color:#658b00">type&lt;/span> cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)
cpu on /sys/fs/cgroup/cpu &lt;span style="color:#658b00">type&lt;/span> cgroup (rw,nosuid,nodev,noexec,relatime,cpu)
cpuacct on /sys/fs/cgroup/cpuacct &lt;span style="color:#658b00">type&lt;/span> cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct)
blkio on /sys/fs/cgroup/blkio &lt;span style="color:#658b00">type&lt;/span> cgroup (rw,nosuid,nodev,noexec,relatime,blkio)
memory on /sys/fs/cgroup/memory &lt;span style="color:#658b00">type&lt;/span> cgroup (rw,nosuid,nodev,noexec,relatime,memory)
...
&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到在 &lt;code>/sys/fs/cgroup&lt;/code> 下面又很多诸如&lt;code>cpuset&lt;/code>、&lt;code>cpu&lt;/code>、&lt;code>memory&lt;/code>这样的子目,也叫子系统.这些都是可以被&lt;code>Cgroups&lt;/code>进行限制的资源种类,而在子系统对应的资源种类下, 你就可以看到该类资源具体可以被限制的方法。比如, 对&lt;code>CPU&lt;/code>子系统来说，我们就可以看到几个配置文件，这个指令是：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; ls /sys/fs/cgroup/cpu
cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us cpu.shares notify_on_release
cgroup.procs cpu.cfs_quota_us cpu.rt_runtime_us cpu.stat tasks
&lt;/code>&lt;/pre>&lt;/div>&lt;p>输出中&lt;code>cfs_period&lt;/code>和&lt;code>cfs_quota&lt;/code>这样的关键词。组合使用,限制进程在长度为&lt;code>cfs_period&lt;/code>的一段时间内,只能被分配到总量为&lt;code>cfs_quota&lt;/code>的&lt;code>CPU&lt;/code>时间&lt;/p>
&lt;p>如何使用&lt;code>cgroups&lt;/code>呢？&lt;/p>
&lt;p>在对应的子系统的下面创建一个目录，比如限制CPU进入 &lt;code>/sys/fs/cgroups/cpu&lt;/code> 目录下&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; &lt;span style="color:#658b00">cd&lt;/span> /sys/fs/cgroups/cpu
&amp;gt; mkdir container
&amp;gt; ls container/
cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us cpu.shares notify_on_releasecgroup.procs cpu.cfs_quota_us cpu.rt_runtime_us cpu.stat tasks
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这个目录就称为一个控制组，操作系统自动在新创建的 &lt;code>container&lt;/code> 目录下，自动生成该子系统的对应的资源限制文件.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22"># 查看 container 控制组的 CPU quota 还没有任何限制：-1，CPU period 则是默认的 100 ms (100000 us)&lt;/span>
&amp;gt; cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us
-1
&amp;gt; cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us
&lt;span style="color:#b452cd">100000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>向 &lt;code>container&lt;/code> 组里的 &lt;code>cfs_quota&lt;/code> 文件写入 20 ms（20000 us）&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22">#意味着在每 100 ms 的时间里，被该控制组限制的进程只能使用 20 ms 的 CPU 时间，也就是说这个进程只能使用到 20% 的 CPU 带宽。&lt;/span>
&amp;gt; &lt;span style="color:#658b00">echo&lt;/span> &lt;span style="color:#b452cd">20000&lt;/span> &amp;gt; /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us
&lt;span style="color:#228b22"># 现在把需要被限制的进程的 PID 写入 container 组里的 tasks 文件，上面的设置就会对该进程生效了&lt;/span>
&amp;gt; &lt;span style="color:#658b00">echo&lt;/span> &lt;span style="color:#cd5555">${&lt;/span>&lt;span style="color:#00688b">需要限制的进程PID&lt;/span>&lt;span style="color:#cd5555">}&lt;/span> &amp;gt; /sys/fs/cgroup/cpu/container/tasks
&lt;span style="color:#228b22"># top 指令查看, 计算机CPU使用率立刻降低到20%&lt;/span>
&amp;gt; top
%Cpu0 : 20.3 us, 0.0 sy, 0.0 ni, 79.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这样, &lt;code>Cgroups&lt;/code> 的每一个子系统都有其独有的资源限制能力&lt;/p>
&lt;ul>
&lt;li>&lt;code>cpu&lt;/code>, 为进程设定&lt;code>cpu&lt;/code>使用的限制;&lt;/li>
&lt;li>&lt;code>blkio&lt;/code>, 为块设备设定 I/O 限制, 一般用户磁盘等设备;&lt;/li>
&lt;li>&lt;code>cpuset&lt;/code>, 为进程分配单独的 CPU核和对应的内存节点;&lt;/li>
&lt;li>&lt;code>memory&lt;/code>, 为进程设定内存使用的限制&lt;/li>
&lt;/ul>
&lt;p>&lt;code>Linux Cgroups&lt;/code>的设计，它就是&lt;code>一个子系统的目录加上一组资源限制文件的组合&lt;/code>。而对于&lt;code>Docker&lt;/code>等&lt;code>Linux&lt;/code>容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组(即创建一个新目录), 然后在启动进程之后，把这个进程的&lt;code>PID&lt;/code>写到对应的控制组的&lt;code>tasks&lt;/code>文件中.&lt;/p>
&lt;p>那么在&lt;code>Docker&lt;/code>容器中，如何启动的时候知道控制组下面的资源如何使用呢？&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22"># docker run 时的参数指定&lt;/span>
&amp;gt; docker run -it --cpu-period=&lt;span style="color:#b452cd">100000&lt;/span> --cpu-quota=&lt;span style="color:#b452cd">20000&lt;/span> ubuntu /bin/bash
&lt;/code>&lt;/pre>&lt;/div>&lt;p>在启动这个容器后，我们可以通过 &lt;code>Cgroups&lt;/code> 文件系统下，&lt;code>CPU&lt;/code>子系统中, &lt;code>docker&lt;/code>这个控制组里的资源限制文件内容来确认：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_period_us
&lt;span style="color:#b452cd">100000&lt;/span>
&amp;gt; cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_quota_us
&lt;span style="color:#b452cd">20000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这就意味着这个&lt;code>Docker&lt;/code>容器,只能使用到 &lt;code>20%&lt;/code> 的&lt;code>CPU带宽&lt;/code>&lt;/p>
&lt;p>核心概念：&lt;/p>
&lt;blockquote>
&lt;p>容器就是一个&lt;code>单进程&lt;/code>模型. 一个正在运行的&lt;code>Docker&lt;/code>容器,其实就是启用了多个&lt;code>Linux Namespace&lt;/code>的应用进程,而这个进程能够使用的资源量,则受&lt;code>Cgroups&lt;/code>配置的限制&lt;/p>
&lt;/blockquote>
&lt;p>一个容器的本质是一个进程, 用户的应用进程实际上就是容器的&lt;code>PID=1&lt;/code>的进程, 也是其他后续创建所有进程的父进程。这就意味着，在一个容器中，你没有办法同时运行两个不同的应用，除非你能事先找到公共的&lt;code>PID=1&lt;/code>的程序充当两个不同应用的父进程，这就是为什么很多会使用&lt;code>systemd&lt;/code>或者&lt;code>supervisord&lt;/code>代理应用本身作为容器的启动进程。&lt;/p>
&lt;p>容器的本身设计，希望容器和应用能够同生命周期，这个对后续的容器编排非常重要。&lt;/p>
&lt;p>&lt;code>Linux&lt;/code>下的&lt;code>/proc&lt;/code>目录存储的是纪录当前内核运行状态的一些列特殊文件，用户可以通过访问这些文件，查看系统以及当前正在运行的进程的信息, 比如 CPU使用、内存占用，&lt;code>top&lt;/code>指令查看系统信息的主要数据来源. 在容器中执行 top 指令, 发现宿主机的CPU和内存的数据，不是当前容器的数据。&lt;/p>
&lt;blockquote>
&lt;p>造成这个问题的原因就是，&lt;code>/proc&lt;/code> 文件系统并不知道用户通过 &lt;code>Cgroups&lt;/code> 给这个容器做了什么样的资源限制，即：&lt;code>/proc&lt;/code> 文件系统不了解 &lt;code>Cgroups&lt;/code> 限制的存在。
当然可以借助其他 &lt;code>lxcfs&lt;/code> 可解决此问题&lt;/p>
&lt;/blockquote>
&lt;h1 id="容器镜像">容器镜像&lt;/h1>
&lt;h2 id="容器中的进程看到的文件系统又是什么样子的呢">容器中的进程看到的文件系统又是什么样子的呢？&lt;/h2>
&lt;p>嘿嘿, &lt;code>Mount Namespace&lt;/code> 开启后，容器进行看到的文件系统也跟宿主机完全一样。&lt;code>Mount Namespace&lt;/code> 修改的，是容器进程对文件系统&amp;quot;挂载点&amp;quot;的认知。&lt;code>Mount Namespace&lt;/code> 跟其他的 &lt;code>Namespace&lt;/code> 的使用略有不同的地方：它对容器进程视图的改变，一定是伴随着挂载操作（&lt;code>mount&lt;/code>）才能生效。&lt;/p>
&lt;p>在&lt;code>Linux&lt;/code>操作系统中，有一个 &lt;code>chroot&lt;/code> 的命令：&lt;code>change root file system&lt;/code>， 改变进程的根目录到你指定的位置。这个 &lt;code>Mount Namespace&lt;/code> 正是基于对 &lt;code>chroot&lt;/code> 的不断改良的，也是 &lt;code>Linux&lt;/code> 操作系统里第一个 &lt;code>Namespace&lt;/code>。
而挂载在容器根目录上，用来为容器进程提供隔离后执行环境的文件系统，就是所谓的容器镜像。它还有一个更专业的名字叫做 &lt;code>rootfs&lt;/code>（根文件系统）&lt;/p>
&lt;p>一个常见的 &lt;code>rootfs&lt;/code>，包含一些目录和文件:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; ls /
bin dev etc home lib lib64 mnt opt proc root run sbin sys tmp usr var
&lt;/code>&lt;/pre>&lt;/div>&lt;p>而进入容器之后执行的 &lt;code>/bin/bash&lt;/code>, 就是 &lt;code>/bin&lt;/code> 目录下的可执行文件, 与宿主机的 &lt;code>/bin/bash&lt;/code> 完全不同。&lt;/p>
&lt;p>对于 &lt;code>Docker&lt;/code> 项目来说，它最核心的原理就是为带创建的用户进程：&lt;/p>
&lt;ul>
&lt;li>启用 &lt;code>Linux Namespace&lt;/code> 配置；&lt;/li>
&lt;li>设置指定的 &lt;code>Cgroups&lt;/code> 参数；&lt;/li>
&lt;li>切换进程的根目录（&lt;code>Change Root&lt;/code>）.&lt;/li>
&lt;/ul>
&lt;p>这样，一个完整的容器就诞生了。不过，在&lt;code>Docker&lt;/code>项目在最后一步的切换上优先使用&lt;code>pivot_root&lt;/code>系统调用,如果系统不支持，才会使用&lt;code>chroot&lt;/code>。&lt;/p>
&lt;p>&lt;code>rootfs&lt;/code>只是操作系统所包含的文件、配置和目录，并不包含操作系统内核。在&lt;code>Linux&lt;/code>操作系统中，这两部分分开存放的。操作系统只在开机启动的时候才会加载指定版本的内核镜像。
所以说&lt;code>rootfs&lt;/code>只是操作系统的&amp;quot;躯壳&amp;quot;，并没有操作系统的&amp;quot;灵魂&amp;quot;，同一台机器的所有容器，都共享宿主机操作系统的内核。因为共享的宿主机内核，应用程序需要配置的内核参数、加载额外的内核模块，以及跟内核进行的直接交互。内核相对于主机上所有容器的是一个全局变量，牵一发而动全身。&lt;/p>
&lt;p>由于&lt;code>rootfs&lt;/code>的存在,容器有了最重要的特性: 一致性&lt;/p>
&lt;h2 id="什么是容器的一致性呢">什么是容器的一致性呢？&lt;/h2>
&lt;p>在开发过程中、本地环境、云环境、打包是一个十分痛苦的过程（对于&lt;code>PAAS&lt;/code>环境来说），有了容器镜像（&lt;code>rootfs&lt;/code>）之后，优雅的解决了这个问题。&lt;/p>
&lt;blockquote>
&lt;p>由于 &lt;code>rootfs&lt;/code> 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着应用以及它运行的所需要的所有依赖，都被封装在一起。&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>对于一个应用来说，操作系统本身才是它运行所需要的完整的&amp;quot;依赖库&amp;quot;，有了容器镜像打包操作系统的能力，这个最基础的依赖环境也终于变成了应用沙盒的一部分。这就赋予了容器的一致性：无论在本地、云端，还是在任何地方的机器上，用户只需要解压打包好的容器镜像，这样这个应用所需要的完整的执行环境就被重现出来了。&lt;/p>
&lt;/blockquote>
&lt;h2 id="如何解决每次升级如何解决重复制作-rootfs-的问题呢">如何解决每次升级，如何解决重复制作 &lt;code>rootfs&lt;/code> 的问题呢？&lt;/h2>
&lt;p>&lt;code>Docker&lt;/code>公司实现&lt;code>Docker&lt;/code>镜像的时候没有使用重制作&lt;code>rootfs&lt;/code>流程，而是在&lt;code>Docker&lt;/code>在镜像的设计中，引入了层（&lt;code>layer&lt;/code>）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量的&lt;code>rootfs&lt;/code>.&lt;/p>
&lt;p>联合文件系统(&lt;code>Union File System&lt;/code>) &lt;code>UnionFS&lt;/code>, 最主要的功能是将不同位置的目录联合挂载（&lt;code>union mount&lt;/code>）到同一个目录下。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; tree
.
|- A
| |- a
| |- x
|--- B
|-- b
|-- x
&lt;span style="color:#228b22"># 联合挂载，两个目录挂载到公共目录C上&lt;/span>
&amp;gt; mkdir C
&amp;gt; mount -t aufs -o &lt;span style="color:#00688b">dirs&lt;/span>=./A:./B none ./C
&lt;span style="color:#228b22"># 展示C文件&lt;/span>
&amp;gt; tree ./C
./C
|-- a
|-- b
|-- x
&lt;span style="color:#228b22"># 此时对 C 里的文件进行修改，在目录 A 和 B 中都会生效&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="docker-layer概念">&lt;code>docker&lt;/code> &lt;code>layer&lt;/code>概念&lt;/h2>
&lt;p>关键目录:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">/var/lib/docker/aufs/diff/&amp;lt;layer_id&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22"># 拉取ubuntu镜像&lt;/span>
&amp;gt; docker pull ubuntu:latest
&lt;span style="color:#228b22"># 展示image的层&lt;/span>
&amp;gt; docker image inspect ubuntu:latest
...
&lt;span style="color:#cd5555">&amp;#34;RootFS&amp;#34;&lt;/span>: {
&lt;span style="color:#cd5555">&amp;#34;Type&amp;#34;&lt;/span>: &lt;span style="color:#cd5555">&amp;#34;layers&amp;#34;&lt;/span>,
&lt;span style="color:#cd5555">&amp;#34;Layers&amp;#34;&lt;/span>: [
&lt;span style="color:#cd5555">&amp;#34;sha256:f49017d4d5ce9c0f544c...&amp;#34;&lt;/span>,
&lt;span style="color:#cd5555">&amp;#34;sha256:8f2b771487e9d6354080...&amp;#34;&lt;/span>,
&lt;span style="color:#cd5555">&amp;#34;sha256:ccd4d61916aaa2159429...&amp;#34;&lt;/span>,
&lt;span style="color:#cd5555">&amp;#34;sha256:c01d74f99de40e097c73...&amp;#34;&lt;/span>,
&lt;span style="color:#cd5555">&amp;#34;sha256:268a067217b5fe78e000...&amp;#34;&lt;/span>
]
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>ubuntu&lt;/code>镜像的是五层组成，这五层就是5个增量 &lt;code>rootfs&lt;/code>,每一层都是 &lt;code>ubuntu&lt;/code> 操作系统文件与目录的一部分; 而在使用镜像时, &lt;code>Docker&lt;/code> 会把这些增量的联合挂载在一个统一的挂载点上。挂载点就是 &lt;code>/var/lib/docker/aufs/mnt/&lt;/code>,比如:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">/var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fcfa2a2f5c89dc21ee30e166be823ceaeba15dce645b3e
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22"># 这个目录下是一个完整的 ubuntu 操作系统&lt;/span>
&amp;gt; ls /var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fcfa2a2f5c89dc21ee30e166be823ceaeba15dce645b3e
bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var
&lt;/code>&lt;/pre>&lt;/div>&lt;p>前面的五个镜像层，如何被挂载到这样一个完整的&lt;code>Ubuntu&lt;/code>的文件系统的呢？这个信息纪录在 &lt;code>AuFS&lt;/code> 的系统目录 &lt;code>/sys/fs/aufs&lt;/code> 下面。查看 &lt;code>AuFS&lt;/code> 的挂载信息, 我们可以找到这个目录对应的 &lt;code>AuFS&lt;/code> 的内部ID（也叫&lt;code>si&lt;/code>），&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22"># si=972c6d361e6b32ba&lt;/span>
&amp;gt; cat /proc/mounts| grep aufs
none /var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fc... aufs rw,relatime,si=972c6d361e6b32ba,dio,dirperm1 &lt;span style="color:#b452cd">0&lt;/span> &lt;span style="color:#b452cd">0&lt;/span>
&lt;span style="color:#228b22"># 查看被联合挂载在一起的各个层的信息&lt;/span>
&amp;gt; cat /sys/fs/aufs/si_972c6d361e6b32ba/br[0-9]*
/var/lib/docker/aufs/diff/6e3be5d2ecccae7cc...=rw
/var/lib/docker/aufs/diff/6e3be5d2ecccae7cc...-init=ro+wh
/var/lib/docker/aufs/diff/32e8e20064858c0f2...=ro+wh
/var/lib/docker/aufs/diff/2b8858809bce62e62...=ro+wh
/var/lib/docker/aufs/diff/20707dce8efc0d267...=ro+wh
/var/lib/docker/aufs/diff/72b0744e06247c7d0...=ro+wh
/var/lib/docker/aufs/diff/a524a729adadedb90...=ro+wh
&lt;span style="color:#228b22"># 镜像的层都放置在 `/var/lib/docker/aufs/diff` 目录下，然后被联合挂载在 `/var/lib/docker/aufs/mnt` 里面 &lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="https://pinkhello.me/%E5%9B%9E%E6%9C%9BK8S/ubuntu-layer.png" alt="容器的rootfs的展示">&lt;/p>
&lt;ul>
&lt;li>第一部分: 只读层
&lt;blockquote>
&lt;p>它是这个容器 &lt;code>rootfs&lt;/code> 最下面的 5 层, 对应的正是 &lt;code>ubuntu&lt;/code> 镜像的五层.他们的挂载方式都是只读的（ro+wh readonly+whiteout）&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>第二部分: 可读写层
&lt;blockquote>
&lt;p>它是这个容器的 &lt;code>rootfs&lt;/code> 最上面的一层（6e3be5d2ecccae7cc），它的挂载方式为：&lt;code>rw&lt;/code> （read write）, 在这个容器中进行修改产生的内容就会以增量的方式出现在这一层。
假如删除只读层的一个文件呢？这时候 &lt;code>AuFS&lt;/code> 在可读写层创建了一个 &lt;code>whiteout&lt;/code> 文件，把只读层里的文件 遮挡 起来了。对上层来说，这个文件就是不可见的。
这边可读写层的作用就是存放我们自己修改后的 &lt;code>rootfs&lt;/code> 后产生的增量，无论增删改都在此处处理，增量的 &lt;code>rootfs&lt;/code>&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>第三部分: &lt;code>Init&lt;/code> 层
&lt;blockquote>
&lt;p>它是以&amp;quot;-init&amp;quot;结尾的层，夹在只读层和读写层之间, &lt;code>Init&lt;/code> 层是&lt;code>Docker&lt;/code>项目单独生成的内部层，专门用来存放 &lt;code>/etc/hosts&lt;/code>、&lt;code>/etc/resolv.conf&lt;/code> 等信息，这些文件本来属于只读的&lt;code>Ubuntu&lt;/code>镜像一部分，但用户往往需要在启动的时候写入一定指定的值 &lt;code>hostname&lt;/code>，用户可以在可读写层对他们进行修改。&lt;/p>
&lt;p>可是我们修改往往只对当前容器生效，我们并不希望执行 &lt;code>docker commit&lt;/code> 时，把这些信息连同可读写层一起提交掉。所以&lt;code>Docker&lt;/code>的做法，时修改的这些文件以后，以一个单独的层挂载出来，而用户执行的 &lt;code>docker commit&lt;/code> 只会提交可读写层，所以不会包含这些内容。&lt;/p>
&lt;p>最终这 7 层都被联合挂载到 &lt;code>/var/lib/docker/aufs/mnt&lt;/code> 目录下&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;/ul>
&lt;h1 id="docker容器">&lt;code>Docker&lt;/code>容器&lt;/h1>
&lt;h2 id="docker-如何实现容器的">docker 如何实现容器的&lt;/h2>
&lt;ul>
&lt;li>&lt;code>Linux Namespace&lt;/code> 隔离能力&lt;/li>
&lt;li>&lt;code>Linux Cgroups&lt;/code> 限制能力&lt;/li>
&lt;li>基于 &lt;code>rootfs&lt;/code> 文件系统的增量实现&lt;/li>
&lt;/ul>
&lt;h2 id="开发的应用的如何容器化的步骤">开发的应用的如何容器化的步骤&lt;/h2>
&lt;h3 id="1dockerfile-制作容器镜像">1、&lt;code>Dockerfile&lt;/code> 制作容器镜像&lt;/h3>
&lt;p>制作&lt;code>rootfs&lt;/code>过程，&lt;code>Docker&lt;/code>提供了一个便捷的方式: &lt;code>Dockerfile&lt;/code>&lt;/p>
&lt;p>举例个写个 &lt;code>app.py&lt;/code>, 使用 &lt;code>Flask&lt;/code> 启动一个&lt;code>Web&lt;/code>服务器。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#8b008b;font-weight:bold">from&lt;/span> &lt;span style="color:#008b45;text-decoration:underline">flask&lt;/span> &lt;span style="color:#8b008b;font-weight:bold">import&lt;/span> Flask
&lt;span style="color:#8b008b;font-weight:bold">import&lt;/span> &lt;span style="color:#008b45;text-decoration:underline">socket&lt;/span>
&lt;span style="color:#8b008b;font-weight:bold">import&lt;/span> &lt;span style="color:#008b45;text-decoration:underline">os&lt;/span>
app = Flask(__name__)
&lt;span style="color:#707a7c">@app.route&lt;/span>(&lt;span style="color:#cd5555">&amp;#39;/&amp;#39;&lt;/span>)
&lt;span style="color:#8b008b;font-weight:bold">def&lt;/span> &lt;span style="color:#008b45">hello&lt;/span>():
html = &lt;span style="color:#cd5555">&amp;#34;&amp;lt;h3&amp;gt;Hello {name}!&amp;lt;/h3&amp;gt;&amp;#34;&lt;/span> \
&lt;span style="color:#cd5555">&amp;#34;&amp;lt;b&amp;gt;Hostname:&amp;lt;/b&amp;gt; {hostname}&amp;lt;br/&amp;gt;&amp;#34;&lt;/span>
&lt;span style="color:#8b008b;font-weight:bold">return&lt;/span> html.format(name=os.getenv(&lt;span style="color:#cd5555">&amp;#34;NAME&amp;#34;&lt;/span>, &lt;span style="color:#cd5555">&amp;#34;world&amp;#34;&lt;/span>), hostname=socket.gethostname())
&lt;span style="color:#8b008b;font-weight:bold">if&lt;/span> __name__ == &lt;span style="color:#cd5555">&amp;#34;__main__&amp;#34;&lt;/span>:
app.run(host=&lt;span style="color:#cd5555">&amp;#39;0.0.0.0&amp;#39;&lt;/span>, port=&lt;span style="color:#b452cd">80&lt;/span>)
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22"># 展示 Python 依赖的关系&lt;/span>
&amp;gt; cat requirements.txt
Flask
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-dockerfile" data-lang="dockerfile">&lt;span style="color:#228b22"># 使用官方 python镜像&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">FROM&lt;/span>&lt;span style="color:#cd5555"> python&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#228b22"># 切换工作目录&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">WORKDIR&lt;/span>&lt;span style="color:#cd5555"> /app&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#228b22"># 将当前目录下内容复制到 /app&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ADD&lt;/span> . /app&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#228b22"># 按照应用依赖&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">RUN&lt;/span> pip install -r requirements.txt&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#228b22"># 允许外界访问容器80端口&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">EXPOSE&lt;/span>&lt;span style="color:#cd5555"> 80&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#228b22"># 设置环境变量&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ENV&lt;/span> NAME helloworld&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#228b22"># 启动python应用&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;span style="color:#a61717;background-color:#e3d2d2">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">CMD&lt;/span> [&lt;span style="color:#cd5555">&amp;#34;python&amp;#34;&lt;/span>,&lt;span style="color:#cd5555">&amp;#34;app.py&amp;#34;&lt;/span>]&lt;span style="color:#a61717;background-color:#e3d2d2">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>有了 Dockerfile 可以进行 Docker 镜像的制作&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22"># 使用dockerfile打一个 名为 helloworld 的镜像&lt;/span>
&amp;gt; docker build -t helloword .
&lt;span style="color:#228b22"># 展示docker&lt;/span>
&amp;gt; docker image ls
REPOSITORY TAG IMAGE ID
helloworld latest 654286cdf963
&lt;span style="color:#228b22"># 启动一个容器 8080 映射 80&lt;/span>
&amp;gt; docker run -p 8080:80 helloword
&lt;span style="color:#228b22"># docker push&lt;/span>
&lt;span style="color:#228b22"># docker tag&lt;/span>
&amp;gt; docker inspect --format &lt;span style="color:#cd5555">&amp;#39;{{ .State.Pid }}&amp;#39;&lt;/span> 4ddf4638572d
&lt;span style="color:#b452cd">25686&lt;/span>
&lt;span style="color:#228b22"># 可以看到，一个进程的每种 Linux Namespace，都在它对应的 /proc/[进程号]/ns 下有一个对应的虚拟文件，并且链接到一个真实的 Namespace 文件上。&lt;/span>
&amp;gt; ls -l /proc/25686/ns
total &lt;span style="color:#b452cd">0&lt;/span>
lrwxrwxrwx &lt;span style="color:#b452cd">1&lt;/span> root root &lt;span style="color:#b452cd">0&lt;/span> Aug &lt;span style="color:#b452cd">13&lt;/span> 14:05 cgroup -&amp;gt; cgroup:[4026531835]
lrwxrwxrwx &lt;span style="color:#b452cd">1&lt;/span> root root &lt;span style="color:#b452cd">0&lt;/span> Aug &lt;span style="color:#b452cd">13&lt;/span> 14:05 ipc -&amp;gt; ipc:[4026532278]
lrwxrwxrwx &lt;span style="color:#b452cd">1&lt;/span> root root &lt;span style="color:#b452cd">0&lt;/span> Aug &lt;span style="color:#b452cd">13&lt;/span> 14:05 mnt -&amp;gt; mnt:[4026532276]
lrwxrwxrwx &lt;span style="color:#b452cd">1&lt;/span> root root &lt;span style="color:#b452cd">0&lt;/span> Aug &lt;span style="color:#b452cd">13&lt;/span> 14:05 net -&amp;gt; net:[4026532281]
lrwxrwxrwx &lt;span style="color:#b452cd">1&lt;/span> root root &lt;span style="color:#b452cd">0&lt;/span> Aug &lt;span style="color:#b452cd">13&lt;/span> 14:05 pid -&amp;gt; pid:[4026532279]
lrwxrwxrwx &lt;span style="color:#b452cd">1&lt;/span> root root &lt;span style="color:#b452cd">0&lt;/span> Aug &lt;span style="color:#b452cd">13&lt;/span> 14:05 pid_for_children -&amp;gt; pid:[4026532279]
lrwxrwxrwx &lt;span style="color:#b452cd">1&lt;/span> root root &lt;span style="color:#b452cd">0&lt;/span> Aug &lt;span style="color:#b452cd">13&lt;/span> 14:05 user -&amp;gt; user:[4026531837]
lrwxrwxrwx &lt;span style="color:#b452cd">1&lt;/span> root root &lt;span style="color:#b452cd">0&lt;/span> Aug &lt;span style="color:#b452cd">13&lt;/span> 14:05 uts -&amp;gt; uts:[4026532277]
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这也就意味着：一个进程，可以选择加入到某个进程已有的 &lt;code>Namespace&lt;/code> 当中，从而达到“进入”这个进程所在容器的目的，这正是 &lt;code>docker exec&lt;/code> 的实现原理。&lt;/p>
&lt;h3 id="2volume-机制允许将宿主机上的指定的目录或者文件挂载到容器里面进行读取和修改">2、&lt;code>Volume&lt;/code> 机制，允许将宿主机上的指定的目录或者文件挂载到容器里面进行读取和修改&lt;/h3>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&amp;gt; docker run -v /test ...
&amp;gt; docker run -v /home:/test ...
&lt;/code>&lt;/pre>&lt;/div>&lt;p>只不过，在第一种情况下，由于你并没有显示声明宿主机目录，那么 &lt;code>Docker&lt;/code> 就会默认在宿主机上创建一个临时目录 &lt;code>/var/lib/docker/volumes/[VOLUME_ID]/_data&lt;/code>，然后把它挂载到容器的 &lt;code>/test&lt;/code> 目录上。而在第二种情况下，&lt;code>Docker&lt;/code> 就直接把宿主机的 &lt;code>/home&lt;/code> 目录挂载到容器的 &lt;code>/test&lt;/code> 目录上。&lt;/p>
&lt;p>当容器进程被创建之后，尽管开启了 &lt;code>Mount Namespace&lt;/code>，但是在它执行 &lt;code>chroot&lt;/code>（或者 &lt;code>pivot_root&lt;/code>）之前，容器进程一直可以看到宿主机上的整个文件系统。&lt;/p>
&lt;p>而宿主机上的文件系统，也自然包括了我们要使用的容器镜像。这个镜像的各个层，保存在 &lt;code>/var/lib/docker/aufs/diff&lt;/code> 目录下，在容器进程启动后，它们会被联合挂载在 &lt;code>/var/lib/docker/aufs/mnt/&lt;/code> 目录中，这样容器所需的 &lt;code>rootfs&lt;/code> 就准备好了。&lt;/p>
&lt;p>所以，我们只需要在 &lt;code>rootfs&lt;/code> 准备好之后，在执行 &lt;code>chroot&lt;/code> 之前，把 &lt;code>Volume&lt;/code> 指定的宿主机目录（比如 &lt;code>/home&lt;/code> 目录），挂载到指定的容器目录（比如 &lt;code>/test&lt;/code> 目录）在宿主机上对应的目录（即 &lt;code>/var/lib/docker/aufs/mnt/[可读写层 ID]/test&lt;/code>）上，这个 &lt;code>Volume&lt;/code> 的挂载工作就完成了。&lt;/p>
&lt;p>更重要的是，由于执行这个挂载操作时，“容器进程”已经创建了，也就意味着此时 &lt;code>Mount Namespace&lt;/code> 已经开启了。所以，这个挂载事件只在这个容器里可见。你在宿主机上，是看不见容器内部的这个挂载点的。这就保证了容器的隔离性不会被 &lt;code>Volume&lt;/code> 打破。&lt;/p>
&lt;p>而这里要使用到的挂载技术，就是 &lt;code>Linux&lt;/code> 的绑定挂载（&lt;code>bind mount&lt;/code>）机制。它的主要作用就是，允许你将一个目录或者文件，而不是整个设备，挂载到一个指定的目录上。并且，这时你在该挂载点上进行的任何操作，只是发生在被挂载的目录或者文件上，而原挂载点的内容则会被隐藏起来且不受影响。&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E5%9B%9E%E6%9C%9BK8S/python-app-image.jpg" alt="应用的镜像">&lt;/p>
&lt;h1 id="kubernetes-本质">&lt;code>Kubernetes&lt;/code> 本质&lt;/h1>
&lt;h2 id="回顾">回顾&lt;/h2>
&lt;p>一个容器：&lt;code>Linux Namespace&lt;/code>、&lt;code>Linux Cgroups&lt;/code>、 &lt;code>rootfs&lt;/code> 三种技术构建的进程隔离环境。&lt;/p>
&lt;p>一个正在允许的 &lt;code>Linux&lt;/code> 的容器:&lt;/p>
&lt;ul>
&lt;li>一组联合挂载在 &lt;code>/var/lib/docker/aufs/mnt&lt;/code> 上的 &lt;code>rootfs&lt;/code>, 容器的静态视图（容器镜像）&lt;/li>
&lt;li>一个有 &lt;code>Namespace&lt;/code> + &lt;code>Cgroups&lt;/code> 构成的隔离环境，容器的动态视图（容器运行时）&lt;/li>
&lt;/ul>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>在整个开发流程中 &amp;ldquo;开发 - 测试 - 发布&amp;rdquo;，真正承载容器信息传递的是&lt;code>容器镜像&lt;/code>！然而云计算商想要与全部用户关联起来，那么只有通过&lt;code>容器镜像&lt;/code>。
容器只是开发者手里的小工具，但是想从容器进入容器云的方式，就需要 &lt;code>容器编排&lt;/code> 技术.&lt;/p>
&lt;h2 id="容器编排技术">&lt;code>容器编排&lt;/code>技术&lt;/h2>
&lt;p>大战之后，Kubernetes 应运而生&lt;/p>
&lt;h3 id="kubernetes-顶层设计">Kubernetes 顶层设计&lt;/h3>
&lt;ul>
&lt;li>编排、调度、容器云、集群管理&lt;/li>
&lt;li>路由网关、水平扩展、监控、备份、灾难恢复&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://pinkhello.me/%E5%9B%9E%E6%9C%9BK8S/kubernetes-%E6%9E%B6%E6%9E%84.png" alt="kubernetes架构">&lt;/p>
&lt;p>Kubernetes 是由 Master 和 Node 两种节点，控制节点 与 计算节点&lt;/p>
&lt;ul>
&lt;li>控制节点（三个组件）
&lt;ul>
&lt;li>kube-apiserver 负责API服务&lt;/li>
&lt;li>kube-scheduler 负责调度&lt;/li>
&lt;li>kube-controller-manager 负责容器编排&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>计算节点
&lt;ul>
&lt;li>核心 kubelet 负责和容器运行时（比如docker）交互
&lt;ul>
&lt;li>交互的时候的依赖接口 CRI （Container Runtime Interface）的远程调用接口&lt;/li>
&lt;li>通过 gRPC 协议 与 Device Plugin 进行交互&lt;/li>
&lt;li>调用网络插件为容器配置网络 CNI （Container Networking Interface）&lt;/li>
&lt;li>调用存储插件为容器配置持久化存储 CSI （Container Storage Interface）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>etcd 整个集群的持久化数据，由 kube-apiserver 处理后保存在 Etcd 中&lt;/li>
&lt;/ul>
&lt;p>从一开始，Kubernetes 就没有衣服到 Docker 项目上，没有将它作为架构的核心，只是将它作为了最底层的容器运行时的实现&lt;/p>
&lt;p>Kubernetes 项目最主要的设计思想：从宏观的角度、以统一的方式定义任务之间的各种关系，为将来支持更多种类的关系留有余地&lt;/p>
&lt;blockquote>
&lt;p>例如：
Kubernetes 在访问关系上的操作&lt;/p>
&lt;p>Pod 是 Kubernetes 的最基础的对象。
Service 是 Kubernetes 提供的访问关系的服务对象&lt;/p>
&lt;p>我现在两个应用各自为POD，现在要做到A应用访问B应用，在使用时候，对于容器需要 IP 地址信息不变等等。
Kubernetes的做法是 Pod 绑定一个 Service 服务，而 Service 服务声明的 IP 地址等信息是不变的，这个Service服务主要作用就是作为 Pod 的代理入口，从而替代Pod对外暴露一个固定的网络地址。
这样对于调用方只需要关系 Service 声明信息，而Service后端真正代理的Pod 的IP地址、端口等信息的自动更新、维护是 Kubernetes的职责。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://pinkhello.me/%E5%9B%9E%E6%9C%9BK8S/kubernetes-%E5%85%A8%E6%99%AF%E5%9B%BE.png" alt="kubernetes全景图">&lt;/p>
&lt;ul>
&lt;li>Pod&lt;/li>
&lt;li>Service 描述访问关系&lt;/li>
&lt;li>Secret 密钥&lt;/li>
&lt;li>Job 描述一次性运行的POD&lt;/li>
&lt;li>DaemonSet 描述每个宿主机必须且只能运行一个副本的守护进程服务&lt;/li>
&lt;li>CronJob 描述定时任务&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>如何编排一个K8S项目&lt;/p>
&lt;ul>
&lt;li>通过编排对象, 比如 Pod、Job、CronJob 等，来描述试图管理的应用；&lt;/li>
&lt;li>定义服务对象, 比如 Service、Secret、Horizontal Pod Autoscaler等，会负责具体的平台级功能&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>&lt;code>声明式 API&lt;/code> 对应的 &lt;code>编排对象&lt;/code> 和 &lt;code>服务对象&lt;/code>，都是 Kubernetes 项目中的 API 对象（API Object）&lt;/p>
- https://pinkhello.me/posts/18-%E5%9B%9E%E6%9C%9Bk8s-%E7%99%BD%E8%AF%9D%E5%AE%B9%E5%99%A8/ - PinkHello, All Rights Reserved</description></item><item><title>17 回望K8S 小鲸鱼容器技术</title><link>https://pinkhello.me/posts/17-%E5%9B%9E%E6%9C%9Bk8s-%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/</link><pubDate>Thu, 11 Feb 2021 10:50:42 +0800</pubDate><guid>https://pinkhello.me/posts/17-%E5%9B%9E%E6%9C%9Bk8s-%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/</guid><description>PinkHello https://pinkhello.me/posts/17-%E5%9B%9E%E6%9C%9Bk8s-%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/ -&lt;p>前言&lt;/p>
&lt;ul>
&lt;li>总结自 极客时间 深入剖析 Kubernetes&lt;/li>
&lt;/ul>
&lt;h1 id="什么是容器">什么是容器&lt;/h1>
&lt;p>在容器之前, 火爆云计算市场的是 &lt;code>PAAS&lt;/code>, &lt;code>PAAS&lt;/code>已经深入人心. 那时候突然有一家公司 dotCloud 剑走偏锋, 直接开源出了 &lt;code>Docker&lt;/code> 项目，并且直接面向的社区。 这样的做法直接将当时的&lt;code>PAAS&lt;/code>流主要公司打的屁滚尿流。&lt;/p>
&lt;p>回头看, &lt;code>PAAS&lt;/code> 最核心的是隔离环境,或者叫 &lt;code>沙盒&lt;/code>,在我看来也就是 &lt;code>容器&lt;/code>. 而 &lt;code>Docker&lt;/code> 项目和 &lt;code>Cloud Foundry&lt;/code> 的容器没有太大的不同,但是它为什么能针对 &lt;code>PAAS&lt;/code>进行了一场快速的闪电战呢？&lt;/p>
&lt;blockquote>
&lt;p>对的, 就是 &lt;code>Docker&lt;/code> 镜像, 这个小小的创新, 迅速改变了云计算的发展轨迹! &lt;code>Docker&lt;/code> 镜像解决的是 &lt;code>打包&lt;/code> 问题。也许有人说&lt;code>Docker&lt;/code> 镜像就是一个压缩包。但是就是这个压缩包包含了完整的操作系统文件和目录, 包含了整个应用所需要的依赖，一包在手, 你可以轻易的运行你的&lt;code>沙盒&lt;/code>,并且本地环境与云端环境高度一致（这是最宝贵的）。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;code>Docker&lt;/code>给&lt;code>PAAS&lt;/code>进行了致命打击, 提供了便利的打包机制, 面向后端开发者来说, 屏蔽了机器、内核等技术细节, 避免了在不同环境间的差异引入的试错成本。是一次解放生产力的革命。当然很多开发者用脚投票, 了结了&lt;code>PAAS&lt;/code>时代。&lt;/p>
&lt;h1 id="docker-三大利器">&lt;code>Docker&lt;/code> 三大利器&lt;/h1>
&lt;ul>
&lt;li>&lt;code>Docker&lt;/code>项目的高调开源, 解决了打包和发布困扰运维的技术难题，同时它也第一次纯后端的概念通过友好的设计和封装交付到了开发者的手里。&lt;/li>
&lt;li>&lt;code>Swarm&lt;/code>,&lt;code>Docker&lt;/code>是创建和启停容器的工具,那么&lt;code>Swarm&lt;/code>是为了向平台化发展而提出的。它提供了完整的整体对外提供集群管理功能,它的亮点是完全使用&lt;code>Docker&lt;/code>原本的管理容器的API来完成集群管理&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22"># Swarm多机环境下，指令会被Swarm拦截处理，后面通过调度算法找到合适的Docker Daemon运行&lt;/span>
docker run -H &lt;span style="color:#cd5555">&amp;#34;Swarm集群API&amp;#34;&lt;/span> &lt;span style="color:#cd5555">&amp;#34;我的容器&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;code>Compose&lt;/code>(Fig)项目, 这是第一次在开发者面前提出 &lt;code>容器编排&lt;/code>(Container Orchestration)概念。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>应用容器 A, 数据库容器B, 负载均衡容器C, Compose 允许 A、B、C 三个容器定义在配置文件中, 并指定关联关系. 只需要执行 (fig/docker-compose up)&lt;/p>
&lt;/blockquote>
&lt;h1 id="容器化群雄并起与尘埃落定">容器化群雄并起与尘埃落定&lt;/h1>
&lt;p>容器开启火爆模式, 大量围绕 &lt;code>Docker&lt;/code> 项目的网络、存储、监控、&lt;code>CI/CD&lt;/code>、UI 等涌现了诸如 &lt;code>Rancher&lt;/code>、&lt;code>Tutum&lt;/code> 等在开源和商业上取得成功的创业公司。
在 &lt;code>Docker&lt;/code> 、 &lt;code>Google&lt;/code>、&lt;code>CoreOS&lt;/code>、&lt;code>ReaHat&lt;/code> 等公司在云计算大打出手的时候，落在下风的 &lt;code>Google&lt;/code>、&lt;code>CoreOS&lt;/code>、&lt;code>RedHat&lt;/code> 开始忽悠 &lt;code>Docker&lt;/code> 将 &lt;code>Libcontainer&lt;/code> 项目捐出、组建一个完全独立中立的基金会管理，以 &lt;code>RunC&lt;/code>（改名的 &lt;code>Libcontainer&lt;/code> ）为依据，大家共同制定一套容器和镜像的标准和规范。这套标准和规范就是 &lt;code>OCI&lt;/code>(&lt;code>Open Container Initiative&lt;/code>),
&lt;code>OCI&lt;/code> 的提出，将容器运行时和镜像的实现从&lt;code>Docker&lt;/code>项目只完全剥离开来。（好一招围魏救赵，改善&lt;code>Docker&lt;/code>公司一家独大，其他公司不依赖与&lt;code>Docker&lt;/code>项目）
这是第一步，后面就是容器之上的平台层，就是 &lt;code>PAAS&lt;/code> 层了,后来&lt;code>Google&lt;/code>、&lt;code>RedHat&lt;/code> 等基础设施玩家，共同发起 &lt;code>CNCF&lt;/code>(&lt;code>Cloud Native Computing Foundation&lt;/code>) 基金会。以 &lt;code>Kubernetes&lt;/code> 项目为基础，建立由开源基础设施厂商领导的按照基金会方式运营的平台级社区。&lt;/p>
&lt;ul>
&lt;li>&lt;code>Kubernetes&lt;/code> 项目必须能够在容器编排领域取得足够大的竞争优势&lt;/li>
&lt;li>&lt;code>CNCF&lt;/code> 社区必须以 &lt;code>Kubernetes&lt;/code> 项目为核心，覆盖更多的常见&lt;/li>
&lt;/ul>
&lt;p>&lt;code>Kubernetes&lt;/code> 当初为什么被认为设计思想过于超前，就是因为 Google 在容器化多年的沉淀和升华（&lt;code>Borg&lt;/code> 和 &lt;code>Omega&lt;/code> 特性、落在 &lt;code>K8S&lt;/code> 上就是 &lt;code>Pod&lt;/code>、&lt;code>Sidecar&lt;/code> 的功能和设计模式）
&lt;code>Kubernetes&lt;/code> 当初没有选择和 &lt;code>Swarm&lt;/code> 展开同质化竞争，而是提出太多的设计理念和号召力，很快构建了不同的容器编排的管理的生态理念。超过了&lt;code>Swarm&lt;/code>项目。有了这个后，又将容器监控事实标准 &lt;code>prometheus&lt;/code>融入其中，后面又新增了 &lt;code>Fluentd&lt;/code>、&lt;code>OpenTracing&lt;/code>、&lt;code>CNDI&lt;/code> 等诸多容器生态工具和项目。后面又一记补刀：整个社区进行推进&lt;code>民主化&lt;/code>架构, 从 API 到 容器运行时的 每一层,
&lt;code>Kubernetes&lt;/code> 项目都为开发者暴露出了可以扩展的插件机制, 鼓励社区用户通过代码的方式介入 &lt;code>Kubernetes&lt;/code> 项目的每一个阶段。这个操作针对 &lt;code>Docker&lt;/code> 来说是致命的,整个容器社区催生了大量的、基于 &lt;code>Kubernetes API&lt;/code> 的做扩展的和二次开发创新的&lt;/p>
&lt;ul>
&lt;li>微服务治理项目 &lt;code>Istio&lt;/code>&lt;/li>
&lt;li>状态应用部署架构 &lt;code>Operator&lt;/code>&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;p>经过一些列骚操作后，K8S 大行其道，编排之争落下帷幕，容器社区的后续繁荣完全以 &lt;code>Kubernetes&lt;/code> 项目为核心的百家争鸣, 从 &lt;code>Rancher&lt;/code>项目 的历史迭代过程中也能看出这个精彩纷呈的展现。&lt;/p>
- https://pinkhello.me/posts/17-%E5%9B%9E%E6%9C%9Bk8s-%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/ - PinkHello, All Rights Reserved</description></item><item><title>16 Hexo迁移Hugo</title><link>https://pinkhello.me/posts/16-hexo%E8%BF%81%E7%A7%BBhugo/</link><pubDate>Wed, 10 Feb 2021 19:36:33 +0800</pubDate><guid>https://pinkhello.me/posts/16-hexo%E8%BF%81%E7%A7%BBhugo/</guid><description>PinkHello https://pinkhello.me/posts/16-hexo%E8%BF%81%E7%A7%BBhugo/ -&lt;h1 id="为什么迁移-hugo">为什么迁移 &lt;code>Hugo&lt;/code>&lt;/h1>
&lt;ul>
&lt;li>&lt;code>Hugo&lt;/code> 使用比 &lt;code>Hexo&lt;/code> 简单, 只有单独的一个二进制文件&lt;/li>
&lt;li>苦于 &lt;code>Hexo&lt;/code> 的 &lt;code>NodeModule&lt;/code> 管理&lt;/li>
&lt;li>迁移成本更低, 结合 &lt;code>Github Action&lt;/code> 实现 &lt;code>Markdown&lt;/code> 文章发布, 自动更新至静态站&lt;/li>
&lt;li>规划：加入自定义域名以及做静态资源CDN做的加速&lt;/li>
&lt;/ul>
&lt;h1 id="前置工作">前置工作&lt;/h1>
&lt;p>1、 之前基本所有的博客都托管与 &lt;code>github&lt;/code>,这次也不例外, 复用 &lt;code>https://pinkhello.github.io&lt;/code>,创建两个项目&lt;/p>
&lt;ul>
&lt;li>pinkhello.github.io template 仓库&lt;/li>
&lt;li>pinkhello.github.io.source private 仓库&lt;/li>
&lt;/ul>
&lt;p>2、准备OpenSSH私钥和公钥&lt;/p>
&lt;ul>
&lt;li>pinkhello.github.io 仓库 添加 settings -&amp;gt; Deploy keys -&amp;gt; Add Deploy Key (将公钥添加进去、注意允许 Write)&lt;/li>
&lt;li>pinkhello.github.io.source 仓库 添加 settings -&amp;gt; Actions secrets -&amp;gt; New Repository Secret ( NAME : ACTION_DEPLOY_KEY, Value: 私钥 )&lt;/li>
&lt;/ul>
&lt;p>3、git clone pinkhello.github.io.source 仓库&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">git clone git@github.com:PinkHello/pinkhello.github.io.source.git
&lt;span style="color:#658b00">cd&lt;/span> pinkhello.github.io.source
&lt;span style="color:#228b22"># 初始化站点【--force 强制初始化】&lt;/span>
hugo new site . --force
&lt;span style="color:#228b22"># content site &lt;/span>
&lt;span style="color:#228b22"># data json数据 or 其他&lt;/span>
&lt;span style="color:#228b22"># static 静态文件&lt;/span>
&lt;span style="color:#228b22"># themes 主题&lt;/span>
&lt;span style="color:#228b22"># 后面可以执行 hugo new posts/XXX.md 创建新的文章&lt;/span>
hugo new posts/XXX.md
&lt;span style="color:#228b22"># 具体参考 https://gohugo.io/getting-started/ 进行操作&lt;/span>
......
&lt;span style="color:#228b22"># 选择一个主题 https://themes.gohugo.io/ 可以选择&lt;/span>
git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke
&lt;span style="color:#228b22"># 后面的参照各个主题设置咯&lt;/span>
....
&lt;span style="color:#228b22"># 本地测试&lt;/span>
hugo serve
&lt;span style="color:#228b22"># 生成最小的静态文件, 会生成 public 文件&lt;/span>
hugo --minify
&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="迁移-hexo-博客进入-hugo">迁移 &lt;code>hexo&lt;/code> 博客进入 &lt;code>hugo&lt;/code>&lt;/h1>
&lt;p>&amp;hellip;&amp;hellip;(可以手动、可以工具进行)&lt;/p>
&lt;h1 id="整合-github-action">整合 &lt;code>Github Action&lt;/code>&lt;/h1>
&lt;p>新建 &lt;code>Github Action&lt;/code> 描述文件 &lt;code>.github/workflows/deploy.yml&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#228b22"># This is a basic workflow to help you get started with Actions&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Deploy on Main Branch&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#228b22"># Controls when the action will run. &lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">on&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># Triggers the workflow on push or pull request events but only for the main branch&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">push&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">branches&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>[&lt;span style="color:#bbb"> &lt;/span>main ]&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">pull_request&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">branches&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>[&lt;span style="color:#bbb"> &lt;/span>main ]&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#228b22"># schedule:&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#228b22"># - cron: &amp;#39;0 21 * * *&amp;#39; # 定时任务&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># Allows you to run this workflow manually from the Actions tab&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">workflow_dispatch&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#228b22"># A workflow run is made up of one or more jobs that can run sequentially or in parallel&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">jobs&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># This workflow contains a single job called &amp;#34;build&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">build&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># The type of runner that the job will run on&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">runs-on&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>ubuntu-latest&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># Steps represent a sequence of tasks that will be executed as part of the job&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">steps&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">uses&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>actions/checkout@v2&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Setup Hugo&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">uses&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>peaceiris/actions-hugo@v2&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># https://github.com/peaceiris/actions-hugo&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">with&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">hugo-version&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#39;latest&amp;#39;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">extended&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">true&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Build&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># 注意强制更新 git submodule 下载，否则生成的主题没有 html 文件哦&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">run&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>|&lt;span style="color:#cd5555">
&lt;/span>&lt;span style="color:#cd5555"> git submodule update --init --recursive
&lt;/span>&lt;span style="color:#cd5555"> hugo --minify --debug&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Deploy&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">uses&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>peaceiris/actions-gh-pages@v3&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># https://github.com/peaceiris/actions-gh-pages&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">with&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">deploy_key&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>${{ secrets.ACTION_DEPLOY_KEY }}&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># 这里的 ACTION_DEPLOY_KEY 则是上面设置 Private Key的变量名&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">external_repository&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>PinkHello/PinkHello.github.io&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># Pages 远程仓库 &lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">publish_dir&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>./public&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">keep_files&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">false&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># remove existing files&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">publish_branch&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>master &lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># deploying branch&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">commit_message&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>${{ github.event.head_commit.message }}&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>so 完美
&lt;img src="https://pinkhello.me/hexo%E8%BF%81%E7%A7%BB%E8%87%B3hugo/github_action_in_process_0.jpg" alt="迁移Hexo">
&lt;img src="https://pinkhello.me/hexo%E8%BF%81%E7%A7%BB%E8%87%B3hugo/github_action_in_process.jpg" alt="迁移Hexo">&lt;/p>
- https://pinkhello.me/posts/16-hexo%E8%BF%81%E7%A7%BBhugo/ - PinkHello, All Rights Reserved</description></item><item><title>15 记一次docker日志磁盘告警问题</title><link>https://pinkhello.me/posts/15-%E8%AE%B0%E4%B8%80%E6%AC%A1docker%E6%97%A5%E5%BF%97%E7%A3%81%E7%9B%98%E5%91%8A%E8%AD%A6%E9%97%AE%E9%A2%98/</link><pubDate>Wed, 10 Feb 2021 10:05:29 +0800</pubDate><guid>https://pinkhello.me/posts/15-%E8%AE%B0%E4%B8%80%E6%AC%A1docker%E6%97%A5%E5%BF%97%E7%A3%81%E7%9B%98%E5%91%8A%E8%AD%A6%E9%97%AE%E9%A2%98/</guid><description>PinkHello https://pinkhello.me/posts/15-%E8%AE%B0%E4%B8%80%E6%AC%A1docker%E6%97%A5%E5%BF%97%E7%A3%81%E7%9B%98%E5%91%8A%E8%AD%A6%E9%97%AE%E9%A2%98/ -&lt;h1 id="前景">前景&lt;/h1>
&lt;p>今日，我正在开开心心的刷着JFX的Coding中，突然线上报警群中爆了个炸弹，EC2磁盘超过80%。&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/%E8%B5%84%E6%BA%90%E4%B8%8D%E8%B6%B3%E6%8A%A5%E8%AD%A6.png" alt="资源不足预警">&lt;/p>
&lt;h1 id="处理过程">处理过程&lt;/h1>
&lt;p>解决问题姿势就位：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>赶紧开机 ==》 ❤️中万匹🦙奔腾而过 ❤️中MMP&lt;/p>
&lt;/li>
&lt;li>
&lt;p>默默的通过跳板机进入目标机器&lt;/p>
&lt;/li>
&lt;li>
&lt;p>不管三七二十一,执行查看磁盘占用大小，我的乖乖，占用确实超过了87%了，一下子暴涨的&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22"># 查看磁盘占用大小&lt;/span>
&amp;gt; sudo df -h
&lt;span style="color:#228b22"># 查看当前目录总量&lt;/span>
&amp;gt; sudo du -sh
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>开始定位具体哪个文件或者目录占用这么大,跑到根目录下。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22"># 查看当前目录下一级子文件和子目录占用的磁盘容量&lt;/span>
&amp;gt; sudo du -lh --max-depth=&lt;span style="color:#b452cd">1&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>一开始猜想可能是docker容器的日志占用大，上面执行后，还真 TM 是&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">/var/lib/docker/containers 目录占用 42G
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>开始查看是哪个容器占用的这么大的空间&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#228b22"># 查看 containers 日志目录排序&lt;/span>
&amp;gt; sudo du -d1 -h /var/lib/docker/containers | sort -h
&lt;span style="color:#228b22"># 查看具体的哪个日志文件大&lt;/span>
&amp;gt; sudo find /var/lib/docker/containers -name *.log
&lt;/code>&lt;/pre>&lt;/div>&lt;p>当然这个配图是我清理之后的
&lt;img src="https://pinkhello.me/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/docker%E5%AE%B9%E5%99%A8%E6%96%87%E4%BB%B6%E6%8E%92%E5%BA%8F.png" alt="docker容器文件排序">
&lt;img src="https://pinkhello.me/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/%E6%9F%A5%E6%89%BEdocker%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6.png" alt="查找docker容器日志文件">&lt;/p>
&lt;ul>
&lt;li>定位到最大的文件，一顿操作&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell"> &lt;span style="color:#228b22"># 清空比较大的日志文件&lt;/span>
&amp;gt; sudo sh -c &lt;span style="color:#cd5555">&amp;#34;cat /dev/null &amp;gt; &lt;/span>&lt;span style="color:#cd5555">${&lt;/span>&lt;span style="color:#00688b">log_file&lt;/span>&lt;span style="color:#cd5555">}&lt;/span>&lt;span style="color:#cd5555">&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="https://pinkhello.me/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/%E6%B8%85%E7%90%86docker%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97%E5%90%8E.png" alt="清理docker容器日志后">&lt;/p>
&lt;h1 id="思考">思考&lt;/h1>
&lt;ul>
&lt;li>上面的方式是一种方式解决【临时】
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell"> &lt;span style="color:#228b22"># 查看 docker 的 Logging Driver&lt;/span>
&amp;gt; docker info | grep &lt;span style="color:#cd5555">&amp;#39;Logging Driver&amp;#39;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如何彻底解决这个问题：&lt;/p>
&lt;ul>
&lt;li>写个&lt;code>shell脚本&lt;/code> 使用 &lt;code>crontab&lt;/code> 定期执行清理
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell"> &lt;span style="color:#228b22">#!/bin/sh&lt;/span>
&lt;span style="color:#658b00">echo&lt;/span> &lt;span style="color:#cd5555">&amp;#34;======== start clean docker containers logs ========&amp;#34;&lt;/span>
&lt;span style="color:#00688b">logs&lt;/span>=&lt;span style="color:#8b008b;font-weight:bold">$(&lt;/span>find /var/lib/docker/containers/ -name *-json.log&lt;span style="color:#8b008b;font-weight:bold">)&lt;/span>
&lt;span style="color:#8b008b;font-weight:bold">for&lt;/span> log in &lt;span style="color:#00688b">$logs&lt;/span>
&lt;span style="color:#8b008b;font-weight:bold">do&lt;/span>
&lt;span style="color:#658b00">echo&lt;/span> &lt;span style="color:#cd5555">&amp;#34;clean logs : &lt;/span>&lt;span style="color:#00688b">$log&lt;/span>&lt;span style="color:#cd5555">&amp;#34;&lt;/span>
cat /dev/null &amp;gt; &lt;span style="color:#00688b">$log&lt;/span>
&lt;span style="color:#8b008b;font-weight:bold">done&lt;/span>
&lt;span style="color:#658b00">echo&lt;/span> &lt;span style="color:#cd5555">&amp;#34;======== end clean docker containers logs ========&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>假如是&lt;code>docker run&lt;/code>创建容器的,指定 &lt;code>--log-opt max-size=${MAX_SIZE}m --log-opt max-file=${NUMBER}&lt;/code>&lt;/li>
&lt;li>&lt;code>docker-compose&lt;/code> 方式更高&lt;code>docker-compose.yaml&lt;/code>文件
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">logging&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">driver&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;json-file&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">options&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">max-size&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;${MAX_SIZE}m&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">max-file&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>${NUMBER}&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>&lt;code>docker&lt;/code> 全局修改 &lt;code>/etc/docker/daemon.json&lt;/code>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json"> {
&lt;span style="color:#8b008b;font-weight:bold">&amp;#34;log-driver&amp;#34;&lt;/span>: &lt;span style="color:#cd5555">&amp;#34;json-file&amp;#34;&lt;/span>,
&lt;span style="color:#8b008b;font-weight:bold">&amp;#34;log-opts&amp;#34;&lt;/span>: {
&lt;span style="color:#8b008b;font-weight:bold">&amp;#34;max-size&amp;#34;&lt;/span>: &lt;span style="color:#cd5555">&amp;#34;${MAX_SIZE}m&amp;#34;&lt;/span>
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell"> &amp;gt; systemctl daemon-reload
&amp;gt; systemctl restart docker
&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>为什么会瞬间💥式的增长 ???&lt;/li>
&lt;/ul>
- https://pinkhello.me/posts/15-%E8%AE%B0%E4%B8%80%E6%AC%A1docker%E6%97%A5%E5%BF%97%E7%A3%81%E7%9B%98%E5%91%8A%E8%AD%A6%E9%97%AE%E9%A2%98/ - PinkHello, All Rights Reserved</description></item><item><title>14 工作纪实2020</title><link>https://pinkhello.me/posts/14-%E5%B7%A5%E4%BD%9C%E7%BA%AA%E5%AE%9E2020/</link><pubDate>Wed, 10 Feb 2021 10:00:19 +0800</pubDate><guid>https://pinkhello.me/posts/14-%E5%B7%A5%E4%BD%9C%E7%BA%AA%E5%AE%9E2020/</guid><description>PinkHello https://pinkhello.me/posts/14-%E5%B7%A5%E4%BD%9C%E7%BA%AA%E5%AE%9E2020/ -&lt;h1 id="每日一思篇">每日一思篇&lt;/h1>
&lt;h2 id="2019-10-12-每日一思-mysql-wal技术-和-ringbuffer-思想好一致">[2019-10-12 每日一思] Mysql WAL技术 和 RingBuffer 思想好一致?&lt;/h2>
&lt;h2 id="2019-10-14-每日一思-jwt-续签该如何做">[2019-10-14 每日一思] JWT 续签该如何做?&lt;/h2>
&lt;h2 id="2019-10-16-每日一思-tcpip-协议具体指哪些">[2019-10-16 每日一思] TCP/IP 协议具体指哪些?&lt;/h2>
&lt;blockquote>
&lt;p>我们都知道网络是7层模型，应表会传网数物，
现在我只讨论应传网数这4层。TCP/IP协议应该被称为TCP/IP族，
我的理解他不是属于单个的协议类型，是一个统称，知道网络模型核心设计思想是分层，为什么分层，分层从设计上和实现难度上都简单很多，哪一层需要修改只需要修改这一层。&lt;/p>
&lt;ul>
&lt;li>应用层，像最常见的http、ftp、dns、rtsp、rtmp等等协议都是属于这类，&lt;/li>
&lt;li>传输层呢按照传输类型又分了TCP和UDP,&lt;/li>
&lt;li>网络层，是数据包交互的层面，&lt;/li>
&lt;li>数据链路层是处理网卡、操作系统等等软硬抽象出的可见部分。&lt;/li>
&lt;/ul>
&lt;p>举一个栗子，一个http请求，在应用层面是完整的，后面被传输层（TCP层）被分包，并打上序号标记，再进入网络层（IP层）添加IP首部（目标mac地址等等），
下面就是开始疯狂的发送了，接收方一样是这个过程的逆序。应用处理完成后面的响应过程与请求过程一样的一个过程。同时可以扩展出L4与L7的问题，
各自是如何去实现负载均衡的？L4是可以看出是基于传输层即TCP层工作（通过发布VIP（第三层）以及第四层端口），L7基于应用层工作（第四层基础上+考虑应用特征），
比如HTTP的URL、客户端的类别、语言类型等等。&lt;/p>
&lt;/blockquote>
&lt;h2 id="2019-10-18-每日一思一种场景rabbitmq-的-exchange-为-fanout-类型绑定到多个queue-什么情况会触发-rabbitmq-流控如何解决">[2019-10-18 每日一思]一种场景，rabbitmq 的 Exchange 为 fanout 类型，绑定到多个queue, 什么情况会触发 rabbitmq 流控？如何解决？&lt;/h2>
&lt;h2 id="2019-10-22-每日一思id序列生产器怎么实现呢">[2019-10-22 每日一思]ID序列生产器怎么实现呢？&lt;/h2>
&lt;blockquote>
&lt;p>uuid生成&lt;/p>
&lt;ul>
&lt;li>基于时间（60位utc时间 和 时间序列值14位，以及mac地址）&lt;/li>
&lt;li>基于名称（针对命名空间dns、url等分配，把名称转成字节序列，再用md5或sha-1与命名空间标识进行计算，产生哈希结果）&lt;/li>
&lt;li>基于随机数（密码学随机数，系统的硬盘内存线程堆栈进程句柄等sha-1生成哈希结果）&lt;/li>
&lt;/ul>
&lt;p>snowflake，64bit，long型ID&lt;/p>
&lt;ul>
&lt;li>ID生成方式 1bit（不使用），41bit时间戳（当前毫秒数、69年一轮回），10bit机器码（1024台，5bit数据中心，5bit机器ID），12bit作为毫秒内序列号（单机理论 409.6w/s）&lt;/li>
&lt;li>雪花算法，多台机器，有因为时钟回拨导致的ID生成问题，当然可以通过发生时钟回拨后一个阈值，在阈值内则不允许产生新的ID，同步阻塞，在阈值外重新设置机器ID来解决&lt;/li>
&lt;li>github.com/baidu/uid-generator 技术老铁百度开源的基于snowflake实现的ID生成器，可以借鉴研读一下&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h2 id="2019-11-01-每日一思我们常说的限流是什么为什么要限流限流有哪些方式">[2019-11-01 每日一思]我们常说的限流是什么？为什么要限流？限流有哪些方式？&lt;/h2>
&lt;blockquote>
&lt;p>我们常说的限流，顾名思义即限制流量. 限制系统的输入和输出
常用的限流发展至今，有四种方式&lt;/p>
&lt;ul>
&lt;li>固定时间计数器&lt;/li>
&lt;li>漏桶&lt;/li>
&lt;li>令牌桶&lt;/li>
&lt;li>滑动窗口计数器&lt;/li>
&lt;/ul>
&lt;p>固定窗口计数器：以单位时间内进入系统（系统级别）或者某一个单一接口服务（系统服务级别）请求次数，在这个单位时间内的超过次数，拒绝服务或者更换其他方案（降级、熔断）达到限流目的。&lt;/p>
&lt;blockquote>
&lt;p>可以看出，明显的缺点，从整体曲线上，毛刺现象非常严重，假设单位时间 1s 内限制 100 次，在0-10ms内我已经请求超过100次了，后面的请求全部拒绝或者做其他处理了。无法控制单位时间内的突发流量。&lt;/p>
&lt;/blockquote>
&lt;p>漏桶: 桶的容量固定，桶流出的速率恒定。桶满则限流。也是无法应对突发流量&lt;/p>
&lt;p>令牌桶： 还是桶的方式， 桶中存放的是 token ，根据限流的大小， token 以恒定速率进入桶中，设置桶的最大的 token 容量，当桶满时候拒绝新添加的token
，或者直接丢弃。所有请求进入先获取令牌，得到令牌继续下面的业务逻辑，处理完成删除 token。&lt;/p>
&lt;blockquote>
&lt;p>相比 漏桶， 一定程度上允许突发流量，平滑限流，因为 桶 中的 token 是匀速放入的，抵御突发流量。桶的 token 数量不会超过给定的最大值。
参考 guava rate limiter&lt;/p>
&lt;/blockquote>
&lt;p>滑动窗口计数器:(参考Sentinel中使用的默认限流方式)
是对固定时间窗口计数器的优化，就是为了解决固定时间计数器的无法面对突发流量，何为滑动窗口呢？
假设单位时间定位 1s， 计数器限制在 1000 次， 再将者 1s 划分为 100ms 为一个小格子，总共 10 个格子，
每个格子还有计数器，当一个请求进来，在对应的时间格子里面的计数器 +1 ，只要总的这个单位时间内所有的时间格子计数器总和小于 限制次数，就不会启动限流作用。
可以看出来，假如我的划分的格子很小，滑动窗口滚动将是越平滑的。
ps： 0.00 - 1.00 有 10 个格子，这是一个滑动窗口期，然后 0.10-1.10是一个窗口期，这样计算的&lt;/p>
&lt;/blockquote>
&lt;h2 id="2019-11-04-每日一思-假如mq消息队列产生了堆积如何更快的消费">[2019-11-04 每日一思] 假如MQ消息队列产生了堆积，如何更快的消费？&lt;/h2>
&lt;blockquote>
&lt;p>会从多种队列去分析，rabbitmq，kafka，rocketmq，pulsar等多个消息中间件去分析。
RabbitMq得看是什么模式，如果是生产消费者模式是可以的，发布订阅模式就没卵用，加个订阅者而已。kafka看consumer的数量吧，如果已经大于等于partition数量了，加consumer也没卵用。pulsar
是也一样啊，有生产者消费者模式，也有独占和失败替补模式。&lt;/p>
&lt;p>对的，先说kafka和RocketMQ，他们都是基于partition的存储模型，也就是说每个subject分为一个或多个partition，Server收到消息分发到某个partition上，而consumer
消费时候是与partition相对应的，当partition与consumer数量相等时，是一对一，当小于时候，会有consumer空闲，大于时候，看数量，有consumer
会负责多个，比较繁忙。在产生队列积压时候，这时候最合理的分配减压策略是 partition数量和consumer数量成倍数关系，单个增加consumer
数量并不能有效提高时候，并且并不能马上提高消费效率，需要添加对应的partition数量，但是就带来了另外的问题，partition数量增加，特别是kafka，partition资源是一个比较重的资源，增加partition
数量还需要考虑集群的处理能力，另外在高峰过后，想要consumer缩容也比较麻烦哦，因为partition只能增加不能减少。&lt;/p>
&lt;p>针对partition存储方式的，扩容相关的问题，已经堆积的消息是不能快速消费的，假设是2partition对2个consumer，这时候增加partition和consumer是无用的，因为已经堆积的只能由这两个consumer
消费，横向扩展不可能了，只能纵向扩展，这时候要么只能接受已经堆积慢慢消费，并且尽量减少入这两个partition的消息，或者执行比较重点再均衡策略！&lt;/p>
&lt;/blockquote>
&lt;h2 id="2019-11-18-每日一思-httpdns有啥好处-httpdns-为什么一般只适用于-app-或者-cs-架构bs-为何不适用">[2019-11-18 每日一思] HttpDNS有啥好处, HttpDNS 为什么一般只适用于 APP 或者 C/S 架构，B/S 为何不适用?#&lt;/h2>
&lt;blockquote>
&lt;p>HttpDNS 是基于HTTP协议发起服务器A记录的地址，不存在向本地运营商询问 domain 解析过程
适用于APP或者C/S架构，是它的特殊性导致的，&lt;/p>
&lt;ul>
&lt;li>一般在终端这种信号差、信号不稳定下，要想尽量的介绍交互&lt;/li>
&lt;li>跑马机制选取就近地址&lt;/li>
&lt;li>SDK嵌入&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h2 id="2019-12-12-每日一思我们知道许多长链接情况下保证链接有效大部分是通过-tcp-keepalive-与-应用心跳-来确定各自的定位是什么为什么大多数情况下很多im系统同时使用-tcp-keepalive-与-应用层心跳去确认-应用层心跳设计上有啥讲究">[2019-12-12 每日一思]我们知道许多长链接情况下，保证链接有效大部分是通过 TCP Keepalive 与 应用心跳 来确定，各自的定位是什么？为什么大多数情况下很多IM系统同时使用 TCP Keepalive 与 应用层心跳去确认？ 应用层心跳设计上有啥讲究？&lt;/h2>
&lt;blockquote>
&lt;p>TCP Keepalive 是 TCP/IP 协议自带，无需额外的开发，但是不灵活，而且我们一般在应用层面是无法感知。更改TCP Keepalive 相关参数需要修改/etc/sysctl.conf&lt;/p>
&lt;p>应用层心跳是为了保活，保证链接的可用性&lt;/p>
&lt;ul>
&lt;li>运营商的环境，，存在 NAT 超时断链问题&lt;/li>
&lt;li>让应用知晓网络可用情况，酌情处理断链重连问题&lt;/li>
&lt;li>可以有效的江都服务端为了维护无效链接的开销&lt;/li>
&lt;/ul>
&lt;p>应用层心跳设计上&lt;/p>
&lt;ul>
&lt;li>固定频率，通常只有请求头，消息体空包（在判断这类心跳处理时候，客户端一般要判断超时时间大于心跳间隔【可能存在网络延迟】）&lt;/li>
&lt;li>智能心跳，根据网络状况自动调整发送的频率，来适配当前网络情况的最佳心跳频率（各个地区各个服务商 NAT 超时设计不一样，长的多达几个小时，少的只有几秒）&lt;/li>
&lt;/ul>
&lt;p>智能心跳，一般采用二分法来逐渐逼近服务商的 NAT 超时设计。心跳设计上不会是空包，而是传输的是客户端的心跳频率是多少。
（假设 最小值 20 s 最大值 1小时）===&amp;gt; 逐渐二分下去&lt;/p>
&lt;/blockquote>
&lt;h2 id="2019-12-14-每日一思-如何判断任意用户上传的文件在服务端是否存在呢网盘的秒传的实现思路">[2019-12-14 每日一思] 如何判断任意用户上传的文件在服务端是否存在呢？网盘的“秒传”的实现思路？&lt;/h2>
&lt;blockquote>
&lt;p>对比文件，确实是使用的文件的提取的特征值（单项哈希算法）,哈希算法是有冲突的，虽然概率较小， 那么如何这种冲突呢：在服务端，
对该文件进行不同的单向Hash算法（MD5，SHA-1）等等得到多个值，一一对比，只有全部相同才认为是同一个文件。&lt;/p>
&lt;p>为什么要哈希？为了将一个不定长、不确定的东东 转化成 固定长度的固化的特征值，并要保证唯一性。&lt;/p>
&lt;/blockquote>
&lt;h1 id="填坑记录">填坑记录&lt;/h1>
&lt;h2 id="docker相关">docker相关&lt;/h2>
&lt;ul>
&lt;li>docker默认网桥问题&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>服务器默认网桥 172.19.0.0, 而 docker 网桥默认172.17.0.0,
在启动多个的docker容器的时候会导致地址冲突，桥接网卡凉，
需要更改docker 默认的网桥地址&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-markdown" data-lang="markdown"> {
&amp;#34;debug&amp;#34; : true,
&amp;#34;default-address-pools&amp;#34; : [
{
&amp;#34;base&amp;#34; : &amp;#34;172.31.0.0/16&amp;#34;,
&amp;#34;size&amp;#34; : 24
}
]
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>更改成和主机不一样的的网段地址&lt;/p>
&lt;/blockquote>
&lt;h2 id="redis分布式锁">redis分布式锁&lt;/h2>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-java" data-lang="java">
&lt;span style="color:#8b008b;font-weight:bold">package&lt;/span> &lt;span style="color:#008b45;text-decoration:underline">com.kezaihui.thor.biz.core.adapter.redis.lock&lt;/span>;
&lt;span style="color:#8b008b;font-weight:bold">import&lt;/span> &lt;span style="color:#008b45;text-decoration:underline">lombok.extern.slf4j.Slf4j&lt;/span>;
&lt;span style="color:#8b008b;font-weight:bold">import&lt;/span> &lt;span style="color:#008b45;text-decoration:underline">org.springframework.beans.factory.annotation.Autowired&lt;/span>;
&lt;span style="color:#8b008b;font-weight:bold">import&lt;/span> &lt;span style="color:#008b45;text-decoration:underline">org.springframework.data.redis.core.RedisTemplate&lt;/span>;
&lt;span style="color:#8b008b;font-weight:bold">import&lt;/span> &lt;span style="color:#008b45;text-decoration:underline">org.springframework.data.redis.core.script.DefaultRedisScript&lt;/span>;
&lt;span style="color:#8b008b;font-weight:bold">import&lt;/span> &lt;span style="color:#008b45;text-decoration:underline">org.springframework.stereotype.Component&lt;/span>;
&lt;span style="color:#8b008b;font-weight:bold">import&lt;/span> &lt;span style="color:#008b45;text-decoration:underline">java.util.Collections&lt;/span>;
&lt;span style="color:#228b22">/**
&lt;/span>&lt;span style="color:#228b22"> * RedisTemplateDistributeLockUtil
&lt;/span>&lt;span style="color:#228b22"> */&lt;/span>
&lt;span style="color:#707a7c">@Slf4j&lt;/span>
&lt;span style="color:#707a7c">@Component&lt;/span>
&lt;span style="color:#8b008b;font-weight:bold">public&lt;/span> &lt;span style="color:#8b008b;font-weight:bold">class&lt;/span> &lt;span style="color:#008b45;font-weight:bold">RedisTemplateDistributeLockUtil&lt;/span> {
&lt;span style="color:#8b008b;font-weight:bold">public&lt;/span> &lt;span style="color:#8b008b;font-weight:bold">static&lt;/span> &lt;span style="color:#8b008b;font-weight:bold">final&lt;/span> String LOCK_SCRIPT =
&lt;span style="color:#cd5555">&amp;#34;local key = KEYS[1]; local value = ARGV[1]; if redis.call(&amp;#39;set&amp;#39;, key, value, &amp;#39;NX&amp;#39; ,&amp;#39;PX&amp;#39;, %d) &amp;#34;&lt;/span>
+ &lt;span style="color:#cd5555">&amp;#34;then return 1 else return 0 end&amp;#34;&lt;/span>;
&lt;span style="color:#8b008b;font-weight:bold">public&lt;/span> &lt;span style="color:#8b008b;font-weight:bold">static&lt;/span> &lt;span style="color:#8b008b;font-weight:bold">final&lt;/span> String UNLOCK_SCRIPT =
&lt;span style="color:#cd5555">&amp;#34;if redis.call(&amp;#39;get&amp;#39;, KEYS[1]) == ARGV[1] then return redis.call(&amp;#39;del&amp;#39;,KEYS[1]) else return 0 end&amp;#34;&lt;/span>;
&lt;span style="color:#8b008b;font-weight:bold">public&lt;/span> &lt;span style="color:#8b008b;font-weight:bold">static&lt;/span> &lt;span style="color:#8b008b;font-weight:bold">final&lt;/span> &lt;span style="color:#00688b;font-weight:bold">int&lt;/span> EXPIRE = 5000;
&lt;span style="color:#707a7c">@Autowired&lt;/span>
&lt;span style="color:#8b008b;font-weight:bold">private&lt;/span> RedisTemplate redisTemplate;
&lt;span style="color:#8b008b;font-weight:bold">private&lt;/span> String &lt;span style="color:#008b45">lockExpireScript&lt;/span>(&lt;span style="color:#00688b;font-weight:bold">int&lt;/span> expireMills) {
&lt;span style="color:#8b008b;font-weight:bold">if&lt;/span> (expireMills &amp;lt;= 0) {
expireMills = EXPIRE;
}
&lt;span style="color:#8b008b;font-weight:bold">return&lt;/span> String.&lt;span style="color:#658b00">format&lt;/span>(LOCK_SCRIPT, expireMills);
}
&lt;span style="color:#8b008b;font-weight:bold">public&lt;/span> &lt;span style="color:#00688b;font-weight:bold">boolean&lt;/span> &lt;span style="color:#008b45">lock&lt;/span>(String key, String value, &lt;span style="color:#00688b;font-weight:bold">int&lt;/span> expireMills) {
String script = lockExpireScript(expireMills);
DefaultRedisScript&amp;lt;Long&amp;gt; redisScript = &lt;span style="color:#8b008b;font-weight:bold">new&lt;/span> DefaultRedisScript&amp;lt;&amp;gt;(script, Long.&lt;span style="color:#658b00">class&lt;/span>);
Long execute = (Long) redisTemplate.&lt;span style="color:#658b00">execute&lt;/span>(redisScript, Collections.&lt;span style="color:#658b00">singletonList&lt;/span>(key),
Collections.&lt;span style="color:#658b00">singletonList&lt;/span>(value));
&lt;span style="color:#8b008b;font-weight:bold">return&lt;/span> execute != &lt;span style="color:#8b008b;font-weight:bold">null&lt;/span> &amp;amp;&amp;amp; execute != 0;
}
&lt;span style="color:#8b008b;font-weight:bold">public&lt;/span> &lt;span style="color:#00688b;font-weight:bold">boolean&lt;/span> &lt;span style="color:#008b45">blockLock&lt;/span>(String key, String value, &lt;span style="color:#00688b;font-weight:bold">int&lt;/span> expireMills) &lt;span style="color:#8b008b;font-weight:bold">throws&lt;/span> DistributeLockTimeoutException {
&lt;span style="color:#228b22">// 被阻塞的时间超过5秒就停止获取锁
&lt;/span>&lt;span style="color:#228b22">&lt;/span> &lt;span style="color:#00688b;font-weight:bold">int&lt;/span> blockTime = expireMills;
&lt;span style="color:#228b22">// 默认的间隔时间
&lt;/span>&lt;span style="color:#228b22">&lt;/span> &lt;span style="color:#8b008b;font-weight:bold">for&lt;/span> (; ; ) {
&lt;span style="color:#8b008b;font-weight:bold">if&lt;/span> (blockTime &amp;gt;= 0) {
String script = lockExpireScript(expireMills);
DefaultRedisScript&amp;lt;Long&amp;gt; redisScript = &lt;span style="color:#8b008b;font-weight:bold">new&lt;/span> DefaultRedisScript&amp;lt;&amp;gt;(script, Long.&lt;span style="color:#658b00">class&lt;/span>);
Long result = (Long) redisTemplate.&lt;span style="color:#658b00">execute&lt;/span>(redisScript, Collections.&lt;span style="color:#658b00">singletonList&lt;/span>(key), value);
&lt;span style="color:#8b008b;font-weight:bold">if&lt;/span> (result != &lt;span style="color:#8b008b;font-weight:bold">null&lt;/span> &amp;amp;&amp;amp; result == 1) {
&lt;span style="color:#228b22">// 得到了锁
&lt;/span>&lt;span style="color:#228b22">&lt;/span> &lt;span style="color:#8b008b;font-weight:bold">return&lt;/span> &lt;span style="color:#8b008b;font-weight:bold">true&lt;/span>;
} &lt;span style="color:#8b008b;font-weight:bold">else&lt;/span> {
blockTime -= 300;
&lt;span style="color:#8b008b;font-weight:bold">try&lt;/span> {
Thread.&lt;span style="color:#658b00">sleep&lt;/span>(300);
} &lt;span style="color:#8b008b;font-weight:bold">catch&lt;/span> (InterruptedException e) {
log.&lt;span style="color:#658b00">error&lt;/span>(&lt;span style="color:#cd5555">&amp;#34;RedisTemplateDistributeLockUtil.blockLock error!&amp;#34;&lt;/span>, e);
}
}
} &lt;span style="color:#8b008b;font-weight:bold">else&lt;/span> {
&lt;span style="color:#228b22">// 已经超时
&lt;/span>&lt;span style="color:#228b22">&lt;/span> &lt;span style="color:#8b008b;font-weight:bold">throw&lt;/span> &lt;span style="color:#8b008b;font-weight:bold">new&lt;/span> DistributeLockTimeoutException(&lt;span style="color:#cd5555">&amp;#34;Distribute Lock Timeout&amp;#34;&lt;/span>);
}
}
}
&lt;span style="color:#8b008b;font-weight:bold">public&lt;/span> &lt;span style="color:#00688b;font-weight:bold">boolean&lt;/span> &lt;span style="color:#008b45">unlock&lt;/span>(String key, String value) {
String script = UNLOCK_SCRIPT;
DefaultRedisScript&amp;lt;Long&amp;gt; redisScript = &lt;span style="color:#8b008b;font-weight:bold">new&lt;/span> DefaultRedisScript&amp;lt;&amp;gt;(script, Long.&lt;span style="color:#658b00">class&lt;/span>);
Long execute = (Long) redisTemplate.&lt;span style="color:#658b00">execute&lt;/span>(redisScript, Collections.&lt;span style="color:#658b00">singletonList&lt;/span>(key), value);
&lt;span style="color:#8b008b;font-weight:bold">return&lt;/span> execute != &lt;span style="color:#8b008b;font-weight:bold">null&lt;/span> &amp;amp;&amp;amp; execute != 0;
}
}
&lt;/code>&lt;/pre>&lt;/div>- https://pinkhello.me/posts/14-%E5%B7%A5%E4%BD%9C%E7%BA%AA%E5%AE%9E2020/ - PinkHello, All Rights Reserved</description></item><item><title>13 Kafka与Debezium构建CDC管道</title><link>https://pinkhello.me/posts/13-kafka%E4%B8%8Edebezium%E6%9E%84%E5%BB%BAcdc%E7%AE%A1%E9%81%93/</link><pubDate>Wed, 10 Feb 2021 09:53:51 +0800</pubDate><guid>https://pinkhello.me/posts/13-kafka%E4%B8%8Edebezium%E6%9E%84%E5%BB%BAcdc%E7%AE%A1%E9%81%93/</guid><description>PinkHello https://pinkhello.me/posts/13-kafka%E4%B8%8Edebezium%E6%9E%84%E5%BB%BAcdc%E7%AE%A1%E9%81%93/ -&lt;h1 id="建设篇">建设篇&lt;/h1>
&lt;h2 id="1什么是-debezium">1、什么是 debezium?&lt;/h2>
&lt;p>&lt;a href="https://debezium.io/">https://debezium.io/&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>Tutorial
&lt;a href="https://debezium.io/documentation/reference/1.3/tutorial.html">https://debezium.io/documentation/reference/1.3/tutorial.html&lt;/a>&lt;/p>
&lt;h2 id="2debezium-如何工作的">2、Debezium 如何工作的&lt;/h2>
&lt;p>&lt;img src="https://pinkhello.me/Kafka%E4%B8%8EDebezium%E6%9E%84%E5%BB%BACDC%E7%AE%A1%E9%81%93/debezium-architecture.png" alt="Debezium工作流程">&lt;/p>
&lt;h3 id="21-debezium-支持的数据库类型">2.1 Debezium 支持的数据库类型&lt;/h3>
&lt;ul>
&lt;li>MySQL&lt;/li>
&lt;li>MongoDB&lt;/li>
&lt;li>PostgreSQL&lt;/li>
&lt;li>Oracle&lt;/li>
&lt;li>SQL Server&lt;/li>
&lt;li>Db2&lt;/li>
&lt;li>Cassandra&lt;/li>
&lt;/ul>
&lt;h3 id="22-debezium-三种方式运行">2.2 Debezium 三种方式运行&lt;/h3>
&lt;ul>
&lt;li>Kafka Connect&lt;/li>
&lt;li>Debezium Server&lt;/li>
&lt;li>Embedded Engine&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://github.com/debezium/debezium-examples/tree/master/kinesis">https://github.com/debezium/debezium-examples/tree/master/kinesis&lt;/a>&lt;/p>
&lt;h2 id="3在-k8s-中构建基础debezium集群环境">3、在 K8S 中构建基础Debezium集群环境&lt;/h2>
&lt;p>镜像准备&lt;/p>
&lt;ul>
&lt;li>kafka | debezium &lt;a href="https://hub.docker.com/r/debezium/kafka">https://hub.docker.com/r/debezium/kafka&lt;/a>&lt;/li>
&lt;li>zookeeper | debezium &lt;a href="https://hub.docker.com/r/debezium/zookeeper">https://hub.docker.com/r/debezium/zookeeper&lt;/a>&lt;/li>
&lt;li>connect | debezium &lt;a href="https://hub.docker.com/r/debezium/connect">https://hub.docker.com/r/debezium/connect&lt;/a>&lt;/li>
&lt;li>schema-registry | confluentinc &lt;a href="https://hub.docker.com/r/confluentinc/cp-schema-registry">https://hub.docker.com/r/confluentinc/cp-schema-registry&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>ps：
debezium 参考地址 &lt;a href="https://github.com/debezium/docker-images">https://github.com/debezium/docker-images&lt;/a>
confluentinc 参考地址 &lt;a href="https://github.com/confluentinc/cp-all-in-one/tree/latest/cp-all-in-one">https://github.com/confluentinc/cp-all-in-one/tree/latest/cp-all-in-one&lt;/a>&lt;/p>
&lt;h3 id="31-k8s基础知识">3.1 K8S基础知识&lt;/h3>
&lt;ul>
&lt;li>kafka 与 zookeeper 建设为 stateful 状态集群&lt;/li>
&lt;li>schema-registry 主要为了 支持 avro 格式这些不需要写到 kafka 消息头里面，减少消息的大小，额外的服务，属于 kafka 生态，存储依赖 kafka broker保证稳定性。&lt;/li>
&lt;li>k8s steteful 集群 0&amp;hellip;~ n 个 POD&lt;/li>
&lt;li>zookeeper 里面 zoo.cfg 指定的是从 1 开始&lt;/li>
&lt;li>kafka 里面 broker 也是从 1 开始&lt;/li>
&lt;/ul>
&lt;h3 id="32-zookeeper-构建">3.2 zookeeper 构建&lt;/h3>
&lt;ul>
&lt;li>对应的 docker-entrypoint.sh 需要改写，注重 zoo.cfg 的生成&lt;/li>
&lt;li>开放 2888 端口 3888 端口 2181 端口&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#228b22"># 使用的 debezium zk 镜像&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#228b22"># https://github.com/debezium/docker-images/blob/master/zookeeper/1.4/README.md&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Service&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zookeeper-hs&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zookeeper&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">2888&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>server&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">3888&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>leader-election&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">2181&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>client&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">clusterIP&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>None&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zookeeper&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>apps/v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>StatefulSet&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zookeeper&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">matchLabels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zookeeper&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">serviceName&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zookeeper-hs&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">3&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">updateStrategy&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">type&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>RollingUpdate&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">podManagementPolicy&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>OrderedReady&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">template&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zookeeper&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">affinity&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">podAntiAffinity&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">requiredDuringSchedulingIgnoredDuringExecution&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">labelSelector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">matchExpressions&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">key&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;app&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">operator&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>In&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">values&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- zookeeper&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">topologyKey&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;kubernetes.io/hostname&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">securityContext&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">fsGroup&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">1000&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">runAsUser&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">1000&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zookeeper&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">imagePullPolicy&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Always&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>debezium/zookeeper:1.3&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">2181&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>client&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">2888&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>server&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">3888&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>leader-election&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">resources&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">requests&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">cpu&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>50m&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">memory&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>1500Mi&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">command&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- bash&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- -ec&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- |&lt;span style="color:#cd5555">
&lt;/span>&lt;span style="color:#cd5555"> if [ ! -d &amp;#34;/zookeeper/zdata/data&amp;#34; ];then
&lt;/span>&lt;span style="color:#cd5555"> mkdir /zookeeper/zdata/data
&lt;/span>&lt;span style="color:#cd5555"> fi
&lt;/span>&lt;span style="color:#cd5555"> if [ ! -d &amp;#34;/zookeeper/zdata/txns&amp;#34; ];then
&lt;/span>&lt;span style="color:#cd5555"> mkdir /zookeeper/zdata/txns
&lt;/span>&lt;span style="color:#cd5555"> fi
&lt;/span>&lt;span style="color:#cd5555"> export INDEX=${HOSTNAME##*-}
&lt;/span>&lt;span style="color:#cd5555"> echo $INDEX
&lt;/span>&lt;span style="color:#cd5555"> export SERVER_ID=$(( INDEX + 1 ))
&lt;/span>&lt;span style="color:#cd5555"> export SERVER_COUNT=3
&lt;/span>&lt;span style="color:#cd5555"> export LOG_LEVEL=INFO
&lt;/span>&lt;span style="color:#cd5555"> cp -rn $ZK_HOME/conf.orig/* $ZK_HOME/conf
&lt;/span>&lt;span style="color:#cd5555"> sed -i -r -e &amp;#34;s|\\$\\{zookeeper.root.logger\\}|$LOG_LEVEL, CONSOLE|g&amp;#34; $ZK_HOME/conf/log4j.properties
&lt;/span>&lt;span style="color:#cd5555"> sed -i -r -e &amp;#34;s|\\$\\{zookeeper.console.threshold\\}|$LOG_LEVEL|g&amp;#34; $ZK_HOME/conf/log4j.properties
&lt;/span>&lt;span style="color:#cd5555"> echo &amp;#34;&amp;#34; &amp;gt;&amp;gt; $ZK_HOME/conf/zoo.cfg
&lt;/span>&lt;span style="color:#cd5555"> echo &amp;#34;#Server List&amp;#34; &amp;gt;&amp;gt; $ZK_HOME/conf/zoo.cfg
&lt;/span>&lt;span style="color:#cd5555"> for i in $( eval echo {1..$SERVER_COUNT});do
&lt;/span>&lt;span style="color:#cd5555"> export HS_INDEX=$((i - 1))
&lt;/span>&lt;span style="color:#cd5555"> if [ &amp;#34;$SERVER_ID&amp;#34; = &amp;#34;$i&amp;#34; ];then
&lt;/span>&lt;span style="color:#cd5555"> echo &amp;#34;server.$i=0.0.0.0:2888:3888&amp;#34; &amp;gt;&amp;gt; $ZK_HOME/conf/zoo.cfg
&lt;/span>&lt;span style="color:#cd5555"> else
&lt;/span>&lt;span style="color:#cd5555"> echo &amp;#34;server.$i=zookeeper-$HS_INDEX.zookeeper-hs:2888:3888&amp;#34; &amp;gt;&amp;gt; $ZK_HOME/conf/zoo.cfg
&lt;/span>&lt;span style="color:#cd5555"> fi
&lt;/span>&lt;span style="color:#cd5555"> done
&lt;/span>&lt;span style="color:#cd5555"> echo ${SERVER_ID} &amp;gt; $ZK_HOME/zdata/data/myid
&lt;/span>&lt;span style="color:#cd5555"> sed -i &amp;#34;s|/zookeeper/data|/zookeeper/zdata/data|g&amp;#34; $ZK_HOME/conf/zoo.cfg
&lt;/span>&lt;span style="color:#cd5555"> sed -i &amp;#34;s|/zookeeper/txns|/zookeeper/zdata/txns|g&amp;#34; $ZK_HOME/conf/zoo.cfg
&lt;/span>&lt;span style="color:#cd5555"> export ZOOCFGDIR=&amp;#34;$ZK_HOME/conf&amp;#34;
&lt;/span>&lt;span style="color:#cd5555"> export ZOOCFG=&amp;#34;zoo.cfg&amp;#34;
&lt;/span>&lt;span style="color:#cd5555"> exec $ZK_HOME/bin/zkServer.sh start-foreground&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">volumeMounts&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zk-data&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>/zookeeper/zdata&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">volumeClaimTemplates&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zk-data&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">accessModes&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>[&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;ReadWriteOnce&amp;#34;&lt;/span>&lt;span style="color:#bbb"> &lt;/span>]&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">storageClassName&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>alicloud-disk-efficiency&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">resources&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">requests&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">storage&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>20Gi&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Service&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zookeeper-hs&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zookeeper&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">2888&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>server&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">3888&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>leader-election&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">2181&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>client&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">clusterIP&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>None&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zookeeper&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>参考文档 &lt;a href="https://github.com/debezium/docker-images/blob/master/zookeeper/1.3/README.md">https://github.com/debezium/docker-images/blob/master/zookeeper/1.3/README.md&lt;/a>&lt;/p>
&lt;h3 id="33-kafka-构建">3.3 kafka 构建&lt;/h3>
&lt;ul>
&lt;li>Kafka BrokerID 要变更，通过 POD 的 Index&lt;/li>
&lt;li>KAFKA_LISTENERS 与 KAFKA_ADVERTISED_LISTENERS 的配置&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>apps/v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>StatefulSet&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">matchLabels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">serviceName&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">3&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">updateStrategy&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">type&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>RollingUpdate&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">podManagementPolicy&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>OrderedReady&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">template&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">affinity&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">podAntiAffinity&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">requiredDuringSchedulingIgnoredDuringExecution&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">labelSelector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">matchExpressions&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">key&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;app&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">operator&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>In&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">values&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- kafka&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">topologyKey&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;kubernetes.io/hostname&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">securityContext&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">fsGroup&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">1000&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">runAsUser&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">1000&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">imagePullPolicy&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Always&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>debezium/kafka:1.3&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">9092&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">9093&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">resources&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">requests&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">cpu&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>100m&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">memory&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>1500Mi&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">env&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>ZOOKEEPER_CONNECT&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;zookeeper-0.zookeeper-hs:2181,zookeeper-1.zookeeper-hs:2181,zookeeper-2.zookeeper-hs:2181&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>LOG_LEVEL&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;INFO&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;2&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>KAFKA_LISTENER_SECURITY_PROTOCOL_MAP&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;PLAINTEXT:PLAINTEXT,EXTERNAL_PLAINTEXT:PLAINTEXT&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>KAFKA_INTER_BROKER_LISTENER_NAME&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;PLAINTEXT&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>KAFKA_LISTENERS&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;PLAINTEXT://0.0.0.0:9092,EXTERNAL_PLAINTEXT://0.0.0.0:9093&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>POD_IP&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">valueFrom&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">fieldRef&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">fieldPath&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>status.podIP&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">command&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- bash&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- -ec&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- |&lt;span style="color:#cd5555">
&lt;/span>&lt;span style="color:#cd5555"> export INDEX=${HOSTNAME##*-}
&lt;/span>&lt;span style="color:#cd5555"> export BROKER_ID=$((INDEX + 1))
&lt;/span>&lt;span style="color:#cd5555"> PORT=$((INDEX + 9093))
&lt;/span>&lt;span style="color:#cd5555"> export JMX_PORT=$((INDEX + 9999))
&lt;/span>&lt;span style="color:#cd5555"> export KAFKA_ADVERTISED_LISTENERS=&amp;#34;PLAINTEXT://${POD_IP}:9092,EXTERNAL_PLAINTEXT://${LB_IP}:${PORT}&amp;#34;
&lt;/span>&lt;span style="color:#cd5555"> exec /docker-entrypoint.sh start&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">volumeMounts&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-data&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">mountPath&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>/kafka/data&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">volumeClaimTemplates&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-data&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">accessModes&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>[&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;ReadWriteOnce&amp;#34;&lt;/span>&lt;span style="color:#bbb"> &lt;/span>]&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">storageClassName&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>alicloud-disk-efficiency&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">resources&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">requests&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">storage&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>20Gi&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Service&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-{index}&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">annotations&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#228b22"># 参考阿里云LB Service 配置 自动创建 好几种 LB类型，这边是内网LB&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">service.beta.kubernetes.io/alicloud-loadbalancer-address-type&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>intranet&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">service.beta.kubernetes.io/alicloud-loadbalancer-id&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>{LB实例ID}&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">service.beta.kubernetes.io/alicloud-loadbalancer-force-override-listeners&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#39;true&amp;#39;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">externalTrafficPolicy&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Local&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">type&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>LoadBalancer&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">statefulset.kubernetes.io/pod-name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-{index}&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>external&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>{{&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">9093&lt;/span>&lt;span style="color:#bbb"> &lt;/span>+ index }}&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">protocol&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>TCP&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">targetPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">9093&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>jmx&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>{{&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">9999&lt;/span>&lt;span style="color:#bbb"> &lt;/span>+ index }}&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">protocol&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>TCP&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">targetPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>{{&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">9999&lt;/span>&lt;span style="color:#bbb"> &lt;/span>+ index }}&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>internal&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">9092&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">protocol&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>TCP&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">targetPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">9092&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">piVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>networking.k8s.io/v1beta1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Ingress&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-manager&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">annotations&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">nginx.ingress.kubernetes.io/enable-global-auth&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;false&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">rules&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">host&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-manager.{域名}.com&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">http&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">paths&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">path&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>/&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">backend&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">serviceName&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-manager&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">servicePort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">80&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Service&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-manager&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-manager&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>http&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">80&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">targetPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">9000&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-manager&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>apps/v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Deployment&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-manager&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-manager&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">1&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">matchLabels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-manager&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">template&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-manager&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-manager&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">imagePullPolicy&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Always&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>dockerkafka/kafka-manager&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">9000&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">env&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>ZK_HOSTS&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;zookeeper-0.zookeeper-hs:2181,zookeeper-1.zookeeper-hs:2181,zookeeper-2.zookeeper-hs:2181&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">resources&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">requests&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">cpu&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>40m&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">memory&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>500Mi&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>参考文档 &lt;a href="https://github.com/debezium/docker-images/blob/master/kafka/1.4/README.md">https://github.com/debezium/docker-images/blob/master/kafka/1.4/README.md&lt;/a>&lt;/p>
&lt;h3 id="33-kafka-schema-registry-构建">3.3 kafka schema-registry 构建&lt;/h3>
&lt;ul>
&lt;li>Docker 基础镜像环境启动脚本 &lt;a href="https://github.com/confluentinc/schema-registry-images/blob/master/schema-registry/include/etc/confluent/docker/">https://github.com/confluentinc/schema-registry-images/blob/master/schema-registry/include/etc/confluent/docker/&lt;/a>&lt;/li>
&lt;li>先启动 pod 再映射 service，否则启动报错, 在这个项目里面有个 SCHEMA_REGISTRY_PORT,在基础启动脚本里面会主动退出&lt;/li>
&lt;li>配置 ZK 的话，在kafka listener 里面要有类型 PLAINTEXT， 集群内网外网环境配置了 KAFKA_LISTENER_SECURITY_PROTOCOL_MAP，按照正常的Kafka是正常的，但是 schema-registry 实现的是没有去找的，未做映射，只要没有 PLAINTEXT 就报错退出，启动失败&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>apps/v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Deployment&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>schema-registry&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>schema-registry&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">1&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">matchLabels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>schema-registry&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">template&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>schema-registry&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">securityContext&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">fsGroup&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">1000&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">runAsUser&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">1000&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>schema-registry&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">imagePullPolicy&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Always&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>confluentinc/cp-schema-registry:6.0.0&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">8081&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">env&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>SCHEMA_REGISTRY_HOST_NAME&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>schema-registry&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>zookeeper-0.zookeeper-hs:2181,zookeeper-1.zookeeper-hs:2181,zookeeper-2.zookeeper-hs:2181&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-0:9092,kafka-1:9092,kafka-2:9092&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">resources&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">requests&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">cpu&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>40m&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">memory&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>500Mi&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Service&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>schema-registry&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>schema-registry&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>http&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">8081&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>schema-registry&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>参考文档 &lt;a href="https://github.com/confluentinc/cp-all-in-one/blob/latest/cp-all-in-one-cloud/docker-compose.yml">https://github.com/confluentinc/cp-all-in-one/blob/latest/cp-all-in-one-cloud/docker-compose.yml&lt;/a>&lt;/p>
&lt;h3 id="33-kafka-connect-建设">3.3 kafka connect 建设&lt;/h3>
&lt;ul>
&lt;li>配置参数 等等 &lt;a href="http://kafka.apache.org/documentation/#connectconfigs">http://kafka.apache.org/documentation/#connectconfigs&lt;/a>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Service&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>connect&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>connect&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>http&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">80&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">targetPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">8083&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>connect&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>apps/v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Deployment&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>connect&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>connect&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">3&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">matchLabels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>connect&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">template&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>connect&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>connect&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">imagePullPolicy&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Always&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>debezium/connect:1.3&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">8083&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">env&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>LOG_LEVEL&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;INFO&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>BOOTSTRAP_SERVERS&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;kafka-0:9092,kafka-1:9092,kafka-2:9092&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>GROUP_ID&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;test_connect&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>CONFIG_STORAGE_TOPIC&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;test_connect_configs&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>OFFSET_STORAGE_TOPIC&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;test_connect_offset&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>STATUS_STORAGE_TOPIC&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;test_connect_status&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>KEY_CONVERTER&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;io.confluent.connect.avro.AvroConverter&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>VALUE_CONVERTER&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;io.confluent.connect.avro.AvroConverter&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>INTERNAL_KEY_CONVERTER&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;org.apache.kafka.connect.json.JsonConverter&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>INTERNAL_VALUE_CONVERTER&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;org.apache.kafka.connect.json.JsonConverter&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_UR&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;http://schema-registry:8081&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_UR&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;http://schema-registry:8081&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">resources&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">requests&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">cpu&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>40m&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">memory&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>500Mi&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#228b22"># 使用 kafka-connect-ui构建&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>networking.k8s.io/v1beta1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Ingress&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-connect-ui&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">annotations&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">nginx.ingress.kubernetes.io/enable-global-auth&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;false&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">rules&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">host&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-connect.{域名}.com&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">http&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">paths&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">path&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>/&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">backend&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">serviceName&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-connect-ui&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">servicePort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">80&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Service&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-connect-ui&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-connect-ui&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>http&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">port&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">80&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">targetPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">8000&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-connect-ui&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#008b45;text-decoration:underline">---&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">apiVersion&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>apps/v1&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">kind&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Deployment&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-connect-ui&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-connect-ui&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">&lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">replicas&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">1&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">selector&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">matchLabels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-connect-ui&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">template&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">metadata&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">labels&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">app&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-connect-ui&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">spec&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">containers&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>kafka-connect-ui&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">imagePullPolicy&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>Always&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">image&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>landoop/kafka-connect-ui&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">ports&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">containerPort&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#b452cd">8000&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">env&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>- &lt;span style="color:#8b008b;font-weight:bold">name&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>CONNECT_URL&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">value&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#cd5555">&amp;#34;http://connect&amp;#34;&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">resources&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">requests&lt;/span>:&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">cpu&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>40m&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb"> &lt;/span>&lt;span style="color:#8b008b;font-weight:bold">memory&lt;/span>:&lt;span style="color:#bbb"> &lt;/span>500Mi&lt;span style="color:#bbb">
&lt;/span>&lt;span style="color:#bbb">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>参考文档&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/debezium/docker-images/blob/master/connect/1.4/README.md">https://github.com/debezium/docker-images/blob/master/connect/1.4/README.md&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/debezium/debezium-examples/blob/master/tutorial/docker-compose-mysql-avro-connector.yaml">https://github.com/debezium/debezium-examples/blob/master/tutorial/docker-compose-mysql-avro-connector.yaml&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="数据湖篇">数据湖篇&lt;/h1>
&lt;h2 id="1hudi-data-lake">1、Hudi Data Lake？&lt;/h2>
&lt;p>之前构建了基于 &lt;code>Debezium&lt;/code> 捕获基本的数据变化，发送至 &lt;code>Kafka&lt;/code>, 后面的对接方可以是哪些呢？这些是要处理的&amp;hellip;&amp;hellip;&lt;/p>
&lt;p>Apache Hudi 是构建在 HDFS/S3 等大数据量的存储，旨在解决大数据生态系统中需要&lt;code>插入更新&lt;/code>及&lt;code>增量消费&lt;/code>的摄取管道和 &lt;code>ETL管道的低效&lt;/code>问题。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Near Real-Time Ingestion （近实时获取）&lt;/p>
&lt;p>将数据从外部数据&lt;code>event logs, databases, external sources&lt;/code>提取到&lt;code>Hadoop Data Lake&lt;/code>。
对于&lt;code>RDBMS&lt;/code>摄取，&lt;code>Hudi&lt;/code>通过&lt;code>Upserts&lt;/code>提供了更快的负载，&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Near Real-time Analytics （近实时分析）&lt;/p>
&lt;p>&lt;code>Hadoop上&lt;/code>的交互式SQL解决方案（如&lt;code>Presto&lt;/code>和&lt;code>SparkSQL&lt;/code>）。通过&lt;code>Hudi&lt;/code>将数据的更新时间缩短至几分钟，还可以对存储在&lt;code>DFS&lt;/code>中的多个大小更大的表进行实时分析。
而且，&lt;code>Hudi&lt;/code> 没有外部依赖项（如&lt;code>HBase&lt;/code>群集），因此可以在不增加运营开销的情况下，对更新鲜的分析进行更快的分析。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Incremental Processing Pipelines （增量处理管道）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Data Dispersal From DFS （分散数据）&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://pinkhello.me/Kafka%E4%B8%8EDebezium%E6%9E%84%E5%BB%BACDC%E7%AE%A1%E9%81%93/hudi-lake.png" alt="Hudi架构">&lt;/p>
&lt;h2 id="2timeline">2、Timeline&lt;/h2>
&lt;p>Hudi的核心是维护&lt;code>timeline&lt;/code>在不同&lt;code>instants&lt;/code>时间上对表上执行的所有操作中一个操作，这有助于提供表的即时视图，
同时还有效地支持按到达顺序对数据进行检索。&lt;/p>
&lt;p>Hudi瞬间包含以下组件&lt;/p>
&lt;ul>
&lt;li>Instant action ：在表格上执行的操作类型&lt;/li>
&lt;li>Instant time ：即时时间通常是一个时间戳记（例如：20190117010349），该时间戳记以动作开始时间的顺序单调增加。&lt;/li>
&lt;li>state ：即时状态&lt;/li>
&lt;/ul>
&lt;p>Hudi保证在&lt;code>timeline&lt;/code>上执行的操作基于当前时间是原子性和时间轴上一致的。&lt;/p>
&lt;p>执行的关键动作包括&lt;/p>
&lt;ul>
&lt;li>COMMITS - 提交记录 一批记录原子写入表中 提交表示将一批记录原子写入表中。&lt;/li>
&lt;li>CLEANS - 后台清除表中不需要的文件旧版本记录。&lt;/li>
&lt;li>DELTA_COMMIT - 增量提交是指将一批记录原子写入&lt;code>MergeOnRead&lt;/code>类型表中，其中一些/所有 数据 可以只写到增量日志中。&lt;/li>
&lt;li>COMPACTION - 调和&lt;code>Hudi&lt;/code>中不同数据结构的后台活动，例如：将更新从基于行的日志文件移动到列格式。在内部，压缩表现为时间轴上的特殊提交&lt;/li>
&lt;li>ROLLBACK - 表示提交/增量提交不成功且已回滚，删除了在写入过程中产生的任何部分文件&lt;/li>
&lt;li>SAVEPOINT - 将某些文件组标记为“已保存”，以便清理程序不会删除它们。在发生灾难/数据恢复的情况下，它有助于将表还原到时间轴上的某个点。&lt;/li>
&lt;/ul>
&lt;p>任何给定的瞬间都可以处于以下状态之一&lt;/p>
&lt;ul>
&lt;li>REQUESTED -表示已经安排了动作，但尚未开始&lt;/li>
&lt;li>INFLIGHT -表示当前正在执行该操作&lt;/li>
&lt;li>COMPLETED -表示在时间表上完成了一项操作
&lt;img src="https://pinkhello.me/Kafka%E4%B8%8EDebezium%E6%9E%84%E5%BB%BACDC%E7%AE%A1%E9%81%93/hudi_c.png" alt="COW">&lt;/li>
&lt;/ul>
&lt;h2 id="3hudi-的存储类型">3、Hudi 的存储类型&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>COW Copy On Write 快照查询 + 增量查询&lt;/p>
&lt;p>数据仅仅以 列文件格式 parquet 存储，每次写操作后数据的同步 Merge 以更新版本并重写文件，COW表中数据使用是最新的&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://pinkhello.me/Kafka%E4%B8%8EDebezium%E6%9E%84%E5%BB%BACDC%E7%AE%A1%E9%81%93/hudi_cow.png" alt="COW">&lt;/p>
&lt;ul>
&lt;li>
&lt;p>MOR merge on read 快照查询 + 增量查询 + 读取优化&lt;/p>
&lt;p>数据以 列文件格式 parquet 和 基于 行文件格式 avro 组合存储。每次写入操作将增量创建文件。然后 compact 以生成 列文件 的最新版&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://pinkhello.me/Kafka%E4%B8%8EDebezium%E6%9E%84%E5%BB%BACDC%E7%AE%A1%E9%81%93/hudi_mor.png" alt="MOR">&lt;/p>
- https://pinkhello.me/posts/13-kafka%E4%B8%8Edebezium%E6%9E%84%E5%BB%BAcdc%E7%AE%A1%E9%81%93/ - PinkHello, All Rights Reserved</description></item><item><title>12 聊聊蝙蝠Chat</title><link>https://pinkhello.me/posts/12-%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0chat/</link><pubDate>Wed, 10 Feb 2021 09:10:14 +0800</pubDate><guid>https://pinkhello.me/posts/12-%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0chat/</guid><description>PinkHello https://pinkhello.me/posts/12-%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0chat/ -&lt;hr>
&lt;p>title: 老司机聊聊BatChat
date: 2021-01-31 21:37:07
tags:&lt;/p>
&lt;ul>
&lt;li>BatChat/加密聊天&lt;/li>
&lt;/ul>
&lt;hr>
&lt;!-- raw HTML omitted -->
&lt;p>今天，在浏览&lt;code>小众软件&lt;/code>的时候，突然看见一个早期小编的推广～～～蝙蝠APP，联想到之前新闻中看到的有个贩卖个人信息的人说在蝙蝠APP上，勾起了我的好奇心，作为一个程序🐶，默默的想探究一下这个蝙蝠APP玩的什么套路。&lt;/p>
&lt;h1 id="什么是蝙蝠batchat">什么是蝙蝠（BatChat）&lt;/h1>
&lt;p>一款免费的端到端加密的蝙蝠APP，随时畅聊！
应用 IOS、Android
&lt;a href="https://batchat.com">https://batchat.com&lt;/a>&lt;/p>
&lt;h1 id="它的特性">它的特性&lt;/h1>
&lt;ul>
&lt;li>安全 ｜ 畅聊时、端到端加密（所有消息经过端到端加密，任何聊天记录不进行云存储，让你的信息想象中更安全）&lt;/li>
&lt;li>隐私 ｜ 畅聊时、双向撤回（聊天记录一键双向撤回，同时删除你和对方设备上所有的聊天记录，撤回数据多次覆盖删除、不可恢复、保证双方的隐私安全）&lt;/li>
&lt;li>匿名群聊 ｜ 开启匿名群聊，群里面的每一个成员都可以&amp;quot;变身&amp;quot;，隐藏真实身份，群内不受身份约束&lt;/li>
&lt;/ul>
&lt;h1 id="什么是端到端加密">什么是端到端加密？&lt;/h1>
&lt;p>端到端加密是在源结点和目的结点中对传送的数据进行加密和解密， 因此数据的安全性不会因中间结点的不可靠而受到影响。&lt;code> 蝙蝠APP的所有数据都通过用户端生成的私钥进行加密后再发送，任何第三方包括开发者都不能解开此数据&lt;/code>.&lt;/p>
&lt;h1 id="蝙蝠app采用的安全层级">蝙蝠APP采用的安全层级？&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>通道加密
通道加密中采用了哪些加密算法？
通道加密中使用到的 RSA, ECDHE, AES256_CBC, SHA256, SHA1等等(如下图)。&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E9%80%9A%E9%81%93%E5%8A%A0%E5%AF%86.png" alt="通道加密">
步骤:&lt;/p>
&lt;ul>
&lt;li>(1. 客户端和服务器先产生随机数&lt;/li>
&lt;li>(2. 服务器下发随机数。&lt;/li>
&lt;li>(3. 客户端用 RSA 对客户端随机数进行加密，并发送给服务器。&lt;/li>
&lt;li>(4. 服务器用 RSA 解密客户端随机数（使用 RSA 的目的是防止中间人攻击）。&lt;/li>
&lt;li>(5. 客户端，服务器用自己的随机数加上对方的随机数生成临时密钥 TempKey 和临时偏移量 TempIV (此时双方均持有相同的 TempKey和TempIV)。&lt;/li>
&lt;li>(6. 客户端服务器均使用 ECDHE 生成各自的公私钥对。&lt;/li>
&lt;li>(7. 客户端用 TempKey, TempIV 对自己的 ECDHE 公钥进行加密，并将密文发送给服务器。&lt;/li>
&lt;li>(8. 服务器收到客户端的 ECDHE 公钥密文，并解密。&lt;/li>
&lt;li>(9. 服务器使用 TempKey, TempIV 对自己的 ECDHE 公钥进行加密，并使用 RSA 对 ECDHE。&lt;/li>
&lt;li>(10. 服务器使用 ECDHE 算法，使用客户端 ECDHE 公钥明文+服务器 ECDHE 私钥明文生成ShareKey。&lt;/li>
&lt;li>(11. 客户端收到服务器的 ECDHE 公钥密文和签名，然后进行解密和验证签名，如果没有问题，就使用客户端 ECDHE 私钥明文+服务器ECDHE 公钥明文生成 ShareKey。&lt;/li>
&lt;li>(12. 服务器初始化各个参数，下发给客户端,参数包含：
&lt;ul>
&lt;li>
&lt;p>AuthKeyID： 服务器随机生成的客户端临时标识符&lt;/p>
&lt;/li>
&lt;li>
&lt;p>MsgKey： 由 ShareKey, AuthkeyID, MsgID, SessionID, Salt, SeqNo 以及真实的消息内容相加后进行 Sha256 后的值&lt;/p>
&lt;blockquote>
&lt;p>本参数用于：&lt;/p>
&lt;blockquote>
&lt;p>(a. 进行防止数据篡改的验证&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>(b. 与 ShareKey 一起使用，生成 Aes256 key, IV，用来对各条消息进行加密。&lt;/p>
&lt;/blockquote>
&lt;/blockquote>
&lt;/li>
&lt;li>
&lt;p>MsgID：时间相关的消息 ID，用于防止重放和去重。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>SessionID：每次登录唯一的会话 ID。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Salt：每次登录唯一的盐值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>SeqNo：用于防止重放。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>(13. 后续每条消息均会有不同的 MsgID, SessionID, Salt, SeqNo 和真实的消息内容；这些变化的值会导致 MsgKey 每次都不同。 这个每次都 不同的 MsgKey 加上 ShareKey 可以为每一条消息生成对应的 32 字节密钥和偏移量。&lt;/li>
&lt;li>(14. ShareKey 会过期，过期后需要重新进行密钥协商。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>内容加密&lt;/p>
&lt;ul>
&lt;li>(1. 用户生成 ECDHE 公私钥，保存在本地。&lt;/li>
&lt;li>(2. 将公钥发送到服务器，私钥保存在本地。&lt;/li>
&lt;li>(3. 用户登录，获取所有好友信息的更新，包含每个好友的公钥。&lt;/li>
&lt;li>(4. 发送消息，和接收消息时均采用自己的私钥+对方的公钥生成 ShareKey。&lt;/li>
&lt;li>(5. 使用 ShareKey 生成 AES256 的密钥，进行加密和解密。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86.png" alt="内容加密">&lt;/p>
&lt;p>蝙蝠 双棘轮算法 如下：
Alice(A)发送的消息传送了她的新公钥。 最终，Bob(B)将收到以下消息之一，并执行第二个DH棘轮步骤； 在每个DH棘轮步骤中生成的DH 输出用于导出新的发送和接收链密钥。当各方轮流执行DH棘轮步骤时，他们轮流引入新的发送链，依此类推。&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E5%8F%8C%E6%A3%98%E8%BD%AE%E7%AE%97%E6%B3%95.png" alt="双棘轮算法">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>服务器数据库安全&lt;/p>
&lt;ul>
&lt;li>(1. 数据库有签名字段。&lt;/li>
&lt;li>(2. 服务器上生成 ECDSA 公私钥。&lt;/li>
&lt;li>(3. 服务器代码中对数据库敏感字段，比如：password, userID, friend 等做增删改操作时均通过 ECDSA 生成签名，并更新到签名字段。&lt;/li>
&lt;li>(4. 服务器代码对 password, userID, friend 等数据进行读取，判断等操作时进行 ECDSA验证签名，只有通过验证才能进行后续流程，否则 给客户端报错。&lt;/li>
&lt;li>(5. 服务端程序进行加密和签名保护。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="好了上面的都是摘自-batchat-官网介绍现在进入正题">好了，上面的都是摘自 BatChat 官网介绍！现在进入正题！&lt;/h1>
&lt;p>先来一个重磅&lt;/p>
&lt;blockquote>
&lt;p>《网络安全法》 第二十一条规定，网络运营者应当按照网络安全等级保护制度的要求,履行安全保护义务,保障网络免受干扰、破坏或者未经授权的访问,防止网络数据泄露或者被窃取、篡改。网络运营者的安全义务包括采取监测、记录网络运行状态、网络安全事件的技术措施,并按照规定留存相关的网络日志不少于六个月。&lt;/p>
&lt;/blockquote>
&lt;p>嘿嘿 ，按照小弟的理解，&lt;code>BatChat&lt;/code> 号称端到端加密，那么信息加密和国内备案明显冲突了，所以要么这其中有一个是假的，要么就是在违&lt;code>法&lt;/code>的边缘疯狂试探。&lt;/p>
&lt;p>正因为看到这些，所以小弟默默的 &lt;code>Download&lt;/code> 了下来, 然后默默的 &lt;code>Install&lt;/code>, 然后默默的注册登录进入了 😯 💐 ～～～～&lt;/p>
&lt;p>进入是基础Tab功能菜单&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/app-%E6%88%91%E7%9A%84.png" alt="app">&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/app-%E8%81%94%E7%B3%BB%E4%BA%BA.jpeg" alt="app">&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/app-%E8%9D%99%E8%9D%A0%E6%88%91%E7%9A%84.png" alt="app">&lt;/p>
&lt;p>进入瞬间的内容，我呵呵咯～～&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E7%9E%AC%E9%97%B4-%E8%BF%9D%E8%A7%84.jpeg" alt="app">&lt;/p>
&lt;p>有没有看出来什么，人脸识别自动识别造假（黑灰产业链）&lt;/p>
&lt;p>下面是我的一些截图，你们自己看咯&lt;/p>
&lt;ul>
&lt;li>
&lt;p>标签搜索 点击换一组，这是官方的推荐的。&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E6%A0%87%E7%AD%BE%E6%90%9C%E7%B4%A21.jpeg" alt="标签">&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E6%A0%87%E7%AD%BE%E6%90%9C%E7%B4%A22.jpeg" alt="标签">&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E6%A0%87%E7%AD%BE%E6%90%9C%E7%B4%A23.jpeg" alt="标签">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>搜索敏感词群&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E7%BE%A4%E6%90%9C%E7%B4%A2%E6%94%AF%E4%BB%98.jpeg" alt="群搜索">&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E7%BE%A4%E6%90%9C%E7%B4%A2%E7%A6%8F%E5%88%A9.jpeg" alt="群搜索">&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E7%BE%A4%E6%90%9C%E7%B4%A2%E8%8F%A0%E8%8F%9C%E5%A4%9A.jpeg" alt="群搜索">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>我默默的加了一个看似正常的群，进群后我风化了！！！！&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E7%BE%A4%E8%BF%9D%E8%A7%84%E5%86%85%E5%AE%B91.jpeg" alt="进群信息">&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E7%BE%A4%E8%BF%9D%E8%A7%84%E5%86%85%E5%AE%B92.jpeg" alt="进群信息">&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E8%BF%9D%E8%A7%84%E7%BE%A4%E5%86%85%E5%AE%B95.png" alt="进群信息">&lt;/p>
&lt;p>下面是防骗官方群里的&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0Chat/%E5%AE%A3%E4%BC%A0%E7%BE%A4%E8%BF%9D%E8%A7%843.jpeg" alt="进群信息">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="好了总结一下batchat">好了，总结一下BatChat！&lt;/h1>
&lt;p>蝙蝠APP聚合了哪些人？&lt;/p>
&lt;ul>
&lt;li>绝大部分黑灰产业链上下游人员！&lt;/li>
&lt;li>极小部分尝鲜的小白&lt;/li>
&lt;li>当然因为陌生人聊天，我能进入的只有群搜索，应该还有更深的。&lt;/li>
&lt;/ul>
&lt;p>当然个人认为，此平台竟然能运行到现在，后面想象的空间很大啊&lt;/p>
&lt;p>补个刀，知乎专栏 &lt;a href="https://zhuanlan.zhihu.com/p/158261618">https://zhuanlan.zhihu.com/p/158261618&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>这尼玛就是为黑灰产业搭建聚合平台啊！虽说你不想，但是就宣传的端到端加密以及消息撤回，这个不正是他们在意的么？
当然某腾也宣称不存储**啥的？你信？&lt;/p>
&lt;/blockquote>
&lt;p>现在我要郑重声明：我默默的删除了此款APP！！！&lt;/p>
- https://pinkhello.me/posts/12-%E8%81%8A%E8%81%8A%E8%9D%99%E8%9D%A0chat/ - PinkHello, All Rights Reserved</description></item><item><title>11 几个关于kafka的知识点</title><link>https://pinkhello.me/posts/11-%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/</link><pubDate>Wed, 10 Feb 2021 08:55:19 +0800</pubDate><guid>https://pinkhello.me/posts/11-%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/</guid><description>PinkHello https://pinkhello.me/posts/11-%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/ -&lt;h1 id="认识kafka">认识kafka&lt;/h1>
&lt;p>&lt;code>Kafka&lt;/code> 是分布式消息系统， &lt;code>Apache&lt;/code> 的子项目。标语也变了&amp;quot;分布式流平台&amp;quot;，
与传统的消息系统不同点在于&lt;/p>
&lt;ul>
&lt;li>分布式的，易于扩展&lt;/li>
&lt;li>为发布和订阅提供了高吞吐&lt;/li>
&lt;li>支持多订阅者，在失败的时候能自动平衡消费者&lt;/li>
&lt;li>消息的持久化&lt;/li>
&lt;/ul>
&lt;h1 id="kafka-的架构">&lt;code>kafka&lt;/code> 的架构&lt;/h1>
&lt;p>几点？&lt;/p>
&lt;ul>
&lt;li>&lt;code>Kafka&lt;/code> 的 &lt;code>Topic&lt;/code> 和 &lt;code>Partition&lt;/code> 内部如何存储？&lt;/li>
&lt;li>与传统的消息系统相比， &lt;code>Kafka&lt;/code> 消费模型有啥优点？&lt;/li>
&lt;li>&lt;code>Kafka&lt;/code> 是如何实现分布式数据存储和数据的读取？&lt;/li>
&lt;/ul>
&lt;h2 id="kafka-架构">&lt;code>Kafka&lt;/code> 架构&lt;/h2>
&lt;p>一个 &lt;code>Kafka&lt;/code> 集群，多个 &lt;code>Producer&lt;/code> ，多个 &lt;code>Consumer&lt;/code> ，多个 &lt;code>Broker&lt;/code> ， 选举 &lt;code>Leader&lt;/code> 以及在 &lt;code>Consumer Group&lt;/code> 发生变化时进行 &lt;code>reblance&lt;/code> 。&lt;/p>
&lt;ul>
&lt;li>&lt;code>Broker&lt;/code> 消息中间件的处理节点，一个 &lt;code>Kafka&lt;/code> 节点就是一个 &lt;code>Broker&lt;/code> ， 一个或者多个 &lt;code>Broker&lt;/code> 组成 &lt;code>Kafka&lt;/code> 集群&lt;/li>
&lt;li>&lt;code>Topic&lt;/code> &lt;code>Kafka&lt;/code> 根据 &lt;code>Topic&lt;/code> 对 &lt;code>Message&lt;/code> 进行归类，发布到 &lt;code>Kafka&lt;/code> 的每条 &lt;code>Message&lt;/code> 都要指定 &lt;code>Topic&lt;/code>&lt;/li>
&lt;li>&lt;code>Producer&lt;/code> 向 &lt;code>Broker&lt;/code> 发生 &lt;code>message&lt;/code>&lt;/li>
&lt;li>&lt;code>Consumer&lt;/code> 从 &lt;code>Broker&lt;/code> 读取 &lt;code>message&lt;/code>&lt;/li>
&lt;li>&lt;code>Consumer Group&lt;/code> 每个 Consumer 属于特定的 Group，一个 Message 可以发送给不同的 &lt;code>Consumer Group&lt;/code> ，但是同一个 &lt;code>Group&lt;/code> 下的只有一个 &lt;code>Consumer&lt;/code> 能消费该 &lt;code>Message&lt;/code>&lt;/li>
&lt;li>&lt;code>Partition&lt;/code> 物理概念，一个 &lt;code>Topic&lt;/code> 下可以分为多个 &lt;code>Partition&lt;/code>, 每个 &lt;code>Partition&lt;/code> 下是有序的。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://pinkhello.me/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-%E6%A1%86%E6%9E%B6%E5%9B%BE.jpeg" alt="kafka 框架图">
&lt;img src="https://pinkhello.me/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%90%91.png" alt="kafka 数据流向">&lt;/p>
&lt;p>下面来讲述 上面为问题啊&lt;/p>
&lt;h2 id="kafka-的-topic-和-partition-内部如何存储">&lt;code>Kafka&lt;/code> 的 &lt;code>Topic&lt;/code> 和 &lt;code>Partition&lt;/code> 内部如何存储?&lt;/h2>
&lt;p>&lt;code>Kafka&lt;/code> 为每个 &lt;code>Topic&lt;/code> 维护了分区（ &lt;code>Partition&lt;/code> ）的日志文件，每个 &lt;code>Partition&lt;/code> 在 &lt;code>kafka&lt;/code> 存储层为 &lt;code>Append Log&lt;/code>。任何发布到此 &lt;code>Partition&lt;/code> 的消息都会被追加到 &lt;code>Log&lt;/code> 文件尾部。
在每个 &lt;code>Partition&lt;/code> 每个消息是按照 &lt;code>Timeline&lt;/code> 分配到一个单调递增的顺序编号的，就是我们说的 &lt;code>Offset&lt;/code>, &lt;code>Offset&lt;/code> 是一个 &lt;code>long&lt;/code> 型的数字，也是我们可以通过这个 &lt;code>Offset&lt;/code> 确定一条在该 &lt;code>Partition&lt;/code> 下的唯一消息。&lt;/p>
&lt;p>这样就有个特性： &lt;code>Partition&lt;/code> 下有序, &lt;code>Topic&lt;/code> 下无法保证有序。&lt;/p>
&lt;p>那么，问题来了？这些 &lt;code>Message&lt;/code> 如何发送到各个 &lt;code>Partition&lt;/code> 的呢？如何指定的呢？&lt;/p>
&lt;ul>
&lt;li>发送至哪个 &lt;code>Partition&lt;/code> 是由 生产者决定的。&lt;/li>
&lt;li>如果没有 &lt;code>Key&lt;/code> 值，则轮询发送&lt;/li>
&lt;li>如果有 &lt;code>key&lt;/code> 值，对 &lt;code>key&lt;/code> 值进行 &lt;code>Hash&lt;/code> ，然后对分区数量取余，保证同一个 &lt;code>Key&lt;/code> 值的会路由到同一个 &lt;code>Partition&lt;/code> 。如果想队列强顺序一致，可以让所有的消息设置为同一个 &lt;code>Key&lt;/code> 。&lt;/li>
&lt;/ul>
&lt;h2 id="与传统的消息系统相比-kafka-消费模型有啥优点">与传统的消息系统相比， &lt;code>Kafka&lt;/code> 消费模型有啥优点？&lt;/h2>
&lt;h3 id="kafka-consumer-消费模型">&lt;code>Kafka Consumer&lt;/code> 消费模型&lt;/h3>
&lt;p>消息由 &lt;code>producer&lt;/code> 发送到 &lt;code>Kafka&lt;/code> 集群后，被 &lt;code>Consumer&lt;/code> 消费，一般来说我们的消费模型有两种： &lt;code>Push&lt;/code> 推送模型 和 &lt;code>Pull&lt;/code> 拉取模型&lt;/p>
&lt;p>&lt;code>Push&lt;/code> 推送模型：&lt;/p>
&lt;blockquote>
&lt;p>消息 &lt;code>Broker&lt;/code> 记录消费状态。消息 &lt;code>Broker&lt;/code> 将消息推送给消费者后，记录这条消息已经被消费，但是这种方式无法很好的保证消费处理的语义。
消息推送完成后，消费者挂掉或者线程 Hang 住 ，或者网络原因未收到，但是 消息 &lt;code>Broker&lt;/code> 将其标记为已消费，这个消息将永远丢失了。
也就是说，采用 &lt;code>Push&lt;/code> ，消息消费完全依赖 消息 &lt;code>Broker&lt;/code> 控制，一旦 &lt;code>Consumer&lt;/code> 发生阻塞，会出现问题。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;code>Pull&lt;/code> 拉取模型：&lt;/p>
&lt;blockquote>
&lt;p>由 &lt;code>Consumer&lt;/code> 控制 &lt;code>Speed&lt;/code> ，以及消费 &lt;code>Offset&lt;/code> ， &lt;code>Consumer&lt;/code> 可以按照任意的偏移量进行 &lt;code>Consumer&lt;/code>
&lt;code>Consumer&lt;/code> 可以回放已经消费过的消息，进行重新处理或者消费最近的消息&lt;/p>
&lt;/blockquote>
&lt;h3 id="kafka-的网络模型">&lt;code>Kafka&lt;/code> 的网络模型&lt;/h3>
&lt;p>&lt;code>Kafka Client&lt;/code> 单线程 &lt;code>Selector&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-client-selector.png" alt="kafka 单线程模型">&lt;/p>
&lt;blockquote>
&lt;p>并发链接数目小，逻辑简单，数据量小。在 &lt;code>Kafka Consumer&lt;/code> 和 &lt;code>Kafka Producer&lt;/code> 都是采用的 单线程模型。&lt;/p>
&lt;/blockquote>
&lt;p>&lt;code>kafka Server&lt;/code> 多线程 &lt;code>Selector&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-server-selector.png" alt="kafka 多线程模型">&lt;/p>
&lt;blockquote>
&lt;p>&lt;code>Acceptor&lt;/code> 运行于一个单独的线程，对于读取操作的线程池中线程都是在 &lt;code>selector&lt;/code> 注册 &lt;code>Op_Read&lt;/code> 事件，负责服务端读取请求。
成功读取后，将请求放入 &lt;code>Message Queue&lt;/code> 共享队列中，然后在 写操作的线程池中，取出这个请求，对其进行逻辑处理。
即使某个线程阻塞了，后面还有后续的线程从 &lt;code>Message Queue&lt;/code> 共享队列里面获取请求进行处理。
写线程处理完逻辑后，由于注册了 &lt;code>Op_Write&lt;/code> 事件，还需要发送响应。&lt;/p>
&lt;/blockquote>
&lt;h2 id="kafka-是如何实现分布式数据存储和数据的读取">&lt;code>Kafka&lt;/code> 是如何实现分布式数据存储和数据的读取？&lt;/h2>
&lt;h3 id="kafka-高可靠的分布式存储模型">&lt;code>Kafka&lt;/code> 高可靠的分布式存储模型&lt;/h3>
&lt;p>主要依靠 副本 机制，有了副本机制，机器宕机，也会恢复。&lt;/p>
&lt;h3 id="kafka-高性能日志存储">&lt;code>Kafka&lt;/code> 高性能日志存储&lt;/h3>
&lt;p>&lt;img src="https://pinkhello.me/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-segement.png" alt="kafka 高性能日志存储">
&lt;img src="https://pinkhello.me/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-append-log.png" alt="kafka 高性能日志存储">&lt;/p>
&lt;p>&lt;code>Kafka&lt;/code> 的一个 &lt;code>Topic&lt;/code> 下的所有的 &lt;code>Message&lt;/code> 都是以 &lt;code>Partition&lt;/code> 的方式，分布式存储在多个节点上。&lt;/p>
&lt;p>同时在 kafka 机器上，每个 &lt;code>Partition&lt;/code> 都会对应一个日志目录，在目录下面会对应对歌 日志分段（&lt;code>LogSegment&lt;/code>）。
LogSegment 组成 &amp;ldquo;.index&amp;rdquo; 与 &amp;ldquo;.log&amp;rdquo; , 分别表示 &lt;code>segment&lt;/code> 索引文件 和 数据文件。
两个文件的命名规则: &lt;code>partition&lt;/code> 全局的第一个 &lt;code>segment&lt;/code> 从 0 开始，后续的每个 &lt;code>Segment&lt;/code> 文件名为上一个 &lt;code>Segment&lt;/code> 文件最后一条消息的 &lt;code>offset&lt;/code> 值。
数值为 64 位， 20 位数字字符长度，没有数字用 0 填充。&lt;/p>
&lt;p>假如有 1000 条消息，每个 &lt;code>LogSegment&lt;/code> 的大小为 100，那么展现 900-1000 的索引 和 Log：
&lt;img src="https://pinkhello.me/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-log.jpg" alt="kafka LogSegment">&lt;/p>
&lt;p>&lt;code>kafka&lt;/code> 消息数据量打，采用的是 &lt;code>稀疏索引&lt;/code> 的方式，加快偏查询速度。&lt;/p>
&lt;p>如何读取数据？ 如果我们要读取第 911 条数据&lt;/p>
&lt;ul>
&lt;li>先找到它属于哪个段？ 二分法查找属于文件，找到 0000900.index 和 0000900.log 之后&lt;/li>
&lt;li>去索引文件 0000900.index 查找 (911-900)=11 这个索引 或者 小于11 最近的索引&lt;/li>
&lt;li>后面通过 二分法我们找到索引 [10,1367]&lt;/li>
&lt;li>然后通过这条索引的物理位置 1367，开始往后找，知道找到 第 911 条数据&lt;/li>
&lt;/ul>
&lt;p>&lt;code>为什么分区？只有一个分区不行么？分区是为了干啥？那么日志为什么要分段呢？&lt;/code>&lt;/p>
&lt;h2 id="kafka-的副本机制">&lt;code>Kafka&lt;/code> 的副本机制&lt;/h2>
&lt;p>&lt;code>Kafka&lt;/code> 副本机制为 多个节点对其他服务端节点的主题分区的日志进行复制。当集群某个节点出现问题，访问该故障节点的请求可以被转移到其他正常的节点（过程脚 &lt;code>reblance&lt;/code> ）&lt;/p>
&lt;p>&lt;code>kafka&lt;/code> 的每个 &lt;code>Topic&lt;/code> 的每个 &lt;code>Partition&lt;/code> 都有一个 主副本以及 &lt;code>0-n&lt;/code> 个副本，副本保持与主副本的数据同步，当 主副本 出现故障时会被替代。&lt;/p>
&lt;p>&lt;img src="https://pinkhello.me/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-partition-replicas.png" alt="kafka 高性能副本机制">&lt;/p>
&lt;p>在 &lt;code>kafka&lt;/code> 中，并不是所有的副本都被拿来代替主副本的，所以在 &lt;code>kafka&lt;/code> 的 &lt;code>leader&lt;/code> 节点中维护者一个 &lt;code>ISR（In Sync Replicas）&lt;/code>集合
&lt;code>ISR (In Sync Replicas)&lt;/code> 副本 &lt;code>follower&lt;/code> 同步队列, 维护着有资格的 &lt;code>follower&lt;/code> 的节点&lt;/p>
&lt;ul>
&lt;li>副本的所有节点必须和 &lt;code>ZK&lt;/code> 保持链接&lt;/li>
&lt;li>在同步过程中，这个副本不能落后主副本太多(即副本最后一条消息的 &lt;code>offset&lt;/code> 和 &lt;code>leader&lt;/code> 副本的最好一条消息的 &lt;code>offset&lt;/code> 之间的差值不能超过阈值)
(&lt;code>replica.lag.max.messages&lt;/code>)&lt;/li>
&lt;/ul>
&lt;p>&lt;code>AR（Assigned Replicas）&lt;/code>标记副本的全集 ，&lt;code>OSR&lt;/code> 表示落后被剔除的副本集合&lt;/p>
&lt;p>ISR = leader + 没有落后太多的副本
AR = OSR + ISR&lt;/p>
&lt;p>&lt;code>HW &amp;amp; LEO&lt;/code>
&lt;code>Follower&lt;/code> 副本同步过程中，两个概念 &lt;code>HW&lt;/code> &lt;code>HighWatermark&lt;/code> 和 &lt;code>LEO&lt;/code> &lt;code>Log End Offset&lt;/code>，与 &lt;code>ISR&lt;/code> 紧密相关。&lt;/p>
&lt;p>&lt;code>HW&lt;/code> 是一个特殊的 &lt;code>Offset&lt;/code> ，当 &lt;code>Consumer&lt;/code> 处理消息的时候，只能 &lt;code>Pull&lt;/code> 到 &lt;code>HW&lt;/code> 之前的消息， &lt;code>HW&lt;/code> 之后的消息对 &lt;code>Consumer&lt;/code> 不可见。
也就是说 &lt;code>Partition&lt;/code> 对应的 ISR 中最小的 &lt;code>LEO&lt;/code> 作为 &lt;code>HW&lt;/code> ， &lt;code>Consumer&lt;/code> 最多只能消费到 &lt;code>HW&lt;/code> 所在的位置，每个 &lt;code>Replica&lt;/code> 都有 &lt;code>HW&lt;/code> ，
&lt;code>leader&lt;/code> 和 &lt;code>follower&lt;/code> 各自维护更新自己的 &lt;code>HW&lt;/code> 的状态，对于 &lt;code>Leader&lt;/code> 新写入的消息， &lt;code>Consumer&lt;/code> 不能立刻消费， &lt;code>Leader&lt;/code> 会等待
该消息被所有的 &lt;code>ISR&lt;/code> 中的 &lt;code>Replicas&lt;/code> 同步更新 &lt;code>HW&lt;/code> ，此时消息才能被 &lt;code>Consumer&lt;/code> 消费，这样保证了如果 &lt;code>Leader&lt;/code> 副本损坏，
该消息仍然可以从新选举的 &lt;code>Leader&lt;/code> 获取。&lt;/p>
&lt;p>&lt;code>LEO&lt;/code> 是所有副都会有的一个 &lt;code>offset&lt;/code> 标记，它指向追加到当前副本的最后一个消息的 &lt;code>offset&lt;/code> ，当生产者向 &lt;code>Leader&lt;/code> 副本追加消息时候， &lt;code>Leader&lt;/code> 副本的 &lt;code>LEO&lt;/code> 标记就会递增；
当 &lt;code>follower&lt;/code> 副本成功从 &lt;code>leader&lt;/code> 副本 &lt;code>pull&lt;/code> 消息并更新到本地的时候， &lt;code>follower&lt;/code> 副本也会增肌&lt;/p>
&lt;blockquote>
&lt;p>&lt;code>producer&lt;/code> 向 &lt;code>leader&lt;/code> 发送消息，可以通过 &lt;code>request.required.acks&lt;/code> 参数来设置数据可靠性级别：&lt;/p>
&lt;ul>
&lt;li>1 默认， &lt;code>producer&lt;/code> 在 &lt;code>ISR&lt;/code> 中的 &lt;code>leader&lt;/code> 已成功收到数据并得到确认后发送下一条 &lt;code>Message&lt;/code> 。如果 &lt;code>Leader&lt;/code> 宕机，会丢失数据&lt;/li>
&lt;li>0 &lt;code>producer&lt;/code> 无需等待，继续发送下一批消息，效率高，但是数据可靠性低&lt;/li>
&lt;li>-1 &lt;code>producer&lt;/code> 需要等待 &lt;code>ISR&lt;/code> 中所以的 &lt;code>follower&lt;/code> 都确认接收到数据才算发送完成。可靠性高，但是没有也不能保证数据不丢失，比如 &lt;code>ISR&lt;/code> 里只有 &lt;code>leader&lt;/code> （其他节点和 &lt;code>ZK&lt;/code> 断链，或者没有追上），这样就变成了 &lt;code>acks=1&lt;/code> 的情况&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;h1 id="kafka-到底会不会丢消息">&lt;code>kafka&lt;/code> 到底会不会丢消息&lt;/h1>
&lt;p>一个消息的流转&lt;/p>
&lt;ul>
&lt;li>&lt;code>Producer&lt;/code> 发送给 &lt;code>Kafka Broker&lt;/code>&lt;/li>
&lt;li>&lt;code>kafka Broker&lt;/code> 消息同步和持久化&lt;/li>
&lt;li>&lt;code>Kafka Brokder&lt;/code> 将消息传递给消费者&lt;/li>
&lt;/ul>
&lt;h1 id="如何优雅的使用-kafka-consumer">如何优雅的使用 Kafka Consumer&lt;/h1>
&lt;p>注意点等等&amp;hellip;..&lt;/p>
&lt;h1 id="kafka-producer-流程详细">&lt;code>kafka Producer&lt;/code> 流程详细&lt;/h1>
&lt;p>&lt;img src="https://pinkhello.me/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-producer-flow.png" alt="kafkaProducer流程解读">
&lt;img src="https://pinkhello.me/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-meta-get.png" alt="kafka 获取元数据">&lt;/p>
- https://pinkhello.me/posts/11-%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/ - PinkHello, All Rights Reserved</description></item></channel></rss>