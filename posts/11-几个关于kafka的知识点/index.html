<!doctype html><html lang=en><head><title>一杯哈希不加盐</title><meta charset=utf-8><meta content="utf-8" http-equiv=encoding><meta name=viewport content="width=device-width,initial-scale=1"><meta name=format-detection content="telephone=no"><meta name=theme-color content="#000084"><link rel=icon href=https://pinkhello.github.io//favicon.ico><link rel=canonical href=https://pinkhello.github.io/></head><body><nav class="navbar navbar-inverse navbar-fixed-top"><div class=navbar-inner><div class=container><button type=button class="btn btn-navbar" data-toggle=collapse data-target=.nav-collapse></button>
<a class=brand href=https://pinkhello.github.io/>一杯哈希不加盐</a><div class="nav-collapse collapse"><ul class=nav><li><a href=/about/><span>About</span></a></li><li><a href=/posts/><span>Archive</span></a></li></ul></div></div></div></nav><div id=content class=container><div class="row-fluid navmargin"><div class=page-header><h1>11 几个关于kafka的知识点 - Wed, Feb 10, 2021</h1></div><p class=lead></p><h1 id=认识kafka>认识kafka</h1><p><code>Kafka</code> 是分布式消息系统， <code>Apache</code> 的子项目。标语也变了"分布式流平台"，
与传统的消息系统不同点在于</p><ul><li>分布式的，易于扩展</li><li>为发布和订阅提供了高吞吐</li><li>支持多订阅者，在失败的时候能自动平衡消费者</li><li>消息的持久化</li></ul><h1 id=kafka-的架构><code>kafka</code> 的架构</h1><p>几点？</p><ul><li><code>Kafka</code> 的 <code>Topic</code> 和 <code>Partition</code> 内部如何存储？</li><li>与传统的消息系统相比， <code>Kafka</code> 消费模型有啥优点？</li><li><code>Kafka</code> 是如何实现分布式数据存储和数据的读取？</li></ul><h2 id=kafka-架构><code>Kafka</code> 架构</h2><p>一个 <code>Kafka</code> 集群，多个 <code>Producer</code> ，多个 <code>Consumer</code> ，多个 <code>Broker</code> ， 选举 <code>Leader</code> 以及在 <code>Consumer Group</code> 发生变化时进行 <code>reblance</code> 。</p><ul><li><code>Broker</code> 消息中间件的处理节点，一个 <code>Kafka</code> 节点就是一个 <code>Broker</code> ， 一个或者多个 <code>Broker</code> 组成 <code>Kafka</code> 集群</li><li><code>Topic</code> <code>Kafka</code> 根据 <code>Topic</code> 对 <code>Message</code> 进行归类，发布到 <code>Kafka</code> 的每条 <code>Message</code> 都要指定 <code>Topic</code></li><li><code>Producer</code> 向 <code>Broker</code> 发生 <code>message</code></li><li><code>Consumer</code> 从 <code>Broker</code> 读取 <code>message</code></li><li><code>Consumer Group</code> 每个 Consumer 属于特定的 Group，一个 Message 可以发送给不同的 <code>Consumer Group</code> ，但是同一个 <code>Group</code> 下的只有一个 <code>Consumer</code> 能消费该 <code>Message</code></li><li><code>Partition</code> 物理概念，一个 <code>Topic</code> 下可以分为多个 <code>Partition</code>, 每个 <code>Partition</code> 下是有序的。</li></ul><p><img src=/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-%E6%A1%86%E6%9E%B6%E5%9B%BE.jpeg alt="kafka 框架图">
<img src=/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%90%91.png alt="kafka 数据流向"></p><p>下面来讲述 上面为问题啊</p><h2 id=kafka-的-topic-和-partition-内部如何存储><code>Kafka</code> 的 <code>Topic</code> 和 <code>Partition</code> 内部如何存储?</h2><p><code>Kafka</code> 为每个 <code>Topic</code> 维护了分区（ <code>Partition</code> ）的日志文件，每个 <code>Partition</code> 在 <code>kafka</code> 存储层为 <code>Append Log</code>。任何发布到此 <code>Partition</code> 的消息都会被追加到 <code>Log</code> 文件尾部。
在每个 <code>Partition</code> 每个消息是按照 <code>Timeline</code> 分配到一个单调递增的顺序编号的，就是我们说的 <code>Offset</code>, <code>Offset</code> 是一个 <code>long</code> 型的数字，也是我们可以通过这个 <code>Offset</code> 确定一条在该 <code>Partition</code> 下的唯一消息。</p><p>这样就有个特性： <code>Partition</code> 下有序, <code>Topic</code> 下无法保证有序。</p><p>那么，问题来了？这些 <code>Message</code> 如何发送到各个 <code>Partition</code> 的呢？如何指定的呢？</p><ul><li>发送至哪个 <code>Partition</code> 是由 生产者决定的。</li><li>如果没有 <code>Key</code> 值，则轮询发送</li><li>如果有 <code>key</code> 值，对 <code>key</code> 值进行 <code>Hash</code> ，然后对分区数量取余，保证同一个 <code>Key</code> 值的会路由到同一个 <code>Partition</code> 。如果想队列强顺序一致，可以让所有的消息设置为同一个 <code>Key</code> 。</li></ul><h2 id=与传统的消息系统相比-kafka-消费模型有啥优点>与传统的消息系统相比， <code>Kafka</code> 消费模型有啥优点？</h2><h3 id=kafka-consumer-消费模型><code>Kafka Consumer</code> 消费模型</h3><p>消息由 <code>producer</code> 发送到 <code>Kafka</code> 集群后，被 <code>Consumer</code> 消费，一般来说我们的消费模型有两种： <code>Push</code> 推送模型 和 <code>Pull</code> 拉取模型</p><p><code>Push</code> 推送模型：</p><blockquote><p>消息 <code>Broker</code> 记录消费状态。消息 <code>Broker</code> 将消息推送给消费者后，记录这条消息已经被消费，但是这种方式无法很好的保证消费处理的语义。
消息推送完成后，消费者挂掉或者线程 Hang 住 ，或者网络原因未收到，但是 消息 <code>Broker</code> 将其标记为已消费，这个消息将永远丢失了。
也就是说，采用 <code>Push</code> ，消息消费完全依赖 消息 <code>Broker</code> 控制，一旦 <code>Consumer</code> 发生阻塞，会出现问题。</p></blockquote><p><code>Pull</code> 拉取模型：</p><blockquote><p>由 <code>Consumer</code> 控制 <code>Speed</code> ，以及消费 <code>Offset</code> ， <code>Consumer</code> 可以按照任意的偏移量进行 <code>Consumer</code>
<code>Consumer</code> 可以回放已经消费过的消息，进行重新处理或者消费最近的消息</p></blockquote><h3 id=kafka-的网络模型><code>Kafka</code> 的网络模型</h3><p><code>Kafka Client</code> 单线程 <code>Selector</code></p><p><img src=/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-client-selector.png alt="kafka 单线程模型"></p><blockquote><p>并发链接数目小，逻辑简单，数据量小。在 <code>Kafka Consumer</code> 和 <code>Kafka Producer</code> 都是采用的 单线程模型。</p></blockquote><p><code>kafka Server</code> 多线程 <code>Selector</code></p><p><img src=/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-server-selector.png alt="kafka 多线程模型"></p><blockquote><p><code>Acceptor</code> 运行于一个单独的线程，对于读取操作的线程池中线程都是在 <code>selector</code> 注册 <code>Op_Read</code> 事件，负责服务端读取请求。
成功读取后，将请求放入 <code>Message Queue</code> 共享队列中，然后在 写操作的线程池中，取出这个请求，对其进行逻辑处理。
即使某个线程阻塞了，后面还有后续的线程从 <code>Message Queue</code> 共享队列里面获取请求进行处理。
写线程处理完逻辑后，由于注册了 <code>Op_Write</code> 事件，还需要发送响应。</p></blockquote><h2 id=kafka-是如何实现分布式数据存储和数据的读取><code>Kafka</code> 是如何实现分布式数据存储和数据的读取？</h2><h3 id=kafka-高可靠的分布式存储模型><code>Kafka</code> 高可靠的分布式存储模型</h3><p>主要依靠 副本 机制，有了副本机制，机器宕机，也会恢复。</p><h3 id=kafka-高性能日志存储><code>Kafka</code> 高性能日志存储</h3><p><img src=/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-segement.png alt="kafka 高性能日志存储">
<img src=/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-append-log.png alt="kafka 高性能日志存储"></p><p><code>Kafka</code> 的一个 <code>Topic</code> 下的所有的 <code>Message</code> 都是以 <code>Partition</code> 的方式，分布式存储在多个节点上。</p><p>同时在 kafka 机器上，每个 <code>Partition</code> 都会对应一个日志目录，在目录下面会对应对歌 日志分段（<code>LogSegment</code>）。
LogSegment 组成 &ldquo;.index&rdquo; 与 &ldquo;.log&rdquo; , 分别表示 <code>segment</code> 索引文件 和 数据文件。
两个文件的命名规则: <code>partition</code> 全局的第一个 <code>segment</code> 从 0 开始，后续的每个 <code>Segment</code> 文件名为上一个 <code>Segment</code> 文件最后一条消息的 <code>offset</code> 值。
数值为 64 位， 20 位数字字符长度，没有数字用 0 填充。</p><p>假如有 1000 条消息，每个 <code>LogSegment</code> 的大小为 100，那么展现 900-1000 的索引 和 Log：
<img src=/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-log.jpg alt="kafka LogSegment"></p><p><code>kafka</code> 消息数据量打，采用的是 <code>稀疏索引</code> 的方式，加快偏查询速度。</p><p>如何读取数据？ 如果我们要读取第 911 条数据</p><ul><li>先找到它属于哪个段？ 二分法查找属于文件，找到 0000900.index 和 0000900.log 之后</li><li>去索引文件 0000900.index 查找 (911-900)=11 这个索引 或者 小于11 最近的索引</li><li>后面通过 二分法我们找到索引 [10,1367]</li><li>然后通过这条索引的物理位置 1367，开始往后找，知道找到 第 911 条数据</li></ul><p><code>为什么分区？只有一个分区不行么？分区是为了干啥？那么日志为什么要分段呢？</code></p><h2 id=kafka-的副本机制><code>Kafka</code> 的副本机制</h2><p><code>Kafka</code> 副本机制为 多个节点对其他服务端节点的主题分区的日志进行复制。当集群某个节点出现问题，访问该故障节点的请求可以被转移到其他正常的节点（过程脚 <code>reblance</code> ）</p><p><code>kafka</code> 的每个 <code>Topic</code> 的每个 <code>Partition</code> 都有一个 主副本以及 <code>0-n</code> 个副本，副本保持与主副本的数据同步，当 主副本 出现故障时会被替代。</p><p><img src=/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-partition-replicas.png alt="kafka 高性能副本机制"></p><p>在 <code>kafka</code> 中，并不是所有的副本都被拿来代替主副本的，所以在 <code>kafka</code> 的 <code>leader</code> 节点中维护者一个 <code>ISR（In Sync Replicas）</code>集合
<code>ISR (In Sync Replicas)</code> 副本 <code>follower</code> 同步队列, 维护着有资格的 <code>follower</code> 的节点</p><ul><li>副本的所有节点必须和 <code>ZK</code> 保持链接</li><li>在同步过程中，这个副本不能落后主副本太多(即副本最后一条消息的 <code>offset</code> 和 <code>leader</code> 副本的最好一条消息的 <code>offset</code> 之间的差值不能超过阈值)
(<code>replica.lag.max.messages</code>)</li></ul><p><code>AR（Assigned Replicas）</code>标记副本的全集 ，<code>OSR</code> 表示落后被剔除的副本集合</p><p>ISR = leader + 没有落后太多的副本
AR = OSR + ISR</p><p><code>HW & LEO</code>
<code>Follower</code> 副本同步过程中，两个概念 <code>HW</code> <code>HighWatermark</code> 和 <code>LEO</code> <code>Log End Offset</code>，与 <code>ISR</code> 紧密相关。</p><p><code>HW</code> 是一个特殊的 <code>Offset</code> ，当 <code>Consumer</code> 处理消息的时候，只能 <code>Pull</code> 到 <code>HW</code> 之前的消息， <code>HW</code> 之后的消息对 <code>Consumer</code> 不可见。
也就是说 <code>Partition</code> 对应的 ISR 中最小的 <code>LEO</code> 作为 <code>HW</code> ， <code>Consumer</code> 最多只能消费到 <code>HW</code> 所在的位置，每个 <code>Replica</code> 都有 <code>HW</code> ，
<code>leader</code> 和 <code>follower</code> 各自维护更新自己的 <code>HW</code> 的状态，对于 <code>Leader</code> 新写入的消息， <code>Consumer</code> 不能立刻消费， <code>Leader</code> 会等待
该消息被所有的 <code>ISR</code> 中的 <code>Replicas</code> 同步更新 <code>HW</code> ，此时消息才能被 <code>Consumer</code> 消费，这样保证了如果 <code>Leader</code> 副本损坏，
该消息仍然可以从新选举的 <code>Leader</code> 获取。</p><p><code>LEO</code> 是所有副都会有的一个 <code>offset</code> 标记，它指向追加到当前副本的最后一个消息的 <code>offset</code> ，当生产者向 <code>Leader</code> 副本追加消息时候， <code>Leader</code> 副本的 <code>LEO</code> 标记就会递增；
当 <code>follower</code> 副本成功从 <code>leader</code> 副本 <code>pull</code> 消息并更新到本地的时候， <code>follower</code> 副本也会增肌</p><blockquote><p><code>producer</code> 向 <code>leader</code> 发送消息，可以通过 <code>request.required.acks</code> 参数来设置数据可靠性级别：</p><ul><li>1 默认， <code>producer</code> 在 <code>ISR</code> 中的 <code>leader</code> 已成功收到数据并得到确认后发送下一条 <code>Message</code> 。如果 <code>Leader</code> 宕机，会丢失数据</li><li>0 <code>producer</code> 无需等待，继续发送下一批消息，效率高，但是数据可靠性低</li><li>-1 <code>producer</code> 需要等待 <code>ISR</code> 中所以的 <code>follower</code> 都确认接收到数据才算发送完成。可靠性高，但是没有也不能保证数据不丢失，比如 <code>ISR</code> 里只有 <code>leader</code> （其他节点和 <code>ZK</code> 断链，或者没有追上），这样就变成了 <code>acks=1</code> 的情况</li></ul></blockquote><h1 id=kafka-到底会不会丢消息><code>kafka</code> 到底会不会丢消息</h1><p>一个消息的流转</p><ul><li><code>Producer</code> 发送给 <code>Kafka Broker</code></li><li><code>kafka Broker</code> 消息同步和持久化</li><li><code>Kafka Brokder</code> 将消息传递给消费者</li></ul><h1 id=如何优雅的使用-kafka-consumer>如何优雅的使用 Kafka Consumer</h1><p>注意点等等&mldr;..</p><h1 id=kafka-producer-流程详细><code>kafka Producer</code> 流程详细</h1><p><img src=/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-producer-flow.png alt=kafkaProducer流程解读>
<img src=/%E5%87%A0%E4%B8%AA%E5%85%B3%E4%BA%8Ekafka%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/kafka-meta-get.png alt="kafka 获取元数据"></p><h4><a href=https://pinkhello.github.io/>Back to Home</a></h4></div></div><footer class=container><hr class=soften><p><a href=https://pinkhello.github.io/>hugo.386 theme</a> |
&copy;
<a href=https://pinkhello.github.io/ target=_blank>一杯哈希不加盐</a>
<span id=thisyear>2020</span>
| Built on <a href=//gohugo.io target=_blank>Hugo</a></p><p class=text-center><a href=https://github.com/PinkHello>GitHub</a></p></footer></body><link rel=stylesheet href=/css/bootstrap.css><link rel=stylesheet href=/css/bootstrap-responsive.css><link rel=stylesheet href=/css/style.css><script src=/js/jquery.js></script><script src=/js/bootstrap-386.js></script><script src=/js/bootstrap-transition.js></script><script src=/js/bootstrap-alert.js></script><script src=/js/bootstrap-modal.js></script><script src=/js/bootstrap-dropdown.js></script><script src=/js/bootstrap-scrollspy.js></script><script src=/js/bootstrap-tab.js></script><script src=/js/bootstrap-tooltip.js></script><script src=/js/bootstrap-popover.js></script><script src=/js/bootstrap-button.js></script><script src=/js/bootstrap-collapse.js></script><script src=/js/bootstrap-carousel.js></script><script src=/js/bootstrap-typeahead.js></script><script src=/js/bootstrap-affix.js></script><script>_386={fastLoad:false,onePass:false,speedFactor:1};function ThisYear(){document.getElementById('thisyear').innerHTML=new Date().getFullYear();};</script></html>